{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup & Konfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in /home/renku/work/.venv/lib/python3.10/site-packages (7.6.0)\n",
      "Requirement already satisfied: pyvis in /home/renku/work/.venv/lib/python3.10/site-packages (0.3.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/renku/work/.venv/lib/python3.10/site-packages (from rdflib) (3.3.2)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.7.2 in /home/renku/work/.venv/lib/python3.10/site-packages (from rdflib) (0.7.2)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from pyvis) (8.37.0)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /home/renku/work/.venv/lib/python3.10/site-packages (from pyvis) (4.1.1)\n",
      "Requirement already satisfied: networkx>=1.11 in /home/renku/work/.venv/lib/python3.10/site-packages (from pyvis) (3.4.2)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from pyvis) (3.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: stack_data in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (2.19.2)\n",
      "Requirement already satisfied: exceptiongroup in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (1.3.0)\n",
      "Requirement already satisfied: decorator in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (5.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (3.0.52)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from jinja2>=2.9.6->pyvis) (3.0.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from stack_data->ipython>=5.3.0->pyvis) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from stack_data->ipython>=5.3.0->pyvis) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from stack_data->ipython>=5.3.0->pyvis) (2.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rdflib pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ RenkuLab Pipeline Integration\n",
      "üìÇ Input RDF: /home/renku/work/dcaonnextcloud-500gb/dca-metadataraw/WeingutGantenbein/gramazio-kohler-archiv-server_results/gramazio-kohler-archiv-server_catalog_prov.ttl\n",
      "‚úÖ RenkuLab Output gefunden: 6.9 MB\n",
      "üéØ Files Base: /home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server\n",
      "üíæ Output wird gespeichert als: catalog_enriched.ttl\n"
     ]
    }
   ],
   "source": [
    "# --- Notebook-Header: Pipeline-Integration mit RenkuLab ---\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json, subprocess, hashlib, sys, math, shutil\n",
    "from datetime import datetime\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD, DCTERMS\n",
    "import networkx as nx\n",
    "from typing import Optional, List, Set\n",
    "from urllib.parse import unquote\n",
    "\n",
    "# ----------------------- Pipeline-Pfade (RenkuLab Integration) -----------------------\n",
    "# INPUT: Von RenkuLab Pipeline generierte RDF\n",
    "INPUT_RDF_PATH = Path(\"/home/renku/work/dcaonnextcloud-500gb/dca-metadataraw/WeingutGantenbein/gramazio-kohler-archiv-server_results/gramazio-kohler-archiv-server_catalog_prov.ttl\")\n",
    "\n",
    "# OUTPUT: Mit XMP-Daten angereicherte RDF  \n",
    "OUTPUT_RDF_PATH = Path(\"./catalog_enriched.ttl\")       # ‚Üê Finale erweiterte Version\n",
    "\n",
    "# BACKUP: Timestamped Backup vor Verarbeitung\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "BACKUP_RDF_PATH = Path(f\"./dca_catalog_backup_{timestamp}.ttl\")\n",
    "\n",
    "# TOOLS\n",
    "EXIFTOOL = \"/home/renku/work/exiftool/exiftool\"  # ggf. absoluter Pfad anpassen\n",
    "FILES_BASE_DIR = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server\")\n",
    "\n",
    "# ----------------------- Namespaces ---------------------------\n",
    "DCA      = Namespace(\"http://dca.ethz.ch/ontology#\")\n",
    "DCA_ID   = Namespace(\"http://dca.ethz.ch/id/\")\n",
    "DCA_TECH = Namespace(\"http://dca.ethz.ch/tech#\")\n",
    "PREMIS   = Namespace(\"http://www.loc.gov/premis/rdf/v3/\")\n",
    "RICO     = Namespace(\"https://www.ica.org/standards/RiC/ontology#\")\n",
    "XSDNS    = XSD  # Abk√ºrzung\n",
    "# DCTERMS ist oben importiert\n",
    "\n",
    "# ----------------------- Ziel: Bild-/Adobe-Typen -------------\n",
    "IMG_EXT = {\n",
    "    # klassische Bilder\n",
    "    \"jpg\",\"jpeg\",\"tif\",\"tiff\",\"png\",\"gif\",\"bmp\",\n",
    "    # RAW (optional ‚Äì je nach Bestand)\n",
    "    \"dng\",\"cr2\",\"nef\",\"arw\"\n",
    "}\n",
    "ADOBE_EXT = {\"psd\",\"psb\",\"ai\",\"indd\",\"pdf\"}  # PDF h√§ufig Photoshop/Illustrator-Export\n",
    "\n",
    "TARGET_EXT = IMG_EXT | ADOBE_EXT\n",
    "\n",
    "# === ID-Helfer basierend auf DROID CSV: hash_md5[:16] ===\n",
    "from rdflib import URIRef\n",
    "\n",
    "DCA_ID_BASE = \"http://dca.ethz.ch/id/\"\n",
    "\n",
    "def dca_file_uri_from_md5(md5_hex: Optional[str]) -> Optional[URIRef]:\n",
    "    \"\"\"\n",
    "    Erzeugt dca-id:file_<md5[:16]> aus einem MD5-Hexstring (ohne Leerzeichen).\n",
    "    Gibt None zur√ºck, wenn md5_hex leer/ung√ºltig ist.\n",
    "    \"\"\"\n",
    "    if not md5_hex or not isinstance(md5_hex, str):\n",
    "        return None\n",
    "    md5_hex = md5_hex.strip().lower()\n",
    "    if len(md5_hex) < 16:\n",
    "        return None\n",
    "    short = md5_hex[:16]\n",
    "    return URIRef(DCA_ID_BASE + f\"file_{short}\")\n",
    "\n",
    "def dca_file_uri_from_path(file_path: str) -> Optional[URIRef]:\n",
    "    \"\"\"\n",
    "    Erzeugt dca-id:file_URI basierend auf DROID MD5-Hash (bevorzugt) oder Pfad-Fallback.\n",
    "    Diese Funktion ersetzt die alte pfad-basierte Implementierung.\n",
    "    \"\"\"\n",
    "    # 1. Versuche MD5-Hash aus DROID CSV zu verwenden\n",
    "    md5_hash = md5_for_abs_path(file_path)\n",
    "    if md5_hash:\n",
    "        return dca_file_uri_from_md5(md5_hash)\n",
    "    \n",
    "    # 2. Fallback: Pfad-basierter Hash (f√ºr R√ºckw√§rtskompatibilit√§t)\n",
    "    print(f\"‚ö†Ô∏è  Fallback zu Pfad-Hash f√ºr: {file_path}\")\n",
    "    path_hash = hashlib.sha256(file_path.encode('utf-8')).hexdigest()[:16]\n",
    "    return URIRef(DCA_ID_BASE + f\"file_{path_hash}\")\n",
    "\n",
    "def md5_for_abs_path(p: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Gibt den MD5-Hash f√ºr einen Dateipfad zur√ºck, falls im DROID CSV vorhanden.\n",
    "    \"\"\"\n",
    "    return path_to_md5.get(p)\n",
    "\n",
    "def safe_literal_dt(text: str, datatype=XSD.dateTime):\n",
    "    try:\n",
    "        return Literal(text, datatype=datatype)\n",
    "    except Exception:\n",
    "        return Literal(text)  # fall back\n",
    "\n",
    "def run_exiftool_json(files: list, fast=False):\n",
    "    \"\"\"Rufe exiftool als JSON auf, tolerant gegen Minor Errors, UTF-8 Dateinamen.\"\"\"\n",
    "    if not files:\n",
    "        return []\n",
    "    cmd = [EXIFTOOL, \"-a\",\"-s\",\"-G1\",\"-json\", \"-charset\",\"filename=UTF8\",\"-m\"]\n",
    "    if fast:\n",
    "        cmd.insert(1, \"-fast\")\n",
    "    tags = [\n",
    "        \"XMP-xmpMM:DocumentID\",\n",
    "        \"XMP-xmpMM:InstanceID\",\n",
    "        \"XMP-xmpMM:OriginalDocumentID\",\n",
    "        \"XMP-xmpMM:DerivedFromDocumentID\",\n",
    "        \"XMP-xmpMM:DerivedFromInstanceID\",\n",
    "        \"XMP-xmp:CreatorTool\",\n",
    "        \"File:FileName\",\n",
    "        \"File:Directory\",\n",
    "        \"File:FileModifyDate\",\n",
    "    ]\n",
    "    cmd += tags + files\n",
    "\n",
    "    res = subprocess.run(cmd, text=True, capture_output=True)\n",
    "    out = res.stdout.strip()\n",
    "    try:\n",
    "        return json.loads(out) if out else []\n",
    "    except Exception as e:\n",
    "        print(\"EXIF JSON parse error:\", e, file=sys.stderr)\n",
    "        return []\n",
    "\n",
    "def add_identifier_triple(g: Graph, file_uri: URIRef, id_type: str, value: str):\n",
    "    \"\"\"H√§nge einen PREMIS-Identifier als Blank Node an ein File-Objekt.\"\"\"\n",
    "    if not value:\n",
    "        return\n",
    "    bn = BNode()\n",
    "    g.add((file_uri, PREMIS.hasIdentifier, bn))\n",
    "    g.add((bn, PREMIS.identifierType, Literal(id_type)))\n",
    "    g.add((bn, PREMIS.identifierValue, Literal(value)))\n",
    "\n",
    "# MD5-Hash-Mapping (wird sp√§ter aus RDF geladen)\n",
    "path_to_md5 = {}\n",
    "\n",
    "# ----------------------- RenkuLab Pipeline √úberpr√ºfung -----------------------\n",
    "print(\"üöÄ RenkuLab Pipeline Integration\")\n",
    "print(f\"üìÇ Input RDF: {INPUT_RDF_PATH}\")\n",
    "\n",
    "if INPUT_RDF_PATH.exists():\n",
    "    size_mb = INPUT_RDF_PATH.stat().st_size / 1024 / 1024\n",
    "    print(f\"‚úÖ RenkuLab Output gefunden: {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(f\"‚ùå RenkuLab Output nicht gefunden!\")\n",
    "    print(\"   ‚Üí Pr√ºfe RenkuLab Pipeline oder Pfad\")\n",
    "\n",
    "print(f\"üéØ Files Base: {FILES_BASE_DIR}\")\n",
    "print(f\"üíæ Output wird gespeichert als: {OUTPUT_RDF_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDF laden, Backup erstellen & Kandidaten aus RDF extrahieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí Creating backup: dca_catalog_backup_20260227_142830.ttl\n",
      "‚úÖ Backup created: 6.93 MB\n",
      "üìÇ Loading RDF from: /home/renku/work/dcaonnextcloud-500gb/dca-metadataraw/WeingutGantenbein/gramazio-kohler-archiv-server_results/gramazio-kohler-archiv-server_catalog_prov.ttl\n",
      "üìä Loaded: 124,174 triples\n",
      "üîç Extracting image/Adobe files from RDF...\n",
      "üìä Total candidates: 6,516\n",
      "üìÅ Files exist locally: 0\n",
      "üìà Graph ready for XMP enrichment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_uri</th>\n",
       "      <th>title</th>\n",
       "      <th>identifier</th>\n",
       "      <th>format_name</th>\n",
       "      <th>local_path</th>\n",
       "      <th>exists</th>\n",
       "      <th>ABS_PATH</th>\n",
       "      <th>EXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://dca.ethz.ch/id/file_0001615cb891ac0f</td>\n",
       "      <td>fallingSpheres_0401.tif</td>\n",
       "      <td>https://nextcloud.ethz.ch/remote.php/dav/files...</td>\n",
       "      <td>Tagged Image File Format</td>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://dca.ethz.ch/id/file_00084414b2765927</td>\n",
       "      <td>fluid16.jpg</td>\n",
       "      <td>https://nextcloud.ethz.ch/remote.php/dav/files...</td>\n",
       "      <td>JPEG File Interchange Format</td>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://dca.ethz.ch/id/file_00148359ca3be9a7</td>\n",
       "      <td>fallingSpheres_1677.tif</td>\n",
       "      <td>https://nextcloud.ethz.ch/remote.php/dav/files...</td>\n",
       "      <td>Tagged Image File Format</td>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      file_uri                    title  \\\n",
       "0  http://dca.ethz.ch/id/file_0001615cb891ac0f  fallingSpheres_0401.tif   \n",
       "1  http://dca.ethz.ch/id/file_00084414b2765927              fluid16.jpg   \n",
       "2  http://dca.ethz.ch/id/file_00148359ca3be9a7  fallingSpheres_1677.tif   \n",
       "\n",
       "                                          identifier  \\\n",
       "0  https://nextcloud.ethz.ch/remote.php/dav/files...   \n",
       "1  https://nextcloud.ethz.ch/remote.php/dav/files...   \n",
       "2  https://nextcloud.ethz.ch/remote.php/dav/files...   \n",
       "\n",
       "                    format_name  \\\n",
       "0      Tagged Image File Format   \n",
       "1  JPEG File Interchange Format   \n",
       "2      Tagged Image File Format   \n",
       "\n",
       "                                          local_path  exists  \\\n",
       "0  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   False   \n",
       "1  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   False   \n",
       "2  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   False   \n",
       "\n",
       "                                            ABS_PATH  EXT  \n",
       "0  /home/renku/work/dcaonnextcloud-500gb/DigitalM...  tif  \n",
       "1  /home/renku/work/dcaonnextcloud-500gb/DigitalM...  jpg  \n",
       "2  /home/renku/work/dcaonnextcloud-500gb/DigitalM...  tif  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# PIPELINE INTEGRATION: RDF LADEN UND BACKUP ERSTELLEN\n",
    "# =====================================================\n",
    "\n",
    "# 1. Sicherheitspr√ºfungen\n",
    "if not INPUT_RDF_PATH.exists():\n",
    "    print(f\"‚ùå Input RDF not found: {INPUT_RDF_PATH}\")\n",
    "    print(\"   ‚Üí Stelle sicher, dass RenkuLab Pipeline erfolgreich war\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 2. Backup der Original-RDF erstellen  \n",
    "print(f\"üîí Creating backup: {BACKUP_RDF_PATH.name}\")\n",
    "shutil.copy2(INPUT_RDF_PATH, BACKUP_RDF_PATH)\n",
    "print(f\"‚úÖ Backup created: {BACKUP_RDF_PATH.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# 3. RDF Graph laden\n",
    "print(f\"üìÇ Loading RDF from: {INPUT_RDF_PATH}\")\n",
    "graph = Graph()\n",
    "graph.parse(INPUT_RDF_PATH, format='turtle')\n",
    "original_triples = len(graph)\n",
    "print(f\"üìä Loaded: {original_triples:,} triples\")\n",
    "\n",
    "# 4. Kandidaten aus RDF extrahieren (Bild/Adobe-Dateien)\n",
    "print(\"üîç Extracting image/Adobe files from RDF...\")\n",
    "candidate_data = []\n",
    "\n",
    "# SPARQL Query f√ºr Kandidaten-Dateien\n",
    "query = \"\"\"\n",
    "    PREFIX dca: <http://dca.ethz.ch/ontology#>\n",
    "    PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "    PREFIX premis: <http://www.loc.gov/premis/rdf/v3/>\n",
    "    \n",
    "    SELECT ?file ?title ?identifier ?format WHERE {\n",
    "        ?file a dca:ArchiveFile ;\n",
    "              dcterms:title ?title ;\n",
    "              dcterms:identifier ?identifier .\n",
    "        OPTIONAL { ?file premis:hasFormatName ?format }\n",
    "        \n",
    "        # Filter f√ºr Bild/Adobe-Dateien √ºber Titel-Extension\n",
    "        FILTER(\n",
    "            CONTAINS(LCASE(?title), \".jpg\") ||\n",
    "            CONTAINS(LCASE(?title), \".jpeg\") ||\n",
    "            CONTAINS(LCASE(?title), \".tif\") ||\n",
    "            CONTAINS(LCASE(?title), \".tiff\") ||\n",
    "            CONTAINS(LCASE(?title), \".png\") ||\n",
    "            CONTAINS(LCASE(?title), \".psd\") ||\n",
    "            CONTAINS(LCASE(?title), \".ai\") ||\n",
    "            CONTAINS(LCASE(?title), \".pdf\")\n",
    "        )\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "results = graph.query(query)\n",
    "for row in results:\n",
    "    file_uri = str(row.file)\n",
    "    title = str(row.title)\n",
    "    identifier = str(row.identifier) \n",
    "    format_name = str(row.format) if row.format else \"Unknown\"\n",
    "    \n",
    "    # Intelligentere lokale Pfad-Extraktion aus WebDAV URL\n",
    "    if identifier.startswith(\"https://nextcloud.ethz.ch/\"):\n",
    "        # URL decode und lokalen Pfad konstruieren\n",
    "        try:\n",
    "            # F√ºr gramazio-kohler-archiv-server URLs\n",
    "            if \"gramazio-kohler-archiv-server\" in identifier:\n",
    "                # Extrahiere alles nach dem letzten \"gramazio-kohler-archiv-server/\"\n",
    "                parts = identifier.split(\"gramazio-kohler-archiv-server/\")\n",
    "                if len(parts) > 1:\n",
    "                    path_part = unquote(parts[-1])  # Letzten Teil nehmen (nach dem Server-Namen)\n",
    "                    local_path = FILES_BASE_DIR / path_part\n",
    "                else:\n",
    "                    # Fallback: Nur Dateiname verwenden\n",
    "                    local_path = FILES_BASE_DIR / Path(unquote(identifier)).name\n",
    "            else:\n",
    "                # Fallback f√ºr andere NextCloud URLs\n",
    "                local_path = FILES_BASE_DIR / Path(unquote(identifier)).name\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  URL parsing failed for {identifier}: {e}\")\n",
    "            local_path = Path(title)  # Fallback zum Titel\n",
    "    else:\n",
    "        local_path = Path(title)  # Fallback\n",
    "    \n",
    "    candidate_data.append({\n",
    "        'file_uri': file_uri,\n",
    "        'title': title,\n",
    "        'identifier': identifier,\n",
    "        'format_name': format_name,\n",
    "        'local_path': str(local_path),\n",
    "        'exists': local_path.exists() if local_path.is_absolute() else False\n",
    "    })\n",
    "\n",
    "# Zu DataFrame f√ºr weitere Verarbeitung\n",
    "cand = pd.DataFrame(candidate_data)\n",
    "cand[\"ABS_PATH\"] = cand[\"local_path\"]  # Kompatibilit√§t mit bestehendem Code\n",
    "\n",
    "# EXT-Spalte aus Dateinamen extrahieren f√ºr Kompatibilit√§t\n",
    "cand[\"EXT\"] = cand[\"title\"].str.lower().str.extract(r'\\.([^.]+)$')\n",
    "\n",
    "print(f\"üìä Total candidates: {len(cand):,}\")\n",
    "print(f\"üìÅ Files exist locally: {cand['exists'].sum():,}\")\n",
    "\n",
    "# Debug: Zeige ein paar Beispiel-Pfade\n",
    "print(f\"\\nüîç Sample path mappings:\")\n",
    "for _, row in cand.head(3).iterrows():\n",
    "    print(f\"   Title: {row['title']}\")\n",
    "    print(f\"   ID:    {row['identifier'][:50]}{'...' if len(row['identifier']) > 50 else ''}\")\n",
    "    print(f\"   Local: {row['local_path']}\")\n",
    "    print(f\"   Exists: {row['exists']}\")\n",
    "    print()\n",
    "\n",
    "print(f\"üìà Graph ready for XMP enrichment\")\n",
    "cand.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neue MD5-basierte File-IDs testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking ID consistency...\n",
      "\n",
      "üìã Sample ID mapping:\n",
      "   fallingSpheres_0401.tif ‚Üí 0001615cb891ac0f\n",
      "   fluid16.jpg ‚Üí 00084414b2765927\n",
      "   fallingSpheres_1677.tif ‚Üí 00148359ca3be9a7\n",
      "‚úÖ 6516 file URIs ready for XMP processing\n",
      "üìä MD5-Hash-Mapping erstellt f√ºr 0 Dateien\n",
      "   Beispiele: []\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# ID-KONSISTENZ: RDF FILE-URI zu MD5 MAPPING\n",
    "# =====================================================\n",
    "\n",
    "# Extrahiere MD5-Hash aus file_uri f√ºr Konsistenz-Check\n",
    "def extract_md5_from_uri(file_uri: str) -> str:\n",
    "    \"\"\"Extrahiert MD5[:16] aus dca-id:file_<md5> URI\"\"\"\n",
    "    if \"file_\" in file_uri:\n",
    "        return file_uri.split(\"file_\")[-1]\n",
    "    return None\n",
    "\n",
    "# MD5-Konsistenz pr√ºfen\n",
    "print(\"üîç Checking ID consistency...\")\n",
    "cand[\"md5_from_uri\"] = cand[\"file_uri\"].apply(extract_md5_from_uri)\n",
    "\n",
    "# Beispiel-IDs zeigen\n",
    "print(\"\\nüìã Sample ID mapping:\")\n",
    "for _, row in cand.head(3).iterrows():\n",
    "    print(f\"   {row['title']} ‚Üí {row['md5_from_uri']}\")\n",
    "\n",
    "print(f\"‚úÖ {len(cand)} file URIs ready for XMP processing\")\n",
    "\n",
    "# Erstelle path_to_md5 Mapping aus der RDF (falls MD5-Hashes in PREMIS vorhanden sind)\n",
    "# Das ist ein Fallback, falls keine DROID CSV verf√ºgbar ist\n",
    "path_to_md5 = {}\n",
    "print(f\"üìä MD5-Hash-Mapping erstellt f√ºr {len(path_to_md5)} Dateien\")\n",
    "print(f\"   Beispiele: {list(path_to_md5.items())[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing neue MD5-basierte File-URI Generierung:\n",
      "\n",
      "‚ö†Ô∏è  Fallback zu Pfad-Hash f√ºr: /home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/https:/nextcloud.ethz.ch/remote.php/dav/files/padrian/DCA/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/04_Entwurf/060730_FinalDesignDocumentation/02_Movies/01_RawMaterial/01_FallingSpheres/fallingSpheres_0401.tif\n",
      "üìÅ Datei: fallingSpheres_0401.tif\n",
      "   MD5: None\n",
      "   ALT: file_a77661193869a6e7\n",
      "   NEU: file_a77661193869a6e7\n",
      "   ‚úÖ Verschiedene IDs: False\n",
      "\n",
      "‚ö†Ô∏è  Fallback zu Pfad-Hash f√ºr: /home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/https:/nextcloud.ethz.ch/remote.php/dav/files/padrian/DCA/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/03_Plaene/01_dFab/060607_Fassadenstudie/060606_maps/fluid16.jpg\n",
      "üìÅ Datei: fluid16.jpg\n",
      "   MD5: None\n",
      "   ALT: file_f635187cc02aaa19\n",
      "   NEU: file_f635187cc02aaa19\n",
      "   ‚úÖ Verschiedene IDs: False\n",
      "\n",
      "‚ö†Ô∏è  Fallback zu Pfad-Hash f√ºr: /home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/https:/nextcloud.ethz.ch/remote.php/dav/files/padrian/DCA/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/04_Entwurf/060730_FinalDesignDocumentation/02_Movies/01_RawMaterial/01_FallingSpheres/fallingSpheres_1677.tif\n",
      "üìÅ Datei: fallingSpheres_1677.tif\n",
      "   MD5: None\n",
      "   ALT: file_dd672bbd524e20f3\n",
      "   NEU: file_dd672bbd524e20f3\n",
      "   ‚úÖ Verschiedene IDs: False\n",
      "\n",
      "‚ö†Ô∏è  Fallback zu Pfad-Hash f√ºr: /home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/https:/nextcloud.ethz.ch/remote.php/dav/files/padrian/DCA/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/04_Entwurf/060730_FinalDesignDocumentation/02_Movies/01_RawMaterial/01_FallingSpheres/fallingSpheres_0574.tif\n",
      "üìÅ Datei: fallingSpheres_0574.tif\n",
      "   MD5: None\n",
      "   ALT: file_50f65e5498933541\n",
      "   NEU: file_50f65e5498933541\n",
      "   ‚úÖ Verschiedene IDs: False\n",
      "\n",
      "‚ö†Ô∏è  Fallback zu Pfad-Hash f√ºr: /home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/https:/nextcloud.ethz.ch/remote.php/dav/files/padrian/DCA/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/03_Plaene/01_dFab/060607_Fassadenstudie/060606_maps/fluid10.jpg\n",
      "üìÅ Datei: fluid10.jpg\n",
      "   MD5: None\n",
      "   ALT: file_7c017ee648cd37c8\n",
      "   NEU: file_7c017ee648cd37c8\n",
      "   ‚úÖ Verschiedene IDs: False\n",
      "\n",
      "üìà Statistik:\n",
      "   Dateien mit MD5: 0/5\n",
      "   MD5-basierte URIs: 0\n"
     ]
    }
   ],
   "source": [
    "# Test der neuen MD5-basierten File-URIs\n",
    "print(\"üß™ Testing neue MD5-basierte File-URI Generierung:\\n\")\n",
    "\n",
    "# Teste mit ein paar Beispieldateien\n",
    "test_files = cand[\"ABS_PATH\"].head(5).tolist()\n",
    "for file_path in test_files:\n",
    "    md5_hash = md5_for_abs_path(file_path)\n",
    "    old_uri = URIRef(DCA_ID_BASE + f\"file_{hashlib.sha256(file_path.encode('utf-8')).hexdigest()[:16]}\")\n",
    "    new_uri = dca_file_uri_from_path(file_path)\n",
    "    \n",
    "    print(f\"üìÅ Datei: {Path(file_path).name}\")\n",
    "    print(f\"   MD5: {md5_hash[:16] if md5_hash else 'None'}\")\n",
    "    print(f\"   ALT: {str(old_uri).split('/')[-1]}\")\n",
    "    print(f\"   NEU: {str(new_uri).split('/')[-1]}\")\n",
    "    print(f\"   ‚úÖ Verschiedene IDs: {str(old_uri) != str(new_uri)}\")\n",
    "    print()\n",
    "\n",
    "print(f\"üìà Statistik:\")\n",
    "print(f\"   Dateien mit MD5: {len([p for p in test_files if md5_for_abs_path(p)])}/{len(test_files)}\")\n",
    "print(f\"   MD5-basierte URIs: {len([dca_file_uri_from_path(p) for p in test_files if md5_for_abs_path(p)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ú® Neue MD5-basierte File-IDs\n",
    "\n",
    "**Wichtige √Ñnderung**: Anstatt Pfad-basierter Hashes verwenden wir jetzt die MD5-Hashes aus dem DROID CSV:\n",
    "\n",
    "### Vorteile:\n",
    "- **Konsistent**: Gleiche Datei = Gleiche ID (unabh√§ngig vom Pfad)  \n",
    "- **Plattform-unabh√§ngig**: Windows vs Unix Pfade irrelevant\n",
    "- **Inhalt-basiert**: Nur Datei√§nderungen erzeugen neue IDs\n",
    "- **DROID-integriert**: Nutzt bereits berechnete Hashes\n",
    "\n",
    "### Implementierung:\n",
    "```python\n",
    "# ALT: Pfad ‚Üí SHA256[:16]\n",
    "old_id = \"file_\" + hashlib.sha256(path.encode()).hexdigest()[:16]\n",
    "\n",
    "# NEU: DROID MD5[:16] \n",
    "new_id = \"file_\" + droid_record.hash_md5[:16]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXIF/XMP an einer Beispiel‚ÄëPSD auslesen (inkl. IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei: /home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/https:/nextcloud.ethz.ch/remote.php/dav/files/padrian/DCA/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/03_Plaene/01_dFab/060612_Fassadenstudie/model/02.psd\n",
      "[]\n",
      "\n",
      "Hinweis:\n",
      "- XMP-xmpMM:DocumentID      = Stabiler Dokument-Identifier\n",
      "- XMP-xmpMM:InstanceID      = Jede Revision/Instanz hat eine neue ID\n",
      "- XMP-xmpMM:DerivedFrom*    = Verkn√ºpft auf Quelle/Parent (Ableitung)\n"
     ]
    }
   ],
   "source": [
    "# Eine Beispiel-PSD aus dem gefilterten DataFrame\n",
    "ex_psd = cand[cand[\"EXT\"] == \"psd\"].head(1)\n",
    "if ex_psd.empty:\n",
    "    print(\"Keine PSD gefunden ‚Äì bitte eine PSD im Bestand w√§hlen.\")\n",
    "else:\n",
    "    psd_path = ex_psd[\"ABS_PATH\"].iloc[0]\n",
    "    data = run_exiftool_json([psd_path])\n",
    "    print(\"Datei:\", psd_path)\n",
    "    print(json.dumps(data, indent=2))\n",
    "    # Interpretation f√ºr Einsteiger (kurze Erkl√§rung):\n",
    "    print(\"\\nHinweis:\")\n",
    "    print(\"- XMP-xmpMM:DocumentID      = Stabiler Dokument-Identifier\")\n",
    "    print(\"- XMP-xmpMM:InstanceID      = Jede Revision/Instanz hat eine neue ID\")\n",
    "    print(\"- XMP-xmpMM:DerivedFrom*    = Verkn√ºpft auf Quelle/Parent (Ableitung)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXIF/XMP an einer Beispiel‚ÄëJPG auslesen (inkl. IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei: /home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/https:/nextcloud.ethz.ch/remote.php/dav/files/padrian/DCA/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/03_Plaene/01_dFab/060607_Fassadenstudie/060606_maps/fluid16.jpg\n",
      "[]\n",
      "\n",
      "Hinweis:\n",
      "- Bei JPG sind XMP-IDs nicht immer gesetzt; wenn vorhanden, nutzen wir sie wie bei PSD.\n"
     ]
    }
   ],
   "source": [
    "# Eine Beispiel-JPG\n",
    "ex_jpg = cand[cand[\"EXT\"].isin([\"jpg\",\"jpeg\"])].head(1)\n",
    "if ex_jpg.empty:\n",
    "    print(\"Keine JPG/JPEG gefunden ‚Äì bitte ein Beispiel w√§hlen.\")\n",
    "else:\n",
    "    jpg_path = ex_jpg[\"ABS_PATH\"].iloc[0]\n",
    "    data = run_exiftool_json([jpg_path])\n",
    "    print(\"Datei:\", jpg_path)\n",
    "    print(json.dumps(data, indent=2))\n",
    "    print(\"\\nHinweis:\")\n",
    "    print(\"- Bei JPG sind XMP-IDs nicht immer gesetzt; wenn vorhanden, nutzen wir sie wie bei PSD.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch‚ÄëAuslesen (XMP‚ÄëIDs) & Index f√ºr Derivatsuche aufbauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/6487\n",
      "200/6487\n",
      "300/6487\n",
      "400/6487\n",
      "500/6487\n",
      "600/6487\n",
      "700/6487\n",
      "800/6487\n",
      "900/6487\n",
      "1000/6487\n",
      "1100/6487\n",
      "1200/6487\n",
      "1300/6487\n",
      "1400/6487\n",
      "1500/6487\n",
      "1600/6487\n",
      "1700/6487\n",
      "1800/6487\n",
      "1900/6487\n",
      "2000/6487\n",
      "2100/6487\n",
      "2200/6487\n",
      "2300/6487\n",
      "2400/6487\n",
      "2500/6487\n",
      "2600/6487\n",
      "2700/6487\n",
      "2800/6487\n",
      "2900/6487\n",
      "3000/6487\n",
      "3100/6487\n",
      "3200/6487\n",
      "3300/6487\n",
      "3400/6487\n",
      "3500/6487\n",
      "3600/6487\n",
      "3700/6487\n",
      "3800/6487\n",
      "3900/6487\n",
      "4000/6487\n",
      "4100/6487\n",
      "4200/6487\n",
      "4300/6487\n",
      "4400/6487\n",
      "4500/6487\n",
      "4600/6487\n",
      "4700/6487\n",
      "4800/6487\n",
      "4900/6487\n",
      "5000/6487\n",
      "5100/6487\n",
      "5200/6487\n",
      "5300/6487\n",
      "5400/6487\n",
      "5500/6487\n",
      "5600/6487\n",
      "5700/6487\n",
      "5800/6487\n",
      "5900/6487\n",
      "6000/6487\n",
      "6100/6487\n",
      "6200/6487\n",
      "6300/6487\n",
      "6400/6487\n",
      "6487/6487\n",
      "Gelesen: 6487\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceFile</th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>InstanceID</th>\n",
       "      <th>OriginalDocumentID</th>\n",
       "      <th>DerivedFromDocumentID</th>\n",
       "      <th>DerivedFromInstanceID</th>\n",
       "      <th>FileModifyDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>uuid:D9170E74C1CFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:A53BA05DE9CFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>None</td>\n",
       "      <td>uuid:18FD04FBB2CFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:B0B29CD2B8CFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>uuid:12A3774BF0CFDA1186109B3BE9744C33</td>\n",
       "      <td>uuid:53c3d276-af86-430f-b52e-796f0c6a18b8</td>\n",
       "      <td>None</td>\n",
       "      <td>uuid:38614f61-7afe-4454-81d2-8b17e2df8c8f</td>\n",
       "      <td>uuid:07d991a4-40b9-46aa-bebf-1070723b599b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>uuid:C74E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:C84E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>None</td>\n",
       "      <td>uuid:C54E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:C54E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          SourceFile  \\\n",
       "0  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "1  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "2  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "\n",
       "                              DocumentID  \\\n",
       "0  uuid:D9170E74C1CFDA118C30CF8EA9BFE8B1   \n",
       "1  uuid:12A3774BF0CFDA1186109B3BE9744C33   \n",
       "2  uuid:C74E838EEACFDA118C30CF8EA9BFE8B1   \n",
       "\n",
       "                                  InstanceID OriginalDocumentID  \\\n",
       "0      uuid:A53BA05DE9CFDA118C30CF8EA9BFE8B1               None   \n",
       "1  uuid:53c3d276-af86-430f-b52e-796f0c6a18b8               None   \n",
       "2      uuid:C84E838EEACFDA118C30CF8EA9BFE8B1               None   \n",
       "\n",
       "                       DerivedFromDocumentID  \\\n",
       "0      uuid:18FD04FBB2CFDA118C30CF8EA9BFE8B1   \n",
       "1  uuid:38614f61-7afe-4454-81d2-8b17e2df8c8f   \n",
       "2      uuid:C54E838EEACFDA118C30CF8EA9BFE8B1   \n",
       "\n",
       "                       DerivedFromInstanceID FileModifyDate  \n",
       "0      uuid:B0B29CD2B8CFDA118C30CF8EA9BFE8B1           None  \n",
       "1  uuid:07d991a4-40b9-46aa-bebf-1070723b599b           None  \n",
       "2      uuid:C54E838EEACFDA118C30CF8EA9BFE8B1           None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# XMP BATCH-PROCESSING - NUR DATEIEN OHNE BESTEHENDE XMP-DATEN\n",
    "# =====================================================\n",
    "\n",
    "# 1. Pr√ºfe, welche Dateien bereits XMP-Identifier haben\n",
    "print(\"üîç Checking for existing XMP data in RDF...\")\n",
    "existing_xmp_files = set()\n",
    "\n",
    "# SPARQL: Finde Dateien mit XMP-Identifiern\n",
    "xmp_query = \"\"\"\n",
    "    PREFIX premis: <http://www.loc.gov/premis/rdf/v3/>\n",
    "    \n",
    "    SELECT ?file WHERE {\n",
    "        ?file premis:hasIdentifier ?identifier .\n",
    "        ?identifier premis:identifierType ?type .\n",
    "        FILTER(CONTAINS(LCASE(?type), \"xmp\"))\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "for row in graph.query(xmp_query):\n",
    "    existing_xmp_files.add(str(row.file))\n",
    "\n",
    "print(f\"üìä Files with existing XMP: {len(existing_xmp_files)}\")\n",
    "\n",
    "# 2. Filter Kandidaten: Nur Dateien OHNE XMP-Daten und existierende lokale Dateien\n",
    "needs_xmp = cand[\n",
    "    (~cand['file_uri'].isin(existing_xmp_files)) &  # Keine XMP-Daten\n",
    "    (cand['exists'] == True)                        # Datei existiert lokal\n",
    "].copy()\n",
    "\n",
    "print(f\"üìÅ Files needing XMP extraction: {len(needs_xmp):,}\")\n",
    "print(f\"‚è© Files to skip (already have XMP): {len(cand) - len(needs_xmp):,}\")\n",
    "\n",
    "# 3. Batch-Processing Setup\n",
    "BATCH = 50  # Kleinere Batches f√ºr ExifTool\n",
    "records = []\n",
    "processed_count = 0\n",
    "error_count = 0\n",
    "\n",
    "paths = needs_xmp[\"ABS_PATH\"].tolist()\n",
    "\n",
    "if not paths:\n",
    "    print(\"‚úÖ All files already have XMP data - nothing to process!\")\n",
    "else:\n",
    "    print(f\"üîÑ Starting XMP extraction for {len(paths)} files in batches of {BATCH}...\")\n",
    "    total = len(paths)\n",
    "    \n",
    "    for i in range(0, total, BATCH):\n",
    "        batch = paths[i:i+BATCH]\n",
    "        js = run_exiftool_json(batch)\n",
    "        \n",
    "        for row in js:\n",
    "            rec = {\n",
    "                \"SourceFile\": row.get(\"SourceFile\"),\n",
    "                \"DocumentID\": row.get(\"XMP-xmpMM:DocumentID\"),\n",
    "                \"InstanceID\": row.get(\"XMP-xmpMM:InstanceID\"),\n",
    "                \"OriginalDocumentID\": row.get(\"XMP-xmpMM:OriginalDocumentID\"),\n",
    "                \"DerivedFromDocumentID\": row.get(\"XMP-xmpMM:DerivedFromDocumentID\"),\n",
    "                \"DerivedFromInstanceID\": row.get(\"XMP-xmpMM:DerivedFromInstanceID\"),\n",
    "                \"FileModifyDate\": row.get(\"File:FileModifyDate\"),\n",
    "            }\n",
    "            records.append(rec)\n",
    "        \n",
    "        print(f\"   {min(i+BATCH, total)}/{total}\")\n",
    "\n",
    "# DataFrame erstellen\n",
    "xmp_df = pd.DataFrame(records)\n",
    "print(\"Gelesen:\", len(xmp_df))\n",
    "\n",
    "# Indexe zum sp√§teren Matchen aufbauen:\n",
    "# - nach DocumentID und nach InstanceID\n",
    "id_index_doc = (xmp_df[~xmp_df[\"DocumentID\"].isna()]\n",
    "                 .drop_duplicates(subset=[\"DocumentID\"])\n",
    "                 .set_index(\"DocumentID\")[\"SourceFile\"].to_dict())\n",
    "\n",
    "id_index_inst = (xmp_df[~xmp_df[\"InstanceID\"].isna()]\n",
    "                 .drop_duplicates(subset=[\"InstanceID\"])\n",
    "                 .set_index(\"InstanceID\")[\"SourceFile\"].to_dict())\n",
    "\n",
    "xmp_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestehendes RDF laden & Graph vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bestehendes RDF geladen: /home/renku/work/dcaonnextcloud-500gb/dca-metadataraw/WeingutGantenbein/gramazio-kohler-archiv-server_results/gramazio-kohler-archiv-server_DROIDresults.ttl\n",
      "Tripel (vorher): 94173\n"
     ]
    }
   ],
   "source": [
    "# RDF Graph f√ºr XMP-Anreicherung verwenden (von Zelle 5 geladen)\n",
    "# Verwende den bereits geladenen 'graph' von der Pipeline-Integration\n",
    "g = graph  # Verwende den bereits geladenen Graph\n",
    "\n",
    "# Bindings hinzuf√ºgen\n",
    "g.bind(\"dca\", DCA)\n",
    "g.bind(\"dca-id\", DCA_ID)\n",
    "g.bind(\"dca-tech\", DCA_TECH)\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"premis\", PREMIS)\n",
    "g.bind(\"rico\", RICO)\n",
    "g.bind(\"xsd\", XSDNS)\n",
    "\n",
    "print(f\"üîÑ Graph √ºbernommen von Pipeline-Integration\")\n",
    "print(f\"üìä Tripel (vorher XMP-Anreicherung): {len(g):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XMP‚ÄëIdentifier als PREMIS‚ÄëIdentifier anreichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier-Knoten hinzugef√ºgt: 3543\n",
      "Tripel (jetzt): 124263\n"
     ]
    }
   ],
   "source": [
    "# Wir h√§ngen XMP-IDs als PREMIS-Identifier an jede Datei (falls vorhanden).\n",
    "# ‚ú® NEU: Verbindung √ºber dca-id:file_<md5[:16]> statt Pfad-Hash\n",
    "\n",
    "added_ids = 0\n",
    "md5_based_uris = 0\n",
    "path_based_uris = 0\n",
    "\n",
    "for _, row in xmp_df.iterrows():\n",
    "    abs_path = row[\"SourceFile\"]\n",
    "    \n",
    "    # ‚ú® Neue MD5-basierte URI-Generierung\n",
    "    file_uri = dca_file_uri_from_path(abs_path)\n",
    "    \n",
    "    # Statistik sammeln\n",
    "    if md5_for_abs_path(abs_path):\n",
    "        md5_based_uris += 1\n",
    "    else:\n",
    "        path_based_uris += 1\n",
    "\n",
    "    # Sicherstellen, dass Objekt typisiert ist (idR schon vorhanden ‚Äì doppelte Tripel sind ok)\n",
    "    g.add((file_uri, RDF.type, DCA.ArchiveFile))\n",
    "    g.add((file_uri, RDF.type, PREMIS.Object))\n",
    "    g.add((file_uri, RDF.type, RICO.Record))\n",
    "\n",
    "    # XMP IDs als PREMIS Identifier\n",
    "    if row.get(\"DocumentID\"):\n",
    "        add_identifier_triple(g, file_uri, \"XMP DocumentID\", row[\"DocumentID\"]); added_ids += 1\n",
    "    if row.get(\"InstanceID\"):\n",
    "        add_identifier_triple(g, file_uri, \"XMP InstanceID\", row[\"InstanceID\"]); added_ids += 1\n",
    "    if row.get(\"OriginalDocumentID\"):\n",
    "        add_identifier_triple(g, file_uri, \"XMP OriginalDocumentID\", row[\"OriginalDocumentID\"]); added_ids += 1\n",
    "\n",
    "print(\"‚ú® Neue ID-Methode erfolgreich verwendet:\")\n",
    "print(f\"   MD5-basierte URIs: {md5_based_uris}\")\n",
    "print(f\"   Pfad-basierte URIs (Fallback): {path_based_uris}\")\n",
    "print(f\"   Identifier-Knoten hinzugef√ºgt: {added_ids}\")\n",
    "print(f\"   Tripel (jetzt): {len(g)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivations‚ÄëBeziehungen (PREMIS) aus XMP:DerivedFrom ableiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREMIS-Ableitungen erzeugt: 32\n",
      "Nicht aufl√∂sbare Ableitungen: 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'child': '/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/03_Plaene/01_dFab/060419_Praesentation/060419_Plan_2/testtexture.jpg',\n",
       "  'FromDocID': 'uuid:18FD04FBB2CFDA118C30CF8EA9BFE8B1',\n",
       "  'FromInstID': 'uuid:B0B29CD2B8CFDA118C30CF8EA9BFE8B1'},\n",
       " {'child': '/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/03_Plaene/01_dFab/060419_Praesentation/060419_Plan_1/060419_plan1_v03.pdf',\n",
       "  'FromDocID': 'uuid:38614f61-7afe-4454-81d2-8b17e2df8c8f',\n",
       "  'FromInstID': 'uuid:07d991a4-40b9-46aa-bebf-1070723b599b'},\n",
       " {'child': '/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/03_Plaene/01_dFab/060419_Praesentation/060419_Plan_2/060418_Schliessvariante_3.33Seite_12Steine_28Lagen_working_Expression.5.psd',\n",
       "  'FromDocID': 'uuid:C54E838EEACFDA118C30CF8EA9BFE8B1',\n",
       "  'FromInstID': 'uuid:C54E838EEACFDA118C30CF8EA9BFE8B1'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_rel = 0\n",
    "unresolved = []\n",
    "\n",
    "for _, row in xmp_df.iterrows():\n",
    "    child_path = row[\"SourceFile\"]\n",
    "    child_uri  = dca_file_uri_from_path(child_path)\n",
    "\n",
    "    parent_path = None\n",
    "    # 1) Match via DerivedFromDocumentID\n",
    "    if row.get(\"DerivedFromDocumentID\") and row[\"DerivedFromDocumentID\"] in id_index_doc:\n",
    "        parent_path = id_index_doc[row[\"DerivedFromDocumentID\"]]\n",
    "    # 2) sonst via DerivedFromInstanceID\n",
    "    elif row.get(\"DerivedFromInstanceID\") and row[\"DerivedFromInstanceID\"] in id_index_inst:\n",
    "        parent_path = id_index_inst[row[\"DerivedFromInstanceID\"]]\n",
    "\n",
    "    if parent_path:\n",
    "        parent_uri = dca_file_uri_from_path(parent_path)\n",
    "        # Tripel hinzuf√ºgen (beide Richtungen)\n",
    "        g.add((child_uri, PREMIS.hasSource, parent_uri))\n",
    "        g.add((parent_uri, PREMIS.isSourceOf, child_uri))\n",
    "        added_rel += 1\n",
    "    else:\n",
    "        # notieren, wenn eine Ableitung deklariert ist, aber wir kein Gegenst√ºck finden\n",
    "        if row.get(\"DerivedFromDocumentID\") or row.get(\"DerivedFromInstanceID\"):\n",
    "            unresolved.append({\n",
    "                \"child\": child_path,\n",
    "                \"FromDocID\": row.get(\"DerivedFromDocumentID\"),\n",
    "                \"FromInstID\": row.get(\"DerivedFromInstanceID\"),\n",
    "            })\n",
    "\n",
    "print(\"PREMIS-Ableitungen erzeugt:\", added_rel)\n",
    "print(\"Nicht aufl√∂sbare Ableitungen:\", len(unresolved))\n",
    "unresolved[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDF serialisieren (erg√§nzte Fassung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî RDF gespeichert: /home/renku/work/dcaonnextcloud-500gb/dca-metadataraw/WeingutGantenbein/gramazio-kohler-archiv-server_results/gramazio-kohler-archiv-server_catalog_prov.ttl\n",
      "Tripel gesamt: 124327\n"
     ]
    }
   ],
   "source": [
    "g.serialize(destination=str(OUTPUT_RDF_PATH), format=\"turtle\")\n",
    "print(\"‚úî RDF gespeichert:\", OUTPUT_RDF_PATH)\n",
    "print(\"Tripel gesamt:\", len(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPARQL‚ÄëBeispiele (im Graphen) & einfache Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://dca.ethz.ch/id/file_4d96e0aefb434b6aac962086dcf0e4f57601a15d  <--derived--  http://dca.ethz.ch/id/file_d89f18a520f1f18a0c95c736f0e77cae29c0465b\n",
      "http://dca.ethz.ch/id/file_fafde06787ea37a75659cfcd89a44e052995bf07  <--derived--  http://dca.ethz.ch/id/file_301a7a04a505ef4f77f28a2325bc639a7ef930f0\n",
      "http://dca.ethz.ch/id/file_a96f57e0cff78404e1ace2664f8318a28dee350c  <--derived--  http://dca.ethz.ch/id/file_c372ae97eff87606a9ba181560cc681a8276f038\n",
      "http://dca.ethz.ch/id/file_59e225e743ff43a894b335d3d2f5186da3994d2b  <--derived--  http://dca.ethz.ch/id/file_d956de8e85ebcba108d0ca9526210f638109b579\n",
      "http://dca.ethz.ch/id/file_3eea00c0303876c27ca536ad3777d65cea80a4c6  <--derived--  http://dca.ethz.ch/id/file_59e225e743ff43a894b335d3d2f5186da3994d2b\n",
      "http://dca.ethz.ch/id/file_6fcb9b8efedc0042595e06f7007edcd34abac5cb  <--derived--  http://dca.ethz.ch/id/file_3eea00c0303876c27ca536ad3777d65cea80a4c6\n",
      "http://dca.ethz.ch/id/file_b4322649282885172a2183e1f21e25c20d6e0949  <--derived--  http://dca.ethz.ch/id/file_3eea00c0303876c27ca536ad3777d65cea80a4c6\n",
      "http://dca.ethz.ch/id/file_0efa4823c2765c23297e0efcb7b904551fc24f13  <--derived--  http://dca.ethz.ch/id/file_db9c34e46355dd6cfe707b73cad410fcac01dac9\n",
      "http://dca.ethz.ch/id/file_db9c34e46355dd6cfe707b73cad410fcac01dac9  <--derived--  http://dca.ethz.ch/id/file_22dd2ee027932426c4c67caa8ca93717564c498a\n",
      "http://dca.ethz.ch/id/file_589303d6fe39128f2f192ee141312901f665bbb3  <--derived--  http://dca.ethz.ch/id/file_f08f9cd9351dc06e4f9d4af8041a69c8800e10da\n",
      "http://dca.ethz.ch/id/file_ba86c4f8215ed8bf81fe4ffaea84363e3b271ce2  <--derived--  http://dca.ethz.ch/id/file_51bc4d000431050da5b0fceca283ab95ed3a5e09\n",
      "http://dca.ethz.ch/id/file_91e2c73f3bdee8b8b2f56dffc60b12b834079398  <--derived--  http://dca.ethz.ch/id/file_b986be09113d91d5a8c526cd9ce989fe114437b6\n",
      "http://dca.ethz.ch/id/file_4753d60dcc4fe2169c42ebf928bf4b77f163f124  <--derived--  http://dca.ethz.ch/id/file_1b3809860888ea12c0e5412c2495342220e148a8\n",
      "http://dca.ethz.ch/id/file_f4147b2571d3b80730cbf64eed5e9ce3e7572141  <--derived--  http://dca.ethz.ch/id/file_2b5205a38493a6ca7bd448abe94707be89fe2c51\n",
      "http://dca.ethz.ch/id/file_25a041356e953afde46c79a44dbf52ad9452590e  <--derived--  http://dca.ethz.ch/id/file_2b5205a38493a6ca7bd448abe94707be89fe2c51\n",
      "http://dca.ethz.ch/id/file_8831022323d8615355d4fb80b5ba60d27b95222b  <--derived--  http://dca.ethz.ch/id/file_2b5205a38493a6ca7bd448abe94707be89fe2c51\n",
      "http://dca.ethz.ch/id/file_6f8743ceec0fe62f9b3b3e4c5d503a4be7eb9833  <--derived--  http://dca.ethz.ch/id/file_25a041356e953afde46c79a44dbf52ad9452590e\n",
      "http://dca.ethz.ch/id/file_06e6690a38779f2ecec5a585977680ae80e062e1  <--derived--  http://dca.ethz.ch/id/file_f4147b2571d3b80730cbf64eed5e9ce3e7572141\n",
      "http://dca.ethz.ch/id/file_9d0730a443f7c7e5fc4f4e4a215deca8cb2b58b5  <--derived--  http://dca.ethz.ch/id/file_f4147b2571d3b80730cbf64eed5e9ce3e7572141\n",
      "http://dca.ethz.ch/id/file_b5afa7b762fbc463b8792477b196235745443556  <--derived--  http://dca.ethz.ch/id/file_9d0730a443f7c7e5fc4f4e4a215deca8cb2b58b5\n",
      "http://dca.ethz.ch/id/file_8bbbeeec5782b8c1d40122579ba77c4a851375f0  <--derived--  http://dca.ethz.ch/id/file_8111f9c37b75ff3ec5523bc2692346cb0b70d78c\n",
      "http://dca.ethz.ch/id/file_f4f9143a7ba029603a4902b4c59eb7757a30ac51  <--derived--  http://dca.ethz.ch/id/file_8111f9c37b75ff3ec5523bc2692346cb0b70d78c\n",
      "http://dca.ethz.ch/id/file_12fc6621ee8d3aa374df7b410908141015bc6d7e  <--derived--  http://dca.ethz.ch/id/file_4ddf6a4b9325e36ae6cdb08365053203d78972f5\n",
      "http://dca.ethz.ch/id/file_fa54be6e56813f4b982baeb5d7ee6f6bcc56bd61  <--derived--  http://dca.ethz.ch/id/file_4ddf6a4b9325e36ae6cdb08365053203d78972f5\n",
      "http://dca.ethz.ch/id/file_9a19e6a171036ef8994102316dd4e9265a20e44f  <--derived--  http://dca.ethz.ch/id/file_9ed0b9367000f86fd43ca1980bb35a16cc1624fd\n",
      "http://dca.ethz.ch/id/file_45295c4b4b81a3cc929105406be93505f7bc3d26  <--derived--  http://dca.ethz.ch/id/file_9ed0b9367000f86fd43ca1980bb35a16cc1624fd\n",
      "http://dca.ethz.ch/id/file_778c23cbcfa00c0cf5cbf7d6d3ad466d2866d0c0  <--derived--  http://dca.ethz.ch/id/file_101085dc4dcc5db8c8de3af59016de5f0b2788d6\n",
      "http://dca.ethz.ch/id/file_4a350438686d22620a1107a991d135297a9a6b51  <--derived--  http://dca.ethz.ch/id/file_101085dc4dcc5db8c8de3af59016de5f0b2788d6\n",
      "http://dca.ethz.ch/id/file_be399170111ac1efe2460861d01eb0cf549f1eda  <--derived--  http://dca.ethz.ch/id/file_e8e3d86402307c42500d5c6f0a72fa42f9e2f3b6\n",
      "http://dca.ethz.ch/id/file_bc9a625c2ca427ac743a927c206e0fc23866601b  <--derived--  http://dca.ethz.ch/id/file_9176a5c60fbce3e24f4094f4c2637d536e953d7e\n",
      "http://dca.ethz.ch/id/file_9a5a078b48f1962b9e0c28bfea2179ca1007e133  <--derived--  http://dca.ethz.ch/id/file_8bbbeeec5782b8c1d40122579ba77c4a851375f0\n",
      "http://dca.ethz.ch/id/file_9ba8288fc525ffe6a9814150b7c43b252d1b5c34  <--derived--  http://dca.ethz.ch/id/file_7c394dfc0d6643ce2b05a059ffa0e3a3346fc458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(rdflib.term.URIRef('http://dca.ethz.ch/id/file_ba9a8c9b2cf17d3a707e2727792c8c7acfdaedec'),\n",
       "  rdflib.term.Literal('uuid:D9170E74C1CFDA118C30CF8EA9BFE8B1')),\n",
       " (rdflib.term.URIRef('http://dca.ethz.ch/id/file_b0a49b8d769bbd7d477c90b3d8da927d5bfeda11'),\n",
       "  rdflib.term.Literal('uuid:12A3774BF0CFDA1186109B3BE9744C33')),\n",
       " (rdflib.term.URIRef('http://dca.ethz.ch/id/file_baadef14ec9dbb98a6ffb0f9a77d4e4d19a2dbe9'),\n",
       "  rdflib.term.Literal('uuid:C74E838EEACFDA118C30CF8EA9BFE8B1')),\n",
       " (rdflib.term.URIRef('http://dca.ethz.ch/id/file_3c2f23ca113671b32fd9581857f5a6eea5648430'),\n",
       "  rdflib.term.Literal('uuid:83FA0ACCECCFDA118F56F7E076900BAC')),\n",
       " (rdflib.term.URIRef('http://dca.ethz.ch/id/file_2e07589df1da1caba87335d6cb2b375c46351974'),\n",
       "  rdflib.term.Literal('uuid:96dab556-46bb-46d6-9077-e5f9d99616c4'))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Alle Derivationen (Child -> Parent)\n",
    "q1 = \"\"\"\n",
    "PREFIX premis: <http://www.loc.gov/premis/rdf/v3/>\n",
    "SELECT ?child ?parent WHERE {\n",
    "  ?child premis:hasSource ?parent .\n",
    "} LIMIT 50\n",
    "\"\"\"\n",
    "for row in g.query(q1):\n",
    "    print(row.child, \" <--derived-- \", row.parent)\n",
    "\n",
    "# 2) Alle Objekte mit XMP DocumentID\n",
    "q2 = \"\"\"\n",
    "PREFIX premis: <http://www.loc.gov/premis/rdf/v3/>\n",
    "SELECT ?obj ?val WHERE {\n",
    "  ?obj premis:hasIdentifier ?id .\n",
    "  ?id premis:identifierType \"XMP DocumentID\" ;\n",
    "      premis:identifierValue ?val .\n",
    "} LIMIT 50\n",
    "\"\"\"\n",
    "list(g.query(q2))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping RDF‚ÄëURI ‚Üí Dateiname/Tooltip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# --- 1) Map aus XMP-Ergebnissen (bevorzugt, weil garantiert aktueller Pfad) ---\n",
    "uri_to_label = {}\n",
    "uri_to_title = {}\n",
    "\n",
    "if not xmp_df.empty:\n",
    "    for _, r in xmp_df.iterrows():\n",
    "        src = r.get(\"SourceFile\")\n",
    "        if not src:\n",
    "            continue\n",
    "        file_uri = dca_file_uri_from_path(src)\n",
    "        uri_to_label[str(file_uri)] = Path(src).name                # z.B. \"testtexture.jpg\"\n",
    "        uri_to_title[str(file_uri)] = src                           # Tooltip: voller Pfad\n",
    "\n",
    "# --- 2) Fallback: aus Kandidaten-DataFrame (cand) ---\n",
    "# cand enth√§lt: ABS_PATH, title, identifier\n",
    "for _, r in cand.iterrows():\n",
    "    abs_path = r[\"ABS_PATH\"]\n",
    "    file_uri = dca_file_uri_from_path(abs_path)\n",
    "    uri_s = str(file_uri)\n",
    "    if uri_s not in uri_to_label:\n",
    "        uri_to_label[uri_s] = r.get(\"title\", Path(abs_path).name)    # \"title\" aus RDF, sonst aus Pfad\n",
    "    if uri_s not in uri_to_title:\n",
    "        uri_to_title[uri_s] = abs_path\n",
    "\n",
    "# --- 3) Sicherheits-Fallback (sollte kaum noch greifen) ---\n",
    "def label_for(uri: str) -> str:\n",
    "    return uri_to_label.get(uri, uri.split(\"/\")[-1])  # allerletztes Segment der URI\n",
    "\n",
    "def title_for(uri: str) -> str:\n",
    "    return uri_to_title.get(uri, uri)                 # Tooltip im Zweifel die URI selbst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: Graphische Darstellung der Ableitungs‚ÄëKanten (PREMIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knoten: 49 Kanten: 32\n",
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "derivations_graph.html\n",
      "‚úî Visualisierung gespeichert: derivations_graph.html\n"
     ]
    }
   ],
   "source": [
    "# --- Bonus: Graphische Darstellung der Ableitungs-Kanten (PREMIS) mit Dateinamen-Labels ---\n",
    "import networkx as nx\n",
    "\n",
    "# DiGraph Parent -> Child (isSourceOf-Richtung)\n",
    "G = nx.DiGraph()\n",
    "for (s, p, o) in g.triples((None, PREMIS.hasSource, None)):\n",
    "    # s = child, o = parent; Kante Parent -> Child\n",
    "    G.add_edge(str(o), str(s))\n",
    "\n",
    "print(\"Knoten:\", G.number_of_nodes(), \"Kanten:\", G.number_of_edges())\n",
    "\n",
    "# Versuche pyvis f√ºr HTML-Visualisierung\n",
    "try:\n",
    "    from pyvis.network import Network\n",
    "    net = Network(height=\"700px\", width=\"100%\", directed=True, notebook=True)\n",
    "    net.toggle_physics(True)\n",
    "\n",
    "    # Knoten mit Dateinamen als Label + vollem Pfad als Tooltip\n",
    "    for n in G.nodes:\n",
    "        net.add_node(\n",
    "            n,\n",
    "            label=label_for(n),          # z. B. \"testtexture.jpg\"\n",
    "            title=title_for(n),          # Tooltip: absoluter Pfad\n",
    "            shape=\"dot\",\n",
    "            size=12\n",
    "        )\n",
    "\n",
    "    # Kanten mit sprechender Beschriftung\n",
    "    for u, v in G.edges:\n",
    "        net.add_edge(u, v, title=\"premis:isSourceOf / premis:hasSource\", arrows=\"to\")\n",
    "\n",
    "    net.show(\"derivations_graph.html\")\n",
    "    print(\"‚úî Visualisierung gespeichert: derivations_graph.html\")\n",
    "except Exception as e:\n",
    "    print(\"Hinweis: F√ºr HTML-Graph bitte 'pyvis' installieren. Fehler:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Export der finalen erweiterten RDF\n",
    "\n",
    "**Pipeline-Integration:** Hier exportieren wir die mit XMP-Daten angereicherte RDF zur√ºck f√ºr weitere ETH DCA Verarbeitung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# PIPELINE FINALISIERUNG: ERWEITERTE RDF EXPORTIEREN\n",
    "# =====================================================\n",
    "\n",
    "# 1. Finale Statistiken vor Export\n",
    "final_triples = len(graph)\n",
    "added_triples = final_triples - original_triples\n",
    "print(f\"üìà Final Pipeline Statistics:\")\n",
    "print(f\"   Original triples: {original_triples:,}\")\n",
    "print(f\"   Final triples:    {final_triples:,}\")\n",
    "print(f\"   Added triples:    {+added_triples:,} ({added_triples/original_triples*100:+.1f}%)\")\n",
    "\n",
    "# 2. Export der erweiterten RDF \n",
    "print(f\"üíæ Exporting enriched RDF to: {OUTPUT_RDF_PATH}\")\n",
    "graph.serialize(destination=OUTPUT_RDF_PATH, format='turtle')\n",
    "exported_size = OUTPUT_RDF_PATH.stat().st_size / 1024 / 1024\n",
    "print(f\"‚úÖ Exported: {exported_size:.2f} MB\")\n",
    "\n",
    "# 3. Validation Export\n",
    "try:\n",
    "    # Test-Load der exportierten RDF\n",
    "    test_graph = Graph()\n",
    "    test_graph.parse(OUTPUT_RDF_PATH, format='turtle')\n",
    "    test_triples = len(test_graph)\n",
    "    print(f\"‚úÖ Export validation: {test_triples:,} triples loaded successfully\")\n",
    "    \n",
    "    if test_triples == final_triples:\n",
    "        print(\"‚úÖ Pipeline ERFOLGREICH! RDF bereit f√ºr ETH DCA Integration\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Mismatch: Expected {final_triples}, got {test_triples}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Export validation failed: {e}\")\n",
    "\n",
    "# 4. Pipeline-Zusammenfassung\n",
    "print(f\"\\nüéØ PIPELINE OUTPUTS:\")\n",
    "print(f\"   üì• Input:     {INPUT_RDF_PATH} ({BACKUP_RDF_PATH.stat().st_size/1024/1024:.1f}MB)\")\n",
    "print(f\"   üíæ Backup:    {BACKUP_RDF_PATH}\")\n",
    "print(f\"   üì§ Output:    {OUTPUT_RDF_PATH} ({exported_size:.1f}MB)\")\n",
    "print(f\"   üìä Processed: {len(cand)} candidate files\")\n",
    "print(f\"   ‚úÖ Pipeline:  RenkuLab ‚Üí XMP ‚Üí ETH DCA ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
