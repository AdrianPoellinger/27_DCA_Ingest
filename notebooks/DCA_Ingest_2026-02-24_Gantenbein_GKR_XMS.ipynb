{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XMP-x]         XMPToolkit                      : 3.1.1-112\n",
      "[XMP-xmpMM]     DocumentID                      : uuid:11B81C2FCA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     InstanceID                      : uuid:12B81C2FCA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     DerivedFromInstanceID           : uuid:0E1E7741BA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     DerivedFromDocumentID           : uuid:0D1E7741BA03DB11958680BA79BAC3A6\n",
      "[XMP-xmp]       CreateDate                      : 2006:06:24 23:41:53+02:00\n",
      "[XMP-xmp]       ModifyDate                      : 2006:06:24 23:41:53+02:00\n",
      "[XMP-xmp]       MetadataDate                    : 2006:06:24 23:41:53+02:00\n",
      "[XMP-xmp]       CreatorTool                     : Adobe Photoshop CS2 Windows\n",
      "[XMP-dc]        Format                          : image/jpeg\n",
      "[XMP-photoshop] ColorMode                       : RGB\n",
      "[XMP-photoshop] History                         : \n",
      "[XMP-tiff]      Orientation                     : Horizontal (normal)\n",
      "[XMP-tiff]      XResolution                     : 72\n",
      "[XMP-tiff]      YResolution                     : 72\n",
      "[XMP-tiff]      ResolutionUnit                  : inches\n",
      "[XMP-tiff]      NativeDigest                    : 256,257,258,259,262,274,277,284,530,531,282,283,296,301,318,319,529,532,306,270,271,272,305,315,33432;5BC2DF82FA2AFB1D1E542374B1F9349E\n",
      "[XMP-exif]      ExifImageWidth                  : 1270\n",
      "[XMP-exif]      ExifImageHeight                 : 285\n",
      "[XMP-exif]      ColorSpace                      : Unknown (-1)\n",
      "[XMP-exif]      NativeDigest                    : 36864,40960,40961,37121,37122,40962,40963,37510,40964,36867,36868,33434,33437,34850,34852,34855,34856,37377,37378,37379,37380,37381,37382,37383,37384,37385,37386,37396,41483,41484,41486,41487,41488,41492,41493,41495,41728,41729,41730,41985,41986,41987,41988,41989,41990,41991,41992,41993,41994,41995,41996,42016,0,2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,22,23,24,25,26,27,28,30;7C663A56C90A75AFBE90519C14FAE106\n",
      "[XMP-xmpMM]     DocumentID                      : uuid:11B81C2FCA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     InstanceID                      : uuid:12B81C2FCA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     DerivedFromInstanceID           : uuid:0E1E7741BA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     DerivedFromDocumentID           : uuid:0D1E7741BA03DB11958680BA79BAC3A6\n"
     ]
    }
   ],
   "source": [
    "!/home/renku/work/exiftool/exiftool -a -G1 -s -XMP:all -XMP-xmpMM:all \"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/04_Entwurf/060625_FinalDesign/02_Texturen/v1_8_r3_cam1_simplified_inv.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "  \"SourceFile\": \"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/04_Entwurf/060625_FinalDesign/02_Texturen/v1_8_r3_cam1_simplified_inv.jpg\",\n",
      "  \"XMP-x:XMPToolkit\": \"3.1.1-112\",\n",
      "  \"XMP-xmpMM:DocumentID\": \"uuid:11B81C2FCA03DB11958680BA79BAC3A6\",\n",
      "  \"XMP-xmpMM:InstanceID\": \"uuid:12B81C2FCA03DB11958680BA79BAC3A6\",\n",
      "  \"XMP-xmpMM:DerivedFrom\": {\n",
      "    \"DocumentID\": \"uuid:0D1E7741BA03DB11958680BA79BAC3A6\",\n",
      "    \"InstanceID\": \"uuid:0E1E7741BA03DB11958680BA79BAC3A6\"\n",
      "  },\n",
      "  \"XMP-xmp:CreateDate\": \"2006:06:24 23:41:53+02:00\",\n",
      "  \"XMP-xmp:ModifyDate\": \"2006:06:24 23:41:53+02:00\",\n",
      "  \"XMP-xmp:MetadataDate\": \"2006:06:24 23:41:53+02:00\",\n",
      "  \"XMP-xmp:CreatorTool\": \"Adobe Photoshop CS2 Windows\",\n",
      "  \"XMP-dc:Format\": \"image/jpeg\",\n",
      "  \"XMP-photoshop:ColorMode\": \"RGB\",\n",
      "  \"XMP-photoshop:History\": \"\",\n",
      "  \"XMP-tiff:Orientation\": \"Horizontal (normal)\",\n",
      "  \"XMP-tiff:XResolution\": 72,\n",
      "  \"XMP-tiff:YResolution\": 72,\n",
      "  \"XMP-tiff:ResolutionUnit\": \"inches\",\n",
      "  \"XMP-tiff:NativeDigest\": \"256,257,258,259,262,274,277,284,530,531,282,283,296,301,318,319,529,532,306,270,271,272,305,315,33432;5BC2DF82FA2AFB1D1E542374B1F9349E\",\n",
      "  \"XMP-exif:ExifImageWidth\": 1270,\n",
      "  \"XMP-exif:ExifImageHeight\": 285,\n",
      "  \"XMP-exif:ColorSpace\": \"Unknown (-1)\",\n",
      "  \"XMP-exif:NativeDigest\": \"36864,40960,40961,37121,37122,40962,40963,37510,40964,36867,36868,33434,33437,34850,34852,34855,34856,37377,37378,37379,37380,37381,37382,37383,37384,37385,37386,37396,41483,41484,41486,41487,41488,41492,41493,41495,41728,41729,41730,41985,41986,41987,41988,41989,41990,41991,41992,41993,41994,41995,41996,42016,0,2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,22,23,24,25,26,27,28,30;7C663A56C90A75AFBE90519C14FAE106\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "!/home/renku/work/exiftool/exiftool -json -a -G1 -s -struct -XMP:all -XMP-xmpMM:all \"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/04_Entwurf/060625_FinalDesign/02_Texturen/v1_8_r3_cam1_simplified_inv.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/renku/work/.venv/lib/python3.10/site-packages (2.3.3)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tzdata>=2022.7 in /home/renku/work/.venv/lib/python3.10/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/renku/work/.venv/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/renku/work/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: networkx\n",
      "Successfully installed networkx-3.4.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### üìÇ Scanne folgendes Wurzelverzeichnis:\n",
       "`/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üîç Durchsuche Dateien..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚úîÔ∏è Insgesamt gescannt: **12338 Dateien**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚úîÔ∏è Dateien mit XMP-MM-Genealogie: **0**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>documentID</th>\n",
       "      <th>instanceID</th>\n",
       "      <th>parentDocumentID</th>\n",
       "      <th>parentInstanceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file documentID instanceID  \\\n",
       "0   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "1   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "2   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "3   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "4   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "5   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "6   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "7   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "8   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "9   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "10  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "11  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "12  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "13  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "14  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "15  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "16  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "17  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "18  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "19  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "\n",
       "   parentDocumentID parentInstanceID  \n",
       "0              None             None  \n",
       "1              None             None  \n",
       "2              None             None  \n",
       "3              None             None  \n",
       "4              None             None  \n",
       "5              None             None  \n",
       "6              None             None  \n",
       "7              None             None  \n",
       "8              None             None  \n",
       "9              None             None  \n",
       "10             None             None  \n",
       "11             None             None  \n",
       "12             None             None  \n",
       "13             None             None  \n",
       "14             None             None  \n",
       "15             None             None  \n",
       "16             None             None  \n",
       "17             None             None  \n",
       "18             None             None  \n",
       "19             None             None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìå Graph-Statistik"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'nodes': 0, 'edges': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renku/work/.venv/lib/python3.10/site-packages/networkx/readwrite/json_graph/node_link.py:142: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üìÅ Genealogie-Graph gespeichert als `genealogy_graph_xmp_full.json`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## üß¨ Gefundene Herkunftsketten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) KONFIGURATION ‚Äì GANZER NEXTCLOUD-ORDNER\n",
    "# ------------------------------------------------------------\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/\")\n",
    "EXTENSIONS = {\".jpg\", \".jpeg\", \".tif\", \".tiff\", \".png\", \".psd\", \".psb\"}\n",
    "\n",
    "display(Markdown(f\"### üìÇ Scanne folgendes Wurzelverzeichnis:\\n`{ROOT}`\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) EXIFTOOL: ALLE XMP-SEGMENTE AUSLESEN (XMP + APP13/8BIM)\n",
    "# ------------------------------------------------------------\n",
    "def extract_xmpmm(path):\n",
    "    \"\"\"\n",
    "    Extrahiert ALLE XMP-MM Felder aus Standard-XMP + Photoshop APP13/8BIM.\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"/home/renku/work/exiftool/exiftool\",   # Pfad zu deinem ExifTool\n",
    "        \"-a\",                          # alle doppelten Tags anzeigen\n",
    "        \"-G1\",                         # zeigt Segment (XMP, APP1, APP13, etc.)\n",
    "        \"-s\",                          # kurze Tag-Namen\n",
    "        \"-struct\",                     # strukturierte Ausgabe\n",
    "        \"-XMP:all\",                    # ALLE XMP-Namespace-Daten\n",
    "        \"-XMP-xmpMM:all\",              # alle Media-Management-Felder\n",
    "        \"-json\",\n",
    "        str(path)\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        out = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        data = json.loads(out.stdout)[0]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    # M√∂gliche Feld-Namen (wegen unterschiedlicher XMP-Segmente)\n",
    "    keys = data.keys()\n",
    "\n",
    "    def get(*names):\n",
    "        for n in names:\n",
    "            if n in data:\n",
    "                return data[n]\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"file\": str(path),\n",
    "        \"documentID\": get(\"XMP-xmpMM-DocumentID\", \"DocumentID\"),\n",
    "        \"instanceID\": get(\"XMP-xmpMM-InstanceID\", \"InstanceID\"),\n",
    "        \"parentDocumentID\": get(\"XMP-xmpMM-DerivedFromDocumentID\"),\n",
    "        \"parentInstanceID\": get(\"XMP-xmpMM-DerivedFromInstanceID\"),\n",
    "    }\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) SCAN DES GESAMTEN VERZEICHNISSES √úBER WEBDAV\n",
    "# ------------------------------------------------------------\n",
    "display(Markdown(\"### üîç Durchsuche Dateien...\"))\n",
    "\n",
    "records = []\n",
    "count = 0\n",
    "\n",
    "for root, dirs, files in os.walk(ROOT):\n",
    "    for f in files:\n",
    "        p = Path(root) / f\n",
    "        if p.suffix.lower() in EXTENSIONS:\n",
    "            rec = extract_xmpmm(p)\n",
    "            if rec:\n",
    "                records.append(rec)\n",
    "            count += 1\n",
    "\n",
    "display(Markdown(f\"### ‚úîÔ∏è Insgesamt gescannt: **{count} Dateien**\"))\n",
    "display(Markdown(f\"### ‚úîÔ∏è Dateien mit XMP-MM-Genealogie: **{sum(1 for r in records if r['documentID'])}**\"))\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "display(df.head(20))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) GENEALOGIE GRAPH\n",
    "# ------------------------------------------------------------\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    doc = row[\"documentID\"]\n",
    "    parent = row[\"parentDocumentID\"]\n",
    "\n",
    "    if doc:\n",
    "        G.add_node(doc)\n",
    "    if parent:\n",
    "        G.add_node(parent)\n",
    "        G.add_edge(parent, doc)\n",
    "\n",
    "display(Markdown(\"### üìå Graph-Statistik\"))\n",
    "display({\"nodes\": G.number_of_nodes(), \"edges\": G.number_of_edges()})\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) EXPORT GRAPH\n",
    "# ------------------------------------------------------------\n",
    "graph_json = nx.readwrite.json_graph.node_link_data(G)\n",
    "\n",
    "with open(\"genealogy_graph_xmp_full.json\", \"w\") as f:\n",
    "    json.dump(graph_json, f, indent=2)\n",
    "\n",
    "display(Markdown(\"### üìÅ Genealogie-Graph gespeichert als `genealogy_graph_xmp_full.json`\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) ALLE HERKUNFTS-KETTEN AUSGEBEN\n",
    "# ------------------------------------------------------------\n",
    "def print_chains(G):\n",
    "    display(Markdown(\"## üß¨ Gefundene Herkunftsketten\"))\n",
    "    roots = [n for n in G.nodes if G.in_degree(n) == 0]\n",
    "    for r in roots:\n",
    "        chain = list(nx.dfs_preorder_nodes(G, source=r))\n",
    "        print(\" ‚Üí \".join(chain))\n",
    "\n",
    "print_chains(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√ò pro Datei: 340.0 ms\n",
      "Gesamtdateien: 12338 | ETA ‚âà 69.9 Minuten\n"
     ]
    }
   ],
   "source": [
    "import time, itertools, os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/\")\n",
    "EXT = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".psd\",\".psb\"}\n",
    "\n",
    "def iter_files(root, limit=None):\n",
    "    c = 0\n",
    "    for r, d, files in os.walk(root):\n",
    "        for f in files:\n",
    "            if Path(f).suffix.lower() in EXT:\n",
    "                yield Path(r)/f\n",
    "                c += 1\n",
    "                if limit and c >= limit:\n",
    "                    return\n",
    "\n",
    "def exif_call(p):\n",
    "    return subprocess.run(\n",
    "        [\"/home/renku/work/exiftool/exiftool\",\"-a\",\"-G1\",\"-s\",\"-struct\",\"-XMP:all\",\"-XMP-xmpMM:all\",\"-json\",str(p)],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "\n",
    "# 1) Mini-Benchmark √ºber 200 Dateien\n",
    "N = 200\n",
    "files = list(iter_files(ROOT, limit=N))\n",
    "t0 = time.time()\n",
    "for fp in files:\n",
    "    exif_call(fp)\n",
    "t1 = time.time()\n",
    "\n",
    "per_file = (t1 - t0) / max(1, len(files))\n",
    "print(f\"√ò pro Datei: {per_file*1000:.1f} ms\")\n",
    "\n",
    "# 2) Gesamtdateien z√§hlen\n",
    "total = sum(1 for _ in iter_files(ROOT))\n",
    "eta_sec = per_file * total\n",
    "print(f\"Gesamtdateien: {total} | ETA ‚âà {eta_sec/60:.1f} Minuten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 121\u001b[0m\n\u001b[1;32m    119\u001b[0m batch\u001b[38;5;241m.\u001b[39mappend(fp)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m BATCH_SIZE:\n\u001b[0;32m--> 121\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43met_request_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;66;03m# Quelle (immer enthalten)\u001b[39;00m\n\u001b[1;32m    124\u001b[0m         src \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSourceFile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 67\u001b[0m, in \u001b[0;36met_request_json\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m     65\u001b[0m out_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[43m_et_proc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, json, subprocess, threading, queue, sys, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Konfiguration\n",
    "# -----------------------------\n",
    "EXIFTOOL = \"/home/renku/work/exiftool/exiftool\"  # dein ExifTool\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/\")\n",
    "EXTENSIONS = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".psd\",\".psb\"}\n",
    "\n",
    "# Globale Prozess-Referenz\n",
    "_et_proc = None\n",
    "_et_lock = threading.Lock()\n",
    "\n",
    "def start_exiftool():\n",
    "    global _et_proc\n",
    "    if _et_proc is not None:\n",
    "        return\n",
    "    _et_proc = subprocess.Popen(\n",
    "        [EXIFTOOL, \"-stay_open\", \"True\", \"-@\",\"-\"], \n",
    "        stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "        text=True, bufsize=1\n",
    "    )\n",
    "\n",
    "def stop_exiftool():\n",
    "    global _et_proc\n",
    "    if _et_proc is None:\n",
    "        return\n",
    "    try:\n",
    "        _et_proc.stdin.write(\"-stay_open\\nFalse\\n-execute\\n\")\n",
    "        _et_proc.stdin.flush()\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        _et_proc.communicate(timeout=5)\n",
    "    except Exception:\n",
    "        _et_proc.kill()\n",
    "    _et_proc = None\n",
    "\n",
    "def et_request_json(files):\n",
    "    \"\"\"\n",
    "    Schickt eine Anfrage (f√ºr eine oder mehrere Dateien) an den offenen ExifTool-Prozess\n",
    "    und gibt die JSON-Liste zur√ºck.\n",
    "    \"\"\"\n",
    "    global _et_proc\n",
    "    if _et_proc is None:\n",
    "        start_exiftool()\n",
    "    args = [\n",
    "        \"-a\",\"-G1\",\"-s\",\"-struct\",\n",
    "        \"-XMP:all\",\"-XMP-xmpMM:all\",\n",
    "        \"-json\",\n",
    "    ]\n",
    "    # Schreibe Befehle + Dateien\n",
    "    with _et_lock:\n",
    "        for a in args:\n",
    "            _et_proc.stdin.write(a+\"\\n\")\n",
    "        for f in files:\n",
    "            _et_proc.stdin.write(str(f)+\"\\n\")\n",
    "        _et_proc.stdin.write(\"-execute\\n\")\n",
    "        _et_proc.stdin.flush()\n",
    "\n",
    "        # Antworte lesen: Wir wissen, dass -json nur EINEN JSON-Block je -execute schreibt.\n",
    "        # Wir lesen so lange Zeilen, bis JSON ‚Äûvermutlich‚Äú vollst√§ndig ist (endet mit ']').\n",
    "        out_lines = []\n",
    "        while True:\n",
    "            line = _et_proc.stdout.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            out_lines.append(line)\n",
    "            # sehr einfache Heuristik: JSON-Array endet mit ']\\n'\n",
    "            if line.strip().endswith(']'):\n",
    "                break\n",
    "\n",
    "    out = \"\".join(out_lines).strip()\n",
    "    if not out:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        data = json.loads(out)\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        return [data]\n",
    "    except json.JSONDecodeError:\n",
    "        # Zur Diagnose ggf. stderr lesen (nicht zwingend in der Schleife auswerten)\n",
    "        return []\n",
    "\n",
    "def iter_files(root: Path, exts):\n",
    "    for r, d, files in os.walk(root):\n",
    "        for f in files:\n",
    "            p = Path(r)/f\n",
    "            if p.suffix.lower() in exts:\n",
    "                yield p\n",
    "\n",
    "def extract_from_json_item(item: dict):\n",
    "    # JSON-Struktur wie in deinem Beispiel:\n",
    "    # \"XMP-xmpMM:DocumentID\": \"uuid:‚Ä¶\",\n",
    "    # \"XMP-xmpMM:InstanceID\": \"uuid:‚Ä¶\",\n",
    "    # \"XMP-xmpMM:DerivedFrom\": {\"DocumentID\": \"...\", \"InstanceID\": \"...\"}\n",
    "    doc = item.get(\"XMP-xmpMM:DocumentID\") or item.get(\"DocumentID\")\n",
    "    ins = item.get(\"XMP-xmpMM:InstanceID\") or item.get(\"InstanceID\")\n",
    "    parent_doc, parent_ins = None, None\n",
    "    drv = item.get(\"XMP-xmpMM:DerivedFrom\") or item.get(\"DerivedFrom\")\n",
    "    if isinstance(drv, dict):\n",
    "        parent_doc = drv.get(\"DocumentID\") or drv.get(\"documentID\")\n",
    "        parent_ins = drv.get(\"InstanceID\") or drv.get(\"instanceID\")\n",
    "    return doc, ins, parent_doc, parent_ins\n",
    "\n",
    "# -----------------------------\n",
    "# Lauf: Dateien in Batches (Stay-Open bringt hier den Gewinn)\n",
    "# -----------------------------\n",
    "records = []\n",
    "batch = []\n",
    "BATCH_SIZE = 50  # 50‚Äì200: guter Kompromiss WebDAV <-> Antwortgr√∂√üe\n",
    "\n",
    "start_exiftool()\n",
    "try:\n",
    "    for fp in iter_files(ROOT, EXTENSIONS):\n",
    "        batch.append(fp)\n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            data = et_request_json(batch)\n",
    "            for item in data:\n",
    "                # Quelle (immer enthalten)\n",
    "                src = item.get(\"SourceFile\")\n",
    "                doc, ins, pdoc, pins = extract_from_json_item(item)\n",
    "                records.append({\n",
    "                    \"file\": src, \n",
    "                    \"documentID\": doc, \n",
    "                    \"instanceID\": ins, \n",
    "                    \"parentDocumentID\": pdoc, \n",
    "                    \"parentInstanceID\": pins\n",
    "                })\n",
    "            batch.clear()\n",
    "\n",
    "    # Rest\n",
    "    if batch:\n",
    "        data = et_request_json(batch)\n",
    "        for item in data:\n",
    "            src = item.get(\"SourceFile\")\n",
    "            doc, ins, pdoc, pins = extract_from_json_item(item)\n",
    "            records.append({\n",
    "                \"file\": src, \n",
    "                \"documentID\": doc, \n",
    "                \"instanceID\": ins, \n",
    "                \"parentDocumentID\": pdoc, \n",
    "                \"parentInstanceID\": pins\n",
    "            })\n",
    "finally:\n",
    "    stop_exiftool()\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "display(df.head(20))\n",
    "print(\"Mit XMP‚ÄëMM:\", df[\"documentID\"].notna().sum(), \"von\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Testlauf (Stay-Open + Sentinel) f√ºr bis zu 200 Dateien:\n",
      " /home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein\n",
      "üîç Teste jetzt 200 Dateien...\n",
      "‚è±Ô∏è Testlauf Dauer: 48.58 s\n",
      "\n",
      "üß¨ Ergebnis (erste 20 Zeilen):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>documentID</th>\n",
       "      <th>instanceID</th>\n",
       "      <th>parentDocumentID</th>\n",
       "      <th>parentInstanceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>uuid:C74E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:C84E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:C54E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:C54E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>uuid:D9170E74C1CFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:A53BA05DE9CFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:18FD04FBB2CFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:B0B29CD2B8CFDA118C30CF8EA9BFE8B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:da668ae1-f595-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:da668ae7-f595-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:4e2d1ba0-f596-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:4e2d1ba6-f596-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:4e2d1baa-f596-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:93726e95-f596-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:eefb7ae0-f596-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>adobe:docid:photoshop:e7dc0224-3095-11d7-a2ec-...</td>\n",
       "      <td>uuid:e7dc0226-3095-11d7-a2ec-d1fcfb080b2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:eefb7ae6-f596-11da-b021-...</td>\n",
       "      <td>uuid:DEBD576D635FDA118C5D9BB46FE99D01</td>\n",
       "      <td>uuid:9EC36DC4625FDA118C5D9BB46FE99D01</td>\n",
       "      <td>uuid:9DC36DC4625FDA118C5D9BB46FE99D01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:17b71261-f597-11da-b021-...</td>\n",
       "      <td>uuid:1B5FD559645FDA118C5D9BB46FE99D01</td>\n",
       "      <td>uuid:1A5FD559645FDA118C5D9BB46FE99D01</td>\n",
       "      <td>uuid:195FD559645FDA118C5D9BB46FE99D01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:17b71267-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:635644d2-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:635644d8-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:9fbfed83-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:9fbfed89-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:dc420934-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:dc42093a-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:335723a5-f598-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:aac4ade4-f5fb-11da-b848-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file  \\\n",
       "0   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "1   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "2   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "3   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "4   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "5   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "6   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "7   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "8   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "9   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "10  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "11  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "12  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "13  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "14  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "15  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "16  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "17  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "18  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "19  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "\n",
       "                                           documentID  \\\n",
       "0               uuid:C74E838EEACFDA118C30CF8EA9BFE8B1   \n",
       "1               uuid:D9170E74C1CFDA118C30CF8EA9BFE8B1   \n",
       "2   adobe:docid:photoshop:da668ae1-f595-11da-b021-...   \n",
       "3   adobe:docid:photoshop:da668ae7-f595-11da-b021-...   \n",
       "4   adobe:docid:photoshop:4e2d1ba0-f596-11da-b021-...   \n",
       "5   adobe:docid:photoshop:4e2d1ba6-f596-11da-b021-...   \n",
       "6   adobe:docid:photoshop:4e2d1baa-f596-11da-b021-...   \n",
       "7   adobe:docid:photoshop:93726e95-f596-11da-b021-...   \n",
       "8   adobe:docid:photoshop:eefb7ae0-f596-11da-b021-...   \n",
       "9   adobe:docid:photoshop:eefb7ae6-f596-11da-b021-...   \n",
       "10  adobe:docid:photoshop:17b71261-f597-11da-b021-...   \n",
       "11  adobe:docid:photoshop:17b71267-f597-11da-b021-...   \n",
       "12  adobe:docid:photoshop:635644d2-f597-11da-b021-...   \n",
       "13  adobe:docid:photoshop:635644d8-f597-11da-b021-...   \n",
       "14  adobe:docid:photoshop:9fbfed83-f597-11da-b021-...   \n",
       "15  adobe:docid:photoshop:9fbfed89-f597-11da-b021-...   \n",
       "16  adobe:docid:photoshop:dc420934-f597-11da-b021-...   \n",
       "17  adobe:docid:photoshop:dc42093a-f597-11da-b021-...   \n",
       "18  adobe:docid:photoshop:335723a5-f598-11da-b021-...   \n",
       "19  adobe:docid:photoshop:aac4ade4-f5fb-11da-b848-...   \n",
       "\n",
       "                               instanceID  \\\n",
       "0   uuid:C84E838EEACFDA118C30CF8EA9BFE8B1   \n",
       "1   uuid:A53BA05DE9CFDA118C30CF8EA9BFE8B1   \n",
       "2                                    None   \n",
       "3                                    None   \n",
       "4                                    None   \n",
       "5                                    None   \n",
       "6                                    None   \n",
       "7                                    None   \n",
       "8                                    None   \n",
       "9   uuid:DEBD576D635FDA118C5D9BB46FE99D01   \n",
       "10  uuid:1B5FD559645FDA118C5D9BB46FE99D01   \n",
       "11                                   None   \n",
       "12                                   None   \n",
       "13                                   None   \n",
       "14                                   None   \n",
       "15                                   None   \n",
       "16                                   None   \n",
       "17                                   None   \n",
       "18                                   None   \n",
       "19                                   None   \n",
       "\n",
       "                                     parentDocumentID  \\\n",
       "0               uuid:C54E838EEACFDA118C30CF8EA9BFE8B1   \n",
       "1               uuid:18FD04FBB2CFDA118C30CF8EA9BFE8B1   \n",
       "2                                                None   \n",
       "3                                                None   \n",
       "4                                                None   \n",
       "5                                                None   \n",
       "6                                                None   \n",
       "7                                                None   \n",
       "8   adobe:docid:photoshop:e7dc0224-3095-11d7-a2ec-...   \n",
       "9               uuid:9EC36DC4625FDA118C5D9BB46FE99D01   \n",
       "10              uuid:1A5FD559645FDA118C5D9BB46FE99D01   \n",
       "11                                               None   \n",
       "12                                               None   \n",
       "13                                               None   \n",
       "14                                               None   \n",
       "15                                               None   \n",
       "16                                               None   \n",
       "17                                               None   \n",
       "18                                               None   \n",
       "19                                               None   \n",
       "\n",
       "                             parentInstanceID  \n",
       "0       uuid:C54E838EEACFDA118C30CF8EA9BFE8B1  \n",
       "1       uuid:B0B29CD2B8CFDA118C30CF8EA9BFE8B1  \n",
       "2                                        None  \n",
       "3                                        None  \n",
       "4                                        None  \n",
       "5                                        None  \n",
       "6                                        None  \n",
       "7                                        None  \n",
       "8   uuid:e7dc0226-3095-11d7-a2ec-d1fcfb080b2c  \n",
       "9       uuid:9DC36DC4625FDA118C5D9BB46FE99D01  \n",
       "10      uuid:195FD559645FDA118C5D9BB46FE99D01  \n",
       "11                                       None  \n",
       "12                                       None  \n",
       "13                                       None  \n",
       "14                                       None  \n",
       "15                                       None  \n",
       "16                                       None  \n",
       "17                                       None  \n",
       "18                                       None  \n",
       "19                                       None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úîÔ∏è Dateien MIT XMP‚ÄëMM: 146 von 200\n"
     ]
    }
   ],
   "source": [
    "import os, json, subprocess, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/\")\n",
    "EXT = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".psd\",\".psb\"}\n",
    "EXIFTOOL = \"/home/renku/work/exiftool/exiftool\"\n",
    "BATCH_SIZE = 50\n",
    "MAX_TEST = 200  # nur Testlauf; f√ºr Vollscan entfernen/erh√∂hen\n",
    "SENTINEL = \"__END__\"\n",
    "\n",
    "print(\"üìÇ Testlauf (Stay-Open + Sentinel) f√ºr bis zu 200 Dateien:\\n\", ROOT)\n",
    "\n",
    "# Dateien einsammeln (bis MAX_TEST)\n",
    "files = []\n",
    "for root, dirs, filelist in os.walk(ROOT):\n",
    "    for f in filelist:\n",
    "        p = Path(root)/f\n",
    "        if p.suffix.lower() in EXT:\n",
    "            files.append(str(p))\n",
    "            if len(files) >= MAX_TEST:\n",
    "                break\n",
    "    if len(files) >= MAX_TEST:\n",
    "        break\n",
    "\n",
    "print(f\"üîç Teste jetzt {len(files)} Dateien...\")\n",
    "\n",
    "# -----------------------------\n",
    "# ExifTool stay-open starten\n",
    "# -----------------------------\n",
    "et = subprocess.Popen(\n",
    "    [EXIFTOOL, \"-stay_open\", \"True\", \"-@\", \"-\"],\n",
    "    stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "    text=True, bufsize=1\n",
    ")\n",
    "\n",
    "def et_send_batch(batch_files):\n",
    "    \"\"\"\n",
    "    Sendet EINEN Auftrag (Batch) an ExifTool:\n",
    "      - schlanke Argumente (nur xmpMM)\n",
    "      - JSON\n",
    "      - Sentinel als EOT-Marker\n",
    "    Liest stdout bis zum Sentinel, extrahiert den JSON-Block und liefert ihn als Liste zur√ºck.\n",
    "    \"\"\"\n",
    "    # SCHLANKE Argumente: nur xmpMM (schneller & weniger Output)\n",
    "    args = [\"-a\", \"-s\", \"-struct\", \"-XMP-xmpMM:all\", \"-json\"]\n",
    "    for a in args:\n",
    "        et.stdin.write(a + \"\\n\")\n",
    "    for f in batch_files:\n",
    "        et.stdin.write(f + \"\\n\")\n",
    "    # Sentinel vor -execute setzen\n",
    "    et.stdin.write(f\"-echo3\\n{SENTINEL}\\n\")\n",
    "    et.stdin.write(\"-execute\\n\")\n",
    "    et.stdin.flush()\n",
    "\n",
    "    # stdout lesen bis Sentinel gefunden\n",
    "    lines = []\n",
    "    t_start = time.time()\n",
    "    while True:\n",
    "        line = et.stdout.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        # Sentinel erreicht -> Ende der Antwort\n",
    "        if line.strip() == SENTINEL:\n",
    "            break\n",
    "        lines.append(line)\n",
    "\n",
    "    out = \"\".join(lines).strip()\n",
    "    if not out:\n",
    "        return []\n",
    "\n",
    "    # JSON extrahieren (es kann vor/nach JSON noch andere Zeilen geben; wir finden den JSON-Array-Block)\n",
    "    # Wir suchen den ersten '[' und das letzte ']'\n",
    "    start = out.find('[')\n",
    "    end   = out.rfind(']')\n",
    "    if start == -1 or end == -1 or end < start:\n",
    "        # Diagnose: zeige kurze Vorschau\n",
    "        print(\"‚ö†Ô∏è Konnte JSON-Block nicht isolieren. Vorschau:\", out[:400])\n",
    "        return []\n",
    "\n",
    "    json_str = out[start:end+1]\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        return data if isinstance(data, list) else [data]\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"‚ö†Ô∏è JSONDecodeError:\", e)\n",
    "        print(\"Vorschau:\", json_str[:400])\n",
    "        return []\n",
    "\n",
    "def et_close():\n",
    "    try:\n",
    "        et.stdin.write(\"-stay_open\\nFalse\\n-execute\\n\")\n",
    "        et.stdin.flush()\n",
    "        et.communicate(timeout=3)\n",
    "    except Exception:\n",
    "        et.kill()\n",
    "\n",
    "# -----------------------------\n",
    "# Batchweise abarbeiten\n",
    "# -----------------------------\n",
    "records = []\n",
    "t0 = time.time()\n",
    "\n",
    "try:\n",
    "    for i in range(0, len(files), BATCH_SIZE):\n",
    "        batch = files[i:i+BATCH_SIZE]\n",
    "        data  = et_send_batch(batch)\n",
    "        # pro Batch extrahieren\n",
    "        for item in data:\n",
    "            src = item.get(\"SourceFile\")\n",
    "            doc = item.get(\"XMP-xmpMM:DocumentID\") or item.get(\"DocumentID\")\n",
    "            ins = item.get(\"XMP-xmpMM:InstanceID\") or item.get(\"InstanceID\")\n",
    "            pdoc = pins = None\n",
    "            drv = item.get(\"XMP-xmpMM:DerivedFrom\") or item.get(\"DerivedFrom\")\n",
    "            if isinstance(drv, dict):\n",
    "                pdoc = drv.get(\"DocumentID\") or drv.get(\"documentID\")\n",
    "                pins = drv.get(\"InstanceID\") or drv.get(\"instanceID\")\n",
    "            records.append({\n",
    "                \"file\": src,\n",
    "                \"documentID\": doc,\n",
    "                \"instanceID\": ins,\n",
    "                \"parentDocumentID\": pdoc,\n",
    "                \"parentInstanceID\": pins\n",
    "            })\n",
    "finally:\n",
    "    et_close()\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"‚è±Ô∏è Testlauf Dauer: {t1-t0:.2f} s\")\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(\"\\nüß¨ Ergebnis (erste 20 Zeilen):\")\n",
    "display(df.head(20))\n",
    "print(\"\\n‚úîÔ∏è Dateien MIT XMP‚ÄëMM:\", df[\"documentID\"].notna().sum() if \"documentID\" in df.columns else 0, \"von\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def norm_id(raw: str|None) -> str|None:\n",
    "    \"\"\"\n",
    "    Normalisiert Document/Instance-IDs:\n",
    "    - trimmt Leerzeichen\n",
    "    - bel√§sst 'uuid:' und 'adobe:docid:photoshop:' Pr√§fixe (wichtig f√ºr Eindeutigkeit)\n",
    "    - wandelt in lowercase f√ºr stabile Vergleiche\n",
    "    \"\"\"\n",
    "    if not raw: \n",
    "        return None\n",
    "    s = raw.strip()\n",
    "    return s.lower()\n",
    "\n",
    "def extract_from_item(item: dict):\n",
    "    \"\"\"\n",
    "    Holt IDs aus der JSON-Struktur (wie in deiner Beispielausgabe):\n",
    "      - XMP-xmpMM:DocumentID\n",
    "      - XMP-xmpMM:InstanceID\n",
    "      - XMP-xmpMM:DerivedFrom{DocumentID,InstanceID}\n",
    "    und normalisiert sie.\n",
    "    \"\"\"\n",
    "    src = item.get(\"SourceFile\")\n",
    "    doc = item.get(\"XMP-xmpMM:DocumentID\") or item.get(\"DocumentID\")\n",
    "    ins = item.get(\"XMP-xmpMM:InstanceID\") or item.get(\"InstanceID\")\n",
    "\n",
    "    pdoc = pins = None\n",
    "    drv = item.get(\"XMP-xmpMM:DerivedFrom\") or item.get(\"DerivedFrom\")\n",
    "    if isinstance(drv, dict):\n",
    "        pdoc = drv.get(\"DocumentID\") or drv.get(\"documentID\")\n",
    "        pins = drv.get(\"InstanceID\") or drv.get(\"instanceID\")\n",
    "\n",
    "    return {\n",
    "        \"file\": src,\n",
    "        \"documentID\": norm_id(doc),\n",
    "        \"instanceID\": norm_id(ins),\n",
    "        \"parentDocumentID\": norm_id(pdoc),\n",
    "        \"parentInstanceID\": norm_id(pins),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Zu scannen:** 12338 Dateien"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12338/12338  |  5.12 Dateien/s  |  ETA 0.0 min\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Mit XMP‚ÄëMM:** 6079 / 12338"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Graph:** 5992 Knoten, 59 Kanten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV ‚Üí genealogy_full.csv\n",
      "Graph JSON ‚Üí genealogy_full_graph.json\n",
      "Gefundene Wurzeln: 5933 (zeige bis zu 5)\n",
      "uuid:c54e838eeacfda118c30cf8ea9bfe8b1 ‚Üí uuid:c74e838eeacfda118c30cf8ea9bfe8b1\n",
      "uuid:18fd04fbb2cfda118c30cf8ea9bfe8b1 ‚Üí uuid:d9170e74c1cfda118c30cf8ea9bfe8b1\n",
      "adobe:docid:photoshop:da668ae1-f595-11da-b021-8ba1b752bf42\n",
      "adobe:docid:photoshop:da668ae7-f595-11da-b021-8ba1b752bf42\n",
      "adobe:docid:photoshop:4e2d1ba0-f596-11da-b021-8ba1b752bf42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renku/work/.venv/lib/python3.10/site-packages/networkx/readwrite/json_graph/node_link.py:142: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, json, subprocess, time, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from IPython.display import display, Markdown\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "# ---------- Konfiguration ----------\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein\")\n",
    "EXT = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".psd\",\".psb\"}\n",
    "EXIFTOOL = \"/home/renku/work/exiftool/exiftool\"\n",
    "SENTINEL = \"__END__\"\n",
    "BATCH_SIZE = 100          # 50‚Äì200 sind oft gut. Bei Timeout: kleiner w√§hlen.\n",
    "FAST = False              # True ‚Üí add -fast f√ºr Minimal‚ÄëI/O\n",
    "OUT_PREFIX = \"genealogy_full\"\n",
    "\n",
    "# ---------- Dateien einsammeln ----------\n",
    "files = []\n",
    "for r, d, flist in os.walk(ROOT):\n",
    "    for f in flist:\n",
    "        p = Path(r)/f\n",
    "        if p.suffix.lower() in EXT:\n",
    "            files.append(str(p))\n",
    "total = len(files)\n",
    "display(Markdown(f\"**Zu scannen:** {total} Dateien\"))\n",
    "\n",
    "# ---------- ExifTool Stay‚ÄëOpen starten ----------\n",
    "args = [EXIFTOOL, \"-stay_open\", \"True\", \"-@\", \"-\"]\n",
    "et = subprocess.Popen(args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "                      text=True, bufsize=1)\n",
    "\n",
    "def send_batch(batch_files):\n",
    "    # Schlanke Argumente ‚Äì nur xmpMM, optional -fast\n",
    "    cmd = [\"-a\",\"-s\",\"-struct\",\"-XMP-xmpMM:all\",\"-json\"]\n",
    "    if FAST:\n",
    "        cmd.insert(0, \"-fast\")\n",
    "    for a in cmd:\n",
    "        et.stdin.write(a + \"\\n\")\n",
    "    for f in batch_files:\n",
    "        et.stdin.write(f + \"\\n\")\n",
    "    # Sentinel f√ºr eindeutigen Abschluss\n",
    "    et.stdin.write(f\"-echo3\\n{SENTINEL}\\n\")\n",
    "    et.stdin.write(\"-execute\\n\")\n",
    "    et.stdin.flush()\n",
    "\n",
    "    # stdout bis Sentinel\n",
    "    lines = []\n",
    "    while True:\n",
    "        line = et.stdout.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        if line.strip() == SENTINEL:\n",
    "            break\n",
    "        lines.append(line)\n",
    "\n",
    "    out = \"\".join(lines).strip()\n",
    "    if not out:\n",
    "        return []\n",
    "\n",
    "    # JSON Array isolieren\n",
    "    i, j = out.find('['), out.rfind(']')\n",
    "    if i == -1 or j == -1 or j < i:\n",
    "        # Diagnose: kleine Vorschau\n",
    "        print(\"‚ö†Ô∏è Kein JSON‚ÄëArray erkennbar. Vorschau:\", out[:400])\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        data = json.loads(out[i:j+1])\n",
    "        return data if isinstance(data, list) else [data]\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"‚ö†Ô∏è JSONDecodeError:\", e)\n",
    "        print(\"Vorschau:\", out[max(0, i-100):min(len(out), j+100)])\n",
    "        return []\n",
    "\n",
    "def close_et():\n",
    "    try:\n",
    "        et.stdin.write(\"-stay_open\\nFalse\\n-execute\\n\")\n",
    "        et.stdin.flush()\n",
    "        et.communicate(timeout=3)\n",
    "    except Exception:\n",
    "        et.kill()\n",
    "\n",
    "# ---------- Hauptlauf mit Fortschritt ----------\n",
    "records = []\n",
    "start = time.time()\n",
    "processed = 0\n",
    "\n",
    "try:\n",
    "    for i in range(0, total, BATCH_SIZE):\n",
    "        batch = files[i:i+BATCH_SIZE]\n",
    "        t0 = time.time()\n",
    "        data = send_batch(batch)\n",
    "        for item in data:\n",
    "            rec = extract_from_item(item)\n",
    "            records.append(rec)\n",
    "        processed += len(batch)\n",
    "        # Fortschritt & ETA\n",
    "        elapsed = time.time() - start\n",
    "        rate = processed / elapsed if elapsed > 0 else 0\n",
    "        remain = (total - processed) / rate if rate > 0 else 0\n",
    "        print(f\"\\r{processed}/{total}  |  {rate:.2f} Dateien/s  |  ETA {remain/60:.1f} min\", end=\"\")\n",
    "finally:\n",
    "    close_et()\n",
    "\n",
    "print()  # Zeilenumbruch\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "display(Markdown(f\"**Mit XMP‚ÄëMM:** {(df['documentID'].notna()).sum() if 'documentID' in df.columns else 0} / {len(df)}\"))\n",
    "\n",
    "# ---------- Graph aufbauen ----------\n",
    "G = nx.DiGraph()\n",
    "for _, row in df.iterrows():\n",
    "    doc, parent = row.get(\"documentID\"), row.get(\"parentDocumentID\")\n",
    "    if doc: G.add_node(doc)\n",
    "    if parent: G.add_edge(parent, doc)\n",
    "\n",
    "display(Markdown(f\"**Graph:** {G.number_of_nodes()} Knoten, {G.number_of_edges()} Kanten\"))\n",
    "\n",
    "# ---------- Exporte ----------\n",
    "csv_path = f\"{OUT_PREFIX}.csv\"\n",
    "json_graph_path = f\"{OUT_PREFIX}_graph.json\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "with open(json_graph_path, \"w\") as f:\n",
    "    json.dump(json_graph.node_link_data(G), f, indent=2)\n",
    "print(f\"CSV ‚Üí {csv_path}\")\n",
    "print(f\"Graph JSON ‚Üí {json_graph_path}\")\n",
    "\n",
    "# ---------- Einfache Ketten-Ausgabe ----------\n",
    "def print_chains(G, max_chains=5):\n",
    "    roots = [n for n in G.nodes if G.in_degree(n) == 0]\n",
    "    print(f\"Gefundene Wurzeln: {len(roots)} (zeige bis zu {max_chains})\")\n",
    "    shown = 0\n",
    "    for r in roots:\n",
    "        if shown >= max_chains: break\n",
    "        chain = list(nx.dfs_preorder_nodes(G, source=r))\n",
    "        print(\" ‚Üí \".join(chain[:10]) + (\" ‚Ä¶\" if len(chain) > 10 else \"\"))\n",
    "        shown += 1\n",
    "\n",
    "print_chains(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pfad zu graph hinzuf√ºgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angereichertes JSON: genealogy_full_graph_with_paths.json\n"
     ]
    }
   ],
   "source": [
    "import json, pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "CSV = \"genealogy_full.csv\"\n",
    "JSON_IN  = \"genealogy_full_graph.json\"\n",
    "JSON_OUT = \"genealogy_full_graph_with_paths.json\"\n",
    "\n",
    "# 1) CSV laden, Pfade je documentID sammeln\n",
    "df = pd.read_csv(CSV)\n",
    "paths_by_doc = defaultdict(list)\n",
    "for _, row in df.iterrows():\n",
    "    doc = str(row.get(\"documentID\")).strip().lower() if pd.notna(row.get(\"documentID\")) else None\n",
    "    fp  = row.get(\"file\")\n",
    "    if doc:\n",
    "        paths_by_doc[doc].append(fp)\n",
    "\n",
    "# 2) JSON laden\n",
    "graph = json.load(open(JSON_IN, \"r\"))\n",
    "\n",
    "# 3) Nodes anreichern\n",
    "for n in graph.get(\"nodes\", []):\n",
    "    doc = str(n.get(\"id\")).strip().lower()\n",
    "    files = sorted(set(paths_by_doc.get(doc, [])))\n",
    "    n[\"files\"] = files\n",
    "    n[\"fileCount\"] = len(files)\n",
    "    n[\"fileSample\"] = files[0] if files else None\n",
    "\n",
    "# 4) Schreiben\n",
    "with open(JSON_OUT, \"w\") as f:\n",
    "    json.dump(graph, f, indent=2)\n",
    "\n",
    "print(\"Angereichertes JSON:\", JSON_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Zu scannen:** 12338 Dateien"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12338/12338  |  5.09 Dateien/s  |  ETA 0.0 min\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Mit XMP‚ÄëMM DocumentID:** 6079 / 12338"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Graph:** 5971 Knoten, 65 Kanten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV ‚Üí genealogy_full.csv\n",
      "Graph JSON ‚Üí genealogy_full_graph.json\n",
      "Gefundene Wurzeln: 5906 (zeige bis zu 5)\n",
      "uuid:C74E838EEACFDA118C30CF8EA9BFE8B1\n",
      "uuid:D9170E74C1CFDA118C30CF8EA9BFE8B1\n",
      "adobe:docid:photoshop:93726e95-f596-11da-b021-8ba1b752bf42\n",
      "adobe:docid:photoshop:eefb7ae0-f596-11da-b021-8ba1b752bf42\n",
      "adobe:docid:photoshop:17b71267-f597-11da-b021-8ba1b752bf42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renku/work/.venv/lib/python3.10/site-packages/networkx/readwrite/json_graph/node_link.py:142: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, json, subprocess, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from IPython.display import display, Markdown\n",
    "from networkx.readwrite import json_graph\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------- Konfiguration ----------\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein\")\n",
    "EXT = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".psd\",\".psb\"}\n",
    "EXIFTOOL = \"/home/renku/work/exiftool/exiftool\"\n",
    "SENTINEL = \"__END__\"\n",
    "BATCH_SIZE = 100          # 50‚Äì200 sind oft gut. Bei Timeout: kleiner w√§hlen.\n",
    "FAST = False              # True ‚Üí add -fast f√ºr Minimal‚ÄëI/O\n",
    "OUT_PREFIX = \"genealogy_full\"\n",
    "\n",
    "# (NEU) Priorit√§ten f√ºr Klassen-Zusammenf√ºhrung je Knoten\n",
    "CLASS_PRIORITY = [\n",
    "    \"photoshop_derivative\",\n",
    "    \"photoshop_no_parent\",\n",
    "    \"camera_original\",\n",
    "    \"bridge_or_raw\",\n",
    "    \"unknown\",\n",
    "    \"camera\"  # nur f√ºr Kamera-Knoten selbst\n",
    "]\n",
    "\n",
    "# ---------- Dateien einsammeln ----------\n",
    "files = []\n",
    "for r, d, flist in os.walk(ROOT):\n",
    "    for f in flist:\n",
    "        p = Path(r) / f\n",
    "        if p.suffix.lower() in EXT:\n",
    "            files.append(str(p))\n",
    "total = len(files)\n",
    "display(Markdown(f\"**Zu scannen:** {total} Dateien\"))\n",
    "\n",
    "# ---------- ExifTool Stay‚ÄëOpen starten ----------\n",
    "args = [EXIFTOOL, \"-stay_open\", \"True\", \"-@\", \"-\"]\n",
    "et = subprocess.Popen(\n",
    "    args,\n",
    "    stdin=subprocess.PIPE,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    text=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "def send_batch(batch_files):\n",
    "    \"\"\"\n",
    "    Ruft ExifTool im Stay-Open-Mode auf und liefert die JSON-Objekte f√ºr die Dateien.\n",
    "    (NEU) Abfrage erweitert um EXIF/TIFF/CreatorTool, -G1 f√ºr stabile Feldnamen.\n",
    "    \"\"\"\n",
    "    # Tags minimal & gezielt halten: XMP-xmpMM + EXIF/TIFF + CreatorTool\n",
    "    cmd = [\n",
    "        \"-a\", \"-s\", \"-struct\", \"-G1\", \"-json\",\n",
    "        # MM-Genealogie\n",
    "        \"XMP-xmpMM:all\",\n",
    "        # Kamera-/EXIF-/TIFF\n",
    "        \"EXIF:Make\", \"EXIF:Model\", \"EXIF:DateTimeOriginal\",\n",
    "        \"XMP-tiff:Make\", \"XMP-tiff:Model\",\n",
    "        # CreatorTool (Photoshop/Camera Raw/Bridge)\n",
    "        \"XMP-xmp:CreatorTool\", \"XMP-x:CreatorTool\"\n",
    "    ]\n",
    "    if FAST:\n",
    "        cmd.insert(0, \"-fast\")\n",
    "\n",
    "    # Kommandos schreiben\n",
    "    for a in cmd:\n",
    "        et.stdin.write(a + \"\\n\")\n",
    "    for f in batch_files:\n",
    "        et.stdin.write(f + \"\\n\")\n",
    "    # Sentinel f√ºr eindeutigen Abschluss\n",
    "    et.stdin.write(f\"-echo3\\n{SENTINEL}\\n\")\n",
    "    et.stdin.write(\"-execute\\n\")\n",
    "    et.stdin.flush()\n",
    "\n",
    "    # stdout bis Sentinel\n",
    "    lines = []\n",
    "    while True:\n",
    "        line = et.stdout.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        if line.strip() == SENTINEL:\n",
    "            break\n",
    "        lines.append(line)\n",
    "\n",
    "    out = \"\".join(lines).strip()\n",
    "    if not out:\n",
    "        return []\n",
    "\n",
    "    # JSON Array isolieren\n",
    "    i, j = out.find('['), out.rfind(']')\n",
    "    if i == -1 or j == -1 or j < i:\n",
    "        # Diagnose: kleine Vorschau\n",
    "        print(\"‚ö†Ô∏è Kein JSON‚ÄëArray erkennbar. Vorschau:\", out[:400])\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        data = json.loads(out[i:j+1])\n",
    "        return data if isinstance(data, list) else [data]\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"‚ö†Ô∏è JSONDecodeError:\", e)\n",
    "        print(\"Vorschau:\", out[max(0, i-100):min(len(out), j+100)])\n",
    "        return []\n",
    "\n",
    "def close_et():\n",
    "    try:\n",
    "        et.stdin.write(\"-stay_open\\nFalse\\n-execute\\n\")\n",
    "        et.stdin.flush()\n",
    "        et.communicate(timeout=3)\n",
    "    except Exception:\n",
    "        et.kill()\n",
    "\n",
    "# ---------- (NEU) Extraktion & Klassifikation ----------\n",
    "def extract_from_item(item):\n",
    "    \"\"\"\n",
    "    Extrahiert XMP‚ÄëMM Genealogie + neue Klassifikation + Kamera-Infos.\n",
    "    Erwartete Schl√ºssel (wegen -G1):\n",
    "    - XMP-xmpMM:DocumentID / InstanceID / DerivedFrom:DocumentID / DerivedFrom:InstanceID\n",
    "    - EXIF:Make/Model/DateTimeOriginal, XMP-tiff:Make/Model\n",
    "    - XMP-xmp:CreatorTool oder XMP-x:CreatorTool\n",
    "    \"\"\"\n",
    "    rec = {}\n",
    "\n",
    "    # Basis\n",
    "    rec[\"file\"] = item.get(\"SourceFile\")\n",
    "\n",
    "    # MM-IDs\n",
    "    rec[\"documentID\"]       = item.get(\"XMP-xmpMM:DocumentID\")\n",
    "    rec[\"instanceID\"]       = item.get(\"XMP-xmpMM:InstanceID\")\n",
    "    rec[\"parentDocumentID\"] = item.get(\"XMP-xmpMM:DerivedFrom:DocumentID\")\n",
    "    rec[\"parentInstanceID\"] = item.get(\"XMP-xmpMM:DerivedFrom:InstanceID\")\n",
    "\n",
    "    # Kamera\n",
    "    make  = item.get(\"EXIF:Make\") or item.get(\"XMP-tiff:Make\")\n",
    "    model = item.get(\"EXIF:Model\") or item.get(\"XMP-tiff:Model\")\n",
    "    rec[\"cameraMake\"] = make\n",
    "    rec[\"cameraModel\"] = model\n",
    "\n",
    "    # CreatorTool\n",
    "    creator = item.get(\"XMP-xmp:CreatorTool\") or item.get(\"XMP-x:CreatorTool\") or \"\"\n",
    "    rec[\"creatorTool\"] = creator\n",
    "\n",
    "    # Flags\n",
    "    has_parent = bool(rec[\"parentDocumentID\"] or rec[\"parentInstanceID\"])\n",
    "    has_exif   = bool(make or model or item.get(\"EXIF:DateTimeOriginal\"))\n",
    "\n",
    "    is_photoshop = \"photoshop\" in creator.lower() if creator else False\n",
    "    is_bridgeraw = (not is_photoshop) and has_exif  # Heuristik: XMP/EXIF ja, aber kein PS\n",
    "\n",
    "    # Klasse\n",
    "    if has_parent:\n",
    "        rec[\"class\"] = \"photoshop_derivative\"\n",
    "    elif has_exif and (make or model):\n",
    "        rec[\"class\"] = \"camera_original\"\n",
    "    elif is_photoshop and not has_parent:\n",
    "        rec[\"class\"] = \"photoshop_no_parent\"\n",
    "    elif is_bridgeraw:\n",
    "        rec[\"class\"] = \"bridge_or_raw\"\n",
    "    else:\n",
    "        rec[\"class\"] = \"unknown\"\n",
    "\n",
    "    return rec\n",
    "\n",
    "def pick_class(old_cls, new_cls):\n",
    "    \"\"\"Nimmt die Klasse mit h√∂herer Priorit√§t.\"\"\"\n",
    "    if not old_cls:\n",
    "        return new_cls\n",
    "    try:\n",
    "        return old_cls if CLASS_PRIORITY.index(old_cls) <= CLASS_PRIORITY.index(new_cls) else new_cls\n",
    "    except ValueError:\n",
    "        return old_cls or new_cls\n",
    "\n",
    "# ---------- Hauptlauf mit Fortschritt ----------\n",
    "records = []\n",
    "start = time.time()\n",
    "processed = 0\n",
    "\n",
    "try:\n",
    "    for i in range(0, total, BATCH_SIZE):\n",
    "        batch = files[i:i+BATCH_SIZE]\n",
    "        t0 = time.time()\n",
    "        data = send_batch(batch)\n",
    "        for item in data:\n",
    "            rec = extract_from_item(item)\n",
    "            records.append(rec)\n",
    "        processed += len(batch)\n",
    "        # Fortschritt & ETA\n",
    "        elapsed = time.time() - start\n",
    "        rate = processed / elapsed if elapsed > 0 else 0\n",
    "        remain = (total - processed) / rate if rate > 0 else 0\n",
    "        print(f\"\\r{processed}/{total}  |  {rate:.2f} Dateien/s  |  ETA {remain/60:.1f} min\", end=\"\")\n",
    "finally:\n",
    "    close_et()\n",
    "\n",
    "print()  # Zeilenumbruch\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "with_xmpmm = (df[\"documentID\"].notna()).sum() if \"documentID\" in df.columns else 0\n",
    "display(Markdown(f\"**Mit XMP‚ÄëMM DocumentID:** {with_xmpmm} / {len(df)}\"))\n",
    "\n",
    "# ---------- Graph aufbauen (NEU: Klassen/Files/Kamera-Knoten) ----------\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Node-Aggregate\n",
    "node_files  = defaultdict(set)\n",
    "node_class  = defaultdict(str)\n",
    "\n",
    "# (1) Zuerst alle Bild-Knoten erfassen (documentID oder fallback instanceID)\n",
    "def get_node_id(row):\n",
    "    return row[\"documentID\"] if pd.notna(row.get(\"documentID\")) else row.get(\"instanceID\")\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    node_id = get_node_id(row)\n",
    "    if not node_id:\n",
    "        continue\n",
    "    # Files sammeln\n",
    "    fpath = row.get(\"file\")\n",
    "    if fpath:\n",
    "        node_files[node_id].add(fpath)\n",
    "    # Klasse zusammenf√ºhren\n",
    "    node_class[node_id] = pick_class(node_class[node_id], row.get(\"class\"))\n",
    "\n",
    "# (2) Kamera-Knoten vorbereiten (nur wenn Kamera-Infos vorhanden)\n",
    "def camera_id_from_row(row):\n",
    "    mk, md = row.get(\"cameraMake\"), row.get(\"cameraModel\")\n",
    "    if mk or md:\n",
    "        # Lesbarer, aber stabiler Identifier:\n",
    "        return f\"camera:{(mk or '').strip()}|{(md or '').strip()}\"\n",
    "    return None\n",
    "\n",
    "camera_nodes = set()\n",
    "for _, row in df.iterrows():\n",
    "    cam_id = camera_id_from_row(row)\n",
    "    if cam_id:\n",
    "        camera_nodes.add(cam_id)\n",
    "\n",
    "# (3) Knoten in den Graph schreiben (mit Attributen class, files)\n",
    "for nid in node_files.keys():\n",
    "    G.add_node(nid, **{\n",
    "        \"class\": node_class[nid] or \"unknown\",\n",
    "        \"files\": sorted(node_files[nid])\n",
    "    })\n",
    "\n",
    "# (4) Kamera-Knoten hinzuf√ºgen (class=camera, files=[])\n",
    "for cam in camera_nodes:\n",
    "    if not G.has_node(cam):\n",
    "        G.add_node(cam, **{\"class\": \"camera\", \"files\": []})\n",
    "\n",
    "# (5) Genealogische Kanten (Parent ‚Üí Child)\n",
    "for _, row in df.iterrows():\n",
    "    child = get_node_id(row)\n",
    "    if not child:\n",
    "        continue\n",
    "    # parent via DocumentID / InstanceID\n",
    "    pdoc = row.get(\"parentDocumentID\")\n",
    "    pinst = row.get(\"parentInstanceID\")\n",
    "    # Wir akzeptieren beide, erzeugen die Knoten bei Bedarf mit default-Attributen\n",
    "    for parent in (pdoc, pinst):\n",
    "        if parent and parent != child:\n",
    "            if not G.has_node(parent):\n",
    "                G.add_node(parent, **{\"class\": \"unknown\", \"files\": []})\n",
    "            G.add_edge(parent, child)\n",
    "\n",
    "# (6) Kamera ‚Üí Bild-Kanten f√ºr camera_original\n",
    "for _, row in df.iterrows():\n",
    "    node_id = get_node_id(row)\n",
    "    if not node_id:\n",
    "        continue\n",
    "    if row.get(\"class\") == \"camera_original\":\n",
    "        cam_id = camera_id_from_row(row)\n",
    "        if cam_id:\n",
    "            if not G.has_node(cam_id):\n",
    "                G.add_node(cam_id, **{\"class\": \"camera\", \"files\": []})\n",
    "            G.add_edge(cam_id, node_id)\n",
    "\n",
    "display(Markdown(f\"**Graph:** {G.number_of_nodes()} Knoten, {G.number_of_edges()} Kanten\"))\n",
    "\n",
    "# ---------- Exporte ----------\n",
    "csv_path = f\"{OUT_PREFIX}.csv\"\n",
    "json_graph_path = f\"{OUT_PREFIX}_graph.json\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "with open(json_graph_path, \"w\") as f:\n",
    "    json.dump(json_graph.node_link_data(G), f, indent=2, ensure_ascii=False)\n",
    "print(f\"CSV ‚Üí {csv_path}\")\n",
    "print(f\"Graph JSON ‚Üí {json_graph_path}\")\n",
    "\n",
    "# ---------- Einfache Ketten-Ausgabe ----------\n",
    "def print_chains(G, max_chains=5):\n",
    "    roots = [n for n in G.nodes if G.in_degree(n) == 0]\n",
    "    print(f\"Gefundene Wurzeln: {len(roots)} (zeige bis zu {max_chains})\")\n",
    "    shown = 0\n",
    "    for r in roots:\n",
    "        if shown >= max_chains:\n",
    "            break\n",
    "        chain = list(nx.dfs_preorder_nodes(G, source=r))\n",
    "        # Eine kurze, lesbare Darstellung:\n",
    "        preview = \" ‚Üí \".join(chain[:10]) + (\" ‚Ä¶\" if len(chain) > 10 else \"\")\n",
    "        print(preview)\n",
    "        shown += 1\n",
    "\n",
    "print_chains(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/renku/work/exiftool/exiftool  -v3 \"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/04_Entwurf/060730_FinalDesignDocumentation/02_Movies/01_RawMaterial/01_FallingSpheres/FallingSpheres_jpg/fallingSpheres_0001.jpg\" | grep -A3 \"Quantization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ExifToolVersion = 13.51\n",
      "  FileName = fallingSpheres_0001.tif\n",
      "  Directory = /home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGanten[snip]\n",
      "  FileSize = 3273772\n",
      "  FileModifyDate = 1153987526\n",
      "  FileAccessDate = 1153987526\n",
      "  FileInodeChangeDate = 1153987526\n",
      "  FilePermissions = 33188\n",
      "  FileType = TIFF\n",
      "  FileTypeExtension = TIF\n",
      "  MIMEType = image/tiff\n",
      "  ExifByteOrder = II\n",
      "  + [IFD0 directory with 15 entries, Little-endian]\n",
      "  | 0)  SubfileType = 0\n",
      "  |     - Tag 0x00fe (4 bytes, int32u[1]):\n",
      "  |         0014: 00 00 00 00                                     [....]\n",
      "  | 1)  ImageWidth = 1920\n",
      "  |     - Tag 0x0100 (4 bytes, int32u[1]):\n",
      "  |         0020: 80 07 00 00                                     [....]\n",
      "  | 2)  ImageHeight = 1080\n",
      "  |     - Tag 0x0101 (4 bytes, int32u[1]):\n",
      "  |         002c: 38 04 00 00                                     [8...]\n",
      "  | 3)  BitsPerSample = 8 8 8 8\n",
      "  |     - Tag 0x0102 (8 bytes, int16u[4]):\n",
      "  |         00d0: 08 00 08 00 08 00 08 00                         [........]\n",
      "  | 4)  Compression = 32773\n",
      "  |     - Tag 0x0103 (2 bytes, int16u[1]):\n",
      "  |         0044: 05 80                                           [..]\n",
      "  | 5)  PhotometricInterpretation = 2\n",
      "  |     - Tag 0x0106 (2 bytes, int16u[1]):\n",
      "  |         0050: 02 00                                           [..]\n",
      "  | 6)  StripOffsets = 252\n",
      "  |     - Tag 0x0111 (4 bytes, int32u[1]):\n",
      "  |         005c: fc 00 00 00                                     [....]\n",
      "  | 7)  SamplesPerPixel = 4\n",
      "  |     - Tag 0x0115 (2 bytes, int16u[1]):\n",
      "  |         0068: 04 00                                           [..]\n",
      "  | 8)  RowsPerStrip = 1080\n",
      "  |     - Tag 0x0116 (4 bytes, int32u[1]):\n",
      "  |         0074: 38 04 00 00                                     [8...]\n",
      "  | 9)  StripByteCounts = 3273520\n",
      "  |     - Tag 0x0117 (4 bytes, int32u[1]):\n",
      "  |         0080: 30 f3 31 00                                     [0.1.]\n",
      "  | 10) XResolution = 72 (72/1)\n",
      "  |     - Tag 0x011a (8 bytes, rational64u[1]):\n",
      "  |         00e8: 48 00 00 00 01 00 00 00                         [H.......]\n",
      "  | 11) YResolution = 72 (72/1)\n",
      "  |     - Tag 0x011b (8 bytes, rational64u[1]):\n",
      "  |         00f4: 48 00 00 00 01 00 00 00                         [H.......]\n",
      "  | 12) PlanarConfiguration = 1\n",
      "  |     - Tag 0x011c (2 bytes, int16u[1]):\n",
      "  |         00a4: 01 00                                           [..]\n",
      "  | 13) ExtraSamples = 1\n",
      "  |     - Tag 0x0152 (2 bytes, int16u[1]):\n",
      "  |         00b0: 01 00                                           [..]\n",
      "  | 14) SampleFormat = 1 1 1 1\n",
      "  |     - Tag 0x0153 (8 bytes, int16u[4]):\n",
      "  |         00dc: 01 00 01 00 01 00 01 00                         [........]\n"
     ]
    }
   ],
   "source": [
    "!/home/renku/work/exiftool/exiftool  -v3 \"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/04_Entwurf/060730_FinalDesignDocumentation/02_Movies/01_RawMaterial/01_FallingSpheres/fallingSpheres_0001.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finale version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanne 12344 Dateien ‚Ä¶\n",
      "Warn: JSON parse problem, head: [{\n",
      "  \"SourceFile\": \"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/03_Plaene/01_dFab/060419_Praesentation/060419_Plan_2/060418_Schliessvariante_3.33Seite_12Steine_28Lagen_working_Expression.5.psd\",\n",
      "  \"ExifTool:ExifToo\n",
      "120/12344Warn: JSON parse problem, head:   \"Photoshop:SlicesGroupName\": \"060418_Schliessvariante_3.33Seite_12Steine_28Lagen_working_Expression.5\",\n",
      "  \"Photoshop:NumSlices\": 1,\n",
      "  \"Photoshop:PixelAspectRatio\": 1,\n",
      "  \"Photoshop:PhotoshopThumbnail\": \"(Binary data 5022 bytes, use -b option to extract)\",\n",
      "  \"Photoshop:HasRealMergedData\": \"Yes\",\n",
      "  \"\n",
      "240/12344Warn: JSON parse problem, head:   \"Photoshop:SlicesGroupName\": \"testtexture\",\n",
      "  \"Photoshop:NumSlices\": 1,\n",
      "  \"Photoshop:PixelAspectRatio\": 1,\n",
      "  \"Photoshop:PhotoshopThumbnail\": \"(Binary data 744 bytes, use -b option to extract)\",\n",
      "  \"Photoshop:HasRealMergedData\": \"Yes\",\n",
      "  \"Photoshop:WriterName\": \"Adobe Photoshop\",\n",
      "  \"Photoshop:Reader\n",
      "360/12344"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, json, subprocess, time, hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "# ========== Konfiguration ==========\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein\")\n",
    "EXIFTOOL = \"/home/renku/work/exiftool/exiftool\"\n",
    "BATCH_SIZE = 120\n",
    "FAST = False  # -fast nur bei sehr gro√üen Datenmengen\n",
    "\n",
    "# Ausgabepfad (von dir vorgegeben) ‚Äì wird automatisch erstellt\n",
    "OUT_DIR = Path(\"/home/renku/work/dcaonnextcloud-500gb/dca-metadataraw/WeingutGantenbein/gramazio-kohler-archiv-server_results/provenance/\")\n",
    "OUT_PREFIX = \"provenance\"  # Dateiname ohne Endung\n",
    "\n",
    "# Ziel-Endungen (erweiterbar)\n",
    "EXT = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".psd\",\".psb\",\".bmp\",\".gif\"}\n",
    "\n",
    "# Zeitn√§he (f√ºr hypothetische PSD->Raster-Matches)\n",
    "HYPOTHESIS_DAYS = 7\n",
    "\n",
    "# ========== CRMdig / CIDOC (minimal, schlank) ==========\n",
    "CRM = {\n",
    "    \"base_uri\": \"http://example.org/obj/\",\n",
    "    \"graph_uri\": \"http://example.org/graph/\",\n",
    "    \"DigitalObject\": \"crmdig:D1_Digital_Object\",\n",
    "    \"fileProp\": \"crm:P1_is_identified_by\",\n",
    "    \"createdBy\": \"crm:P94i_was_created_by\",        # optional (nicht genutzt in Minimalversion)\n",
    "    \"derivedFrom\": \"crm:P130_shows_features_of\",    # bekannte Ableitung\n",
    "    \"hyp_derivation\": \"crmdig:L23_used_for_derivation\",  # hypothetische Ableitung\n",
    "    \"usedCamera\": \"crmdig:L22_created_with\",        # Kamera -> Bild\n",
    "    \"certainty\": \"crmsci:O8_observed\"               # hier h√§ngen wir Confidence/Evidence als Literal dran\n",
    "}\n",
    "\n",
    "# ========== Hilfsfunktionen ==========\n",
    "def list_files(root: Path):\n",
    "    for r, d, flist in os.walk(root):\n",
    "        for f in flist:\n",
    "            p = Path(r)/f\n",
    "            if p.suffix.lower() in EXT:\n",
    "                yield str(p)\n",
    "\n",
    "def stable_id(s: str) -> str:\n",
    "    return \"urn:sha1:\" + hashlib.sha1(s.encode(\"utf-8\",\"ignore\")).hexdigest()\n",
    "\n",
    "def to_datetime(s):\n",
    "    if not s: return None\n",
    "    for fmt in (\"%Y:%m:%d %H:%M:%S%z\", \"%Y:%m:%d %H:%M:%S\", \"%Y-%m-%dT%H:%M:%S%z\", \"%Y-%m-%dT%H:%M:%S\"):\n",
    "        try:\n",
    "            return datetime.strptime(s, fmt)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# ========== ExifTool Stay-Open ==========\n",
    "def et_start():\n",
    "    args = [EXIFTOOL, \"-stay_open\", \"True\", \"-@\", \"-\"]\n",
    "    return subprocess.Popen(args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, bufsize=1)\n",
    "\n",
    "def et_cmd(et, files):\n",
    "    # Tagliste: XMP-MM, EXIF/Kamera, TIFF, Software/Creator/Photoshop, JPEG-Hints\n",
    "    cmd = [\n",
    "        \"-a\",\"-s\",\"-struct\",\"-G1\",\"-json\",\n",
    "        # IDs & Genealogie\n",
    "        \"XMP-xmpMM:DocumentID\",\"XMP-xmpMM:InstanceID\",\n",
    "        \"XMP-xmpMM:DerivedFrom:DocumentID\",\"XMP-xmpMM:DerivedFrom:InstanceID\",\"XMP-xmpMM:OriginalDocumentID\",\n",
    "        # XMP Tool\n",
    "        \"XMP-xmp:CreatorTool\",\"XMP-x:CreatorTool\",\n",
    "        # EXIF Kamera\n",
    "        \"EXIF:Make\",\"EXIF:Model\",\"EXIF:DateTimeOriginal\",\"EXIF:Software\",\n",
    "        # File\n",
    "        \"File:FileType\",\"File:MIMEType\",\"File:FileSize\",\"File:Directory\",\"File:FileName\",\"File:FileModifyDate\",\n",
    "        # Basis-Bildtags\n",
    "        \"EXIF:ImageWidth\",\"EXIF:ImageHeight\",\"EXIF:ColorSpace\",\n",
    "        \"Composite:ImageSize\",\"Composite:Megapixels\",\n",
    "        # TIFF-spezifisch\n",
    "        \"IFD0:BitsPerSample\",\"IFD0:SamplesPerPixel\",\"IFD0:ExtraSamples\",\n",
    "        \"IFD0:Compression\",\"IFD0:PhotometricInterpretation\",\n",
    "        \"IFD0:XResolution\",\"IFD0:YResolution\",\"IFD0:ResolutionUnit\",\n",
    "        # Photoshop / Adobe Hinweise (vor allem f√ºr JPEG)\n",
    "        \"Photoshop:WriterName\",\"Photoshop:ReaderName\",\"APP14Flags0\",\"JFIFVersion\",\"Photoshop:PhotoshopThumbnail\",\n",
    "    ]\n",
    "    if FAST: cmd.insert(0,\"-fast\")\n",
    "\n",
    "    for a in cmd:\n",
    "        et.stdin.write(a+\"\\n\")\n",
    "    for f in files:\n",
    "        et.stdin.write(f+\"\\n\")\n",
    "    et.stdin.write(\"-execute\\n\")\n",
    "    et.stdin.flush()\n",
    "\n",
    "def et_read(et):\n",
    "    # exiftool -json gibt i.d.R. ein JSON-Array pro -execute zur√ºck\n",
    "    buf = \"\"\n",
    "    while True:\n",
    "        line = et.stdout.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        buf += line\n",
    "        if \"]\" in buf:\n",
    "            break\n",
    "    try:\n",
    "        data = json.loads(buf)\n",
    "        return data if isinstance(data, list) else [data]\n",
    "    except Exception:\n",
    "        print(\"Warn: JSON parse problem, head:\", buf[:300])\n",
    "        return []\n",
    "\n",
    "def et_close(et):\n",
    "    try:\n",
    "        et.stdin.write(\"-stay_open\\nFalse\\n-execute\\n\")\n",
    "        et.stdin.flush()\n",
    "        et.communicate(timeout=2)\n",
    "    except Exception:\n",
    "        et.kill()\n",
    "\n",
    "# ========== Klassifikation ==========\n",
    "def flag_adobe(x: dict) -> bool:\n",
    "    ct = (x.get(\"XMP-xmp:CreatorTool\") or x.get(\"XMP-x:CreatorTool\") or \"\" ).lower()\n",
    "    sw = (x.get(\"EXIF:Software\") or \"\").lower()\n",
    "    ps_writer = x.get(\"Photoshop:WriterName\")\n",
    "    ps_reader = x.get(\"Photoshop:ReaderName\")\n",
    "    app14 = x.get(\"APP14Flags0\")\n",
    "    if \"photoshop\" in ct or \"adobe\" in ct: return True\n",
    "    if \"photoshop\" in sw or \"adobe\" in sw: return True\n",
    "    if ps_writer or ps_reader: return True\n",
    "    if app14 not in (None, \"\", 0): return True\n",
    "    return False\n",
    "\n",
    "def is_camera_present(x: dict) -> bool:\n",
    "    return bool(x.get(\"EXIF:Make\") or x.get(\"EXIF:Model\") or x.get(\"EXIF:DateTimeOriginal\"))\n",
    "\n",
    "def filetype_from_name(name: str) -> str:\n",
    "    ext = Path(name).suffix.lower()\n",
    "    if ext in (\".psd\",\".psb\"): return \"psd\"\n",
    "    if ext in (\".jpg\",\".jpeg\"): return \"jpg\"\n",
    "    if ext in (\".tif\",\".tiff\"): return \"tiff\"\n",
    "    if ext == \".png\": return \"png\"\n",
    "    return ext.lstrip(\".\")\n",
    "\n",
    "def render_score(x: dict, ftype: str) -> int:\n",
    "    score = 0\n",
    "    adobe = flag_adobe(x)\n",
    "    cam = is_camera_present(x)\n",
    "\n",
    "    if not cam: score += 15\n",
    "    if not adobe: score += 20\n",
    "\n",
    "    if ftype == \"tiff\":\n",
    "        sps = x.get(\"IFD0:SamplesPerPixel\")\n",
    "        extras = x.get(\"IFD0:ExtraSamples\")\n",
    "        comp = x.get(\"IFD0:Compression\")\n",
    "        xres = x.get(\"IFD0:XResolution\")\n",
    "        yres = x.get(\"IFD0:YResolution\")\n",
    "        try:\n",
    "            sps_i = int(str(sps).split()[0]) if sps else 0\n",
    "        except Exception: sps_i = 0\n",
    "        try:\n",
    "            extras_i = int(str(extras).split()[0]) if extras else 0\n",
    "        except Exception: extras_i = 0\n",
    "        rgba = (sps_i >= 4) and (extras_i >= 1)\n",
    "        if rgba: score += 40\n",
    "        if str(comp) in (\"1\",\"5\",\"32773\"): score += 10  # Uncompressed/LZW/PackBits\n",
    "        if str(xres) in (\"72\",\"72/1\") and str(yres) in (\"72\",\"72/1\"): score += 15\n",
    "\n",
    "    if ftype == \"jpg\":\n",
    "        if not adobe and not cam:\n",
    "            score += 20\n",
    "\n",
    "    return min(score, 100)\n",
    "\n",
    "def genealogy_status(x: dict) -> str:\n",
    "    if x.get(\"XMP-xmpMM:DerivedFrom:DocumentID\") or x.get(\"XMP-xmpMM:DerivedFrom:InstanceID\"):\n",
    "        return \"derived\"\n",
    "    return \"root\"\n",
    "\n",
    "def extract_record(x: dict) -> dict:\n",
    "    rec = {}\n",
    "    rec[\"file\"] = x.get(\"SourceFile\")\n",
    "    rec[\"filetype\"] = filetype_from_name(rec[\"file\"])\n",
    "    rec[\"mimetype\"] = x.get(\"File:MIMEType\")\n",
    "    rec[\"filesize\"] = x.get(\"File:FileSize\")\n",
    "    rec[\"modified\"] = x.get(\"File:FileModifyDate\")\n",
    "\n",
    "    rec[\"documentID\"] = x.get(\"XMP-xmpMM:DocumentID\")\n",
    "    rec[\"instanceID\"] = x.get(\"XMP-xmpMM:InstanceID\")\n",
    "    rec[\"parentDocumentID\"] = x.get(\"XMP-xmpMM:DerivedFrom:DocumentID\")\n",
    "    rec[\"parentInstanceID\"] = x.get(\"XMP-xmpMM:DerivedFrom:InstanceID\")\n",
    "    rec[\"originalDocumentID\"] = x.get(\"XMP-xmpMM:OriginalDocumentID\")\n",
    "\n",
    "    rec[\"creatorTool\"] = x.get(\"XMP-xmp:CreatorTool\") or x.get(\"XMP-x:CreatorTool\")\n",
    "    rec[\"software\"] = x.get(\"EXIF:Software\")\n",
    "\n",
    "    w = x.get(\"EXIF:ImageWidth\")\n",
    "    h = x.get(\"EXIF:ImageHeight\")\n",
    "    rec[\"width\"]  = int(str(w).split()[0]) if w else None\n",
    "    rec[\"height\"] = int(str(h).split()[0]) if h else None\n",
    "\n",
    "    rec[\"make\"] = x.get(\"EXIF:Make\")\n",
    "    rec[\"model\"] = x.get(\"EXIF:Model\")\n",
    "    rec[\"dateTimeOriginal\"] = x.get(\"EXIF:DateTimeOriginal\")\n",
    "\n",
    "    rec[\"tiff_bitsPerSample\"] = x.get(\"IFD0:BitsPerSample\")\n",
    "    rec[\"tiff_samplesPerPixel\"] = x.get(\"IFD0:SamplesPerPixel\")\n",
    "    rec[\"tiff_extraSamples\"] = x.get(\"IFD0:ExtraSamples\")\n",
    "    rec[\"tiff_compression\"] = x.get(\"IFD0:Compression\")\n",
    "    rec[\"tiff_photometric\"] = x.get(\"IFD0:PhotometricInterpretation\")\n",
    "    rec[\"tiff_xres\"] = x.get(\"IFD0:XResolution\")\n",
    "    rec[\"tiff_yres\"] = x.get(\"IFD0:YResolution\")\n",
    "    rec[\"tiff_resUnit\"] = x.get(\"IFD0:ResolutionUnit\")\n",
    "\n",
    "    rec[\"ps_writer\"] = x.get(\"Photoshop:WriterName\")\n",
    "    rec[\"ps_reader\"] = x.get(\"Photoshop:ReaderName\")\n",
    "    rec[\"app14_flags0\"] = x.get(\"APP14Flags0\")\n",
    "    rec[\"jfif_version\"] = x.get(\"JFIFVersion\")\n",
    "\n",
    "    rec[\"has_adobe\"] = flag_adobe(x)\n",
    "    rec[\"has_camera\"] = is_camera_present(x)\n",
    "    rec[\"genealogy_status\"] = genealogy_status(x)\n",
    "    rec[\"render_score\"] = render_score(x, rec[\"filetype\"])\n",
    "    rec[\"origin_guess\"] = (\n",
    "        \"render_possible\" if rec[\"render_score\"] >= 60 else\n",
    "        \"photoshop\"       if rec[\"has_adobe\"] and rec[\"filetype\"] in (\"jpg\",\"png\",\"tiff\",\"psd\",\"psb\") else\n",
    "        \"camera\"          if rec[\"has_camera\"] else\n",
    "        \"unknown\"\n",
    "    )\n",
    "\n",
    "    rec[\"node_id\"] = rec[\"documentID\"] or rec[\"instanceID\"] or stable_id(rec[\"file\"])\n",
    "    return rec\n",
    "\n",
    "# ========== Scan ==========\n",
    "def scan_all():\n",
    "    files = list(list_files(ROOT))\n",
    "    print(f\"Scanne {len(files)} Dateien ‚Ä¶\")\n",
    "    et = et_start()\n",
    "    records = []\n",
    "    try:\n",
    "        for i in range(0, len(files), BATCH_SIZE):\n",
    "            batch = files[i:i+BATCH_SIZE]\n",
    "            et_cmd(et, batch)\n",
    "            data = et_read(et)\n",
    "            for item in data:\n",
    "                rec = extract_record(item)\n",
    "                records.append(rec)\n",
    "            print(f\"\\r{min(i+BATCH_SIZE, len(files))}/{len(files)}\", end=\"\")\n",
    "        print()\n",
    "    finally:\n",
    "        et_close(et)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# ========== Kanten ==========\n",
    "def build_edges(df: pd.DataFrame):\n",
    "    edges = []\n",
    "\n",
    "    # 1) bekannte XMP-MM Ableitungen\n",
    "    for _, r in df.iterrows():\n",
    "        child = r[\"node_id\"]\n",
    "        pdoc = r.get(\"parentDocumentID\")\n",
    "        pinst = r.get(\"parentInstanceID\")\n",
    "        parent = pdoc or pinst\n",
    "        if parent and child and parent != child:\n",
    "            edges.append({\n",
    "                \"source\": parent,\n",
    "                \"target\": child,\n",
    "                \"kind\": \"known_derivation\",\n",
    "                \"confidence\": 1.0,\n",
    "                \"evidence\": \"xmpMM:DerivedFrom\"\n",
    "            })\n",
    "\n",
    "    # 2) Hypothesen (Basename + gleiche Dimension + zeitnah), wenn keine bekannte Kante\n",
    "    base_index = defaultdict(list)\n",
    "    for _, r in df.iterrows():\n",
    "        base = Path(r[\"file\"]).stem.lower()\n",
    "        base_index[base].append(r)\n",
    "\n",
    "    def dt_of(r):\n",
    "        return to_datetime(r.get(\"dateTimeOriginal\") or r.get(\"modified\"))\n",
    "\n",
    "    for base, rows in base_index.items():\n",
    "        psds = [r for r in rows if r[\"filetype\"] in (\"psd\",\"psb\")]\n",
    "        rasters = [r for r in rows if r[\"filetype\"] in (\"jpg\",\"png\",\"tiff\")]\n",
    "        for p in psds:\n",
    "            has_known_child = any(e[\"source\"]==p[\"node_id\"] and e[\"kind\"]==\"known_derivation\" for e in edges)\n",
    "            if has_known_child: continue\n",
    "            for q in rasters:\n",
    "                if p[\"width\"] and p[\"height\"] and q[\"width\"] and q[\"height\"]:\n",
    "                    same_dim = (p[\"width\"]==q[\"width\"] and p[\"height\"]==q[\"height\"])\n",
    "                else:\n",
    "                    same_dim = False\n",
    "                tp, tq = dt_of(p), dt_of(q)\n",
    "                time_close = False\n",
    "                if tp and tq:\n",
    "                    delta = abs((tq - tp).days)\n",
    "                    time_close = (delta <= HYPOTHESIS_DAYS)\n",
    "\n",
    "                if same_dim and time_close:\n",
    "                    edges.append({\n",
    "                        \"source\": p[\"node_id\"],\n",
    "                        \"target\": q[\"node_id\"],\n",
    "                        \"kind\": \"hypothesis_derivation\",\n",
    "                        \"confidence\": 0.5,\n",
    "                        \"evidence\": \"basename+dimensions+time\"\n",
    "                    })\n",
    "\n",
    "    # 3) Kamera ‚Üí Bild\n",
    "    for _, r in df.iterrows():\n",
    "        if r[\"has_camera\"]:\n",
    "            cam_id = f\"camera:{(r['make'] or '').strip()}|{(r['model'] or '').strip()}\"\n",
    "            edges.append({\n",
    "                \"source\": cam_id,\n",
    "                \"target\": r[\"node_id\"],\n",
    "                \"kind\": \"camera_used\",\n",
    "                \"confidence\": 1.0,\n",
    "                \"evidence\": \"EXIF:Make/Model\"\n",
    "            })\n",
    "\n",
    "    return edges\n",
    "\n",
    "# ========== Graph-Export ==========\n",
    "def export_graph(df: pd.DataFrame, edges: list, path: Path):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Knoten\n",
    "    for _, r in df.iterrows():\n",
    "        G.add_node(r[\"node_id\"], **{\n",
    "            \"class\": r[\"origin_guess\"],\n",
    "            \"file\": r[\"file\"],\n",
    "            \"filetype\": r[\"filetype\"],\n",
    "            \"width\": r[\"width\"], \"height\": r[\"height\"],\n",
    "            \"has_adobe\": bool(r[\"has_adobe\"]),\n",
    "            \"has_camera\": bool(r[\"has_camera\"]),\n",
    "            \"render_score\": int(r[\"render_score\"]),\n",
    "            \"documentID\": r[\"documentID\"],\n",
    "            \"instanceID\": r[\"instanceID\"]\n",
    "        })\n",
    "\n",
    "    # Kanten\n",
    "    for e in edges:\n",
    "        if e[\"kind\"]==\"camera_used\" and e[\"source\"].startswith(\"camera:\"):\n",
    "            if not G.has_node(e[\"source\"]):\n",
    "                G.add_node(e[\"source\"], **{\"class\":\"camera\",\"filetype\":\"camera\",\"file\":None})\n",
    "        if not G.has_node(e[\"source\"]):\n",
    "            G.add_node(e[\"source\"], **{\"class\":\"unknown\"})\n",
    "        if not G.has_node(e[\"target\"]):\n",
    "            G.add_node(e[\"target\"], **{\"class\":\"unknown\"})\n",
    "        G.add_edge(e[\"source\"], e[\"target\"], kind=e[\"kind\"], confidence=e[\"confidence\"], evidence=e[\"evidence\"])\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_graph.node_link_data(G), f, indent=2, ensure_ascii=False)\n",
    "    return G\n",
    "\n",
    "# ========== CSV ==========\n",
    "def export_csv(df: pd.DataFrame, path: Path):\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "# ========== CRMdig TTL (minimal) ==========\n",
    "def ttl_esc(s:str) -> str:\n",
    "    return s.replace(\"\\\\\",\"/\").replace('\"','\\\\\"')\n",
    "\n",
    "def export_crmdig_ttl(df: pd.DataFrame, edges: list, path: Path):\n",
    "    lines = []\n",
    "    lines.append(\"@prefix crm: <http://www.cidoc-crm.org/cidoc-crm/> .\")\n",
    "    lines.append(\"@prefix crmdig: <http://www.ics.forth.gr/isl/CRMdig/> .\")\n",
    "    lines.append(\"@prefix crmsci: <http://www.ics.forth.gr/isl/CRMsci/> .\")\n",
    "    lines.append(\"@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\")\n",
    "    lines.append(f\"@base <{CRM['graph_uri']}> .\\n\")\n",
    "\n",
    "    # Objekte\n",
    "    for _, r in df.iterrows():\n",
    "        uid = r[\"node_id\"]\n",
    "        uri = f\"<{CRM['base_uri']}{uid}>\"\n",
    "        lines.append(f\"{uri} a {CRM['DigitalObject']} ;\")\n",
    "        lines.append(f'  {CRM[\"fileProp\"]} \"{ttl_esc(r[\"file\"])}\" ;')\n",
    "        if r[\"documentID\"]:\n",
    "            lines.append(f'  crm:P1_is_identified_by \"{ttl_esc(r[\"documentID\"])}\" ;')\n",
    "        lines.append(f'  crm:P2_has_type \"{r[\"filetype\"]}\" .')\n",
    "\n",
    "    # Kamera-Knoten\n",
    "    cams = {e[\"source\"] for e in edges if e[\"kind\"]==\"camera_used\" and e[\"source\"].startswith(\"camera:\")}\n",
    "    for cam in cams:\n",
    "        cam_uri = f\"<{CRM['base_uri']}{cam}>\"\n",
    "        lines.append(f\"{cam_uri} a crm:E39_Actor ; crm:P1_is_identified_by \\\"{ttl_esc(cam)}\\\" .\")\n",
    "\n",
    "    # Kanten\n",
    "    for e in edges:\n",
    "        s = f\"<{CRM['base_uri']}{e['source']}>\"\n",
    "        t = f\"<{CRM['base_uri']}{e['target']}>\"\n",
    "        if e[\"kind\"]==\"known_derivation\":\n",
    "            lines.append(f\"{t} {CRM['derivedFrom']} {s} ; {CRM['certainty']} \\\"confidence:{e['confidence']}|evidence:{e['evidence']}\\\" .\")\n",
    "        elif e[\"kind\"]==\"hypothesis_derivation\":\n",
    "            lines.append(f\"{t} {CRM['hyp_derivation']} {s} ; {CRM['certainty']} \\\"confidence:{e['confidence']}|evidence:{e['evidence']}|status:hypothesis\\\" .\")\n",
    "        elif e[\"kind\"]==\"camera_used\":\n",
    "            lines.append(f\"{t} {CRM['usedCamera']} {s} ; {CRM['certainty']} \\\"confidence:{e['confidence']}|evidence:{e['evidence']}\\\" .\")\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "# ========== Main ==========\n",
    "def main():\n",
    "    # Ausgabeverzeichnis sicherstellen\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = scan_all()\n",
    "\n",
    "    # CSV\n",
    "    csv_path = OUT_DIR / f\"{OUT_PREFIX}.csv\"\n",
    "    export_csv(df, csv_path)\n",
    "    print(f\"CSV ‚Üí {csv_path}\")\n",
    "\n",
    "    # Edges & Graph\n",
    "    edges = build_edges(df)\n",
    "    graph_path = OUT_DIR / f\"{OUT_PREFIX}_graph.json\"\n",
    "    G = export_graph(df, edges, graph_path)\n",
    "    print(f\"Graph JSON ‚Üí {graph_path} | Nodes: {G.number_of_nodes()} | Edges: {G.number_of_edges()}\")\n",
    "\n",
    "    # CRMdig TTL\n",
    "    ttl_path = OUT_DIR / f\"{OUT_PREFIX}_crmdig.ttl\"\n",
    "    export_crmdig_ttl(df, edges, ttl_path)\n",
    "    print(f\"CRMdig TTL ‚Üí {ttl_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
