{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XMP-x]         XMPToolkit                      : 3.1.1-112\n",
      "[XMP-xmpMM]     DocumentID                      : uuid:11B81C2FCA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     InstanceID                      : uuid:12B81C2FCA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     DerivedFromInstanceID           : uuid:0E1E7741BA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     DerivedFromDocumentID           : uuid:0D1E7741BA03DB11958680BA79BAC3A6\n",
      "[XMP-xmp]       CreateDate                      : 2006:06:24 23:41:53+02:00\n",
      "[XMP-xmp]       ModifyDate                      : 2006:06:24 23:41:53+02:00\n",
      "[XMP-xmp]       MetadataDate                    : 2006:06:24 23:41:53+02:00\n",
      "[XMP-xmp]       CreatorTool                     : Adobe Photoshop CS2 Windows\n",
      "[XMP-dc]        Format                          : image/jpeg\n",
      "[XMP-photoshop] ColorMode                       : RGB\n",
      "[XMP-photoshop] History                         : \n",
      "[XMP-tiff]      Orientation                     : Horizontal (normal)\n",
      "[XMP-tiff]      XResolution                     : 72\n",
      "[XMP-tiff]      YResolution                     : 72\n",
      "[XMP-tiff]      ResolutionUnit                  : inches\n",
      "[XMP-tiff]      NativeDigest                    : 256,257,258,259,262,274,277,284,530,531,282,283,296,301,318,319,529,532,306,270,271,272,305,315,33432;5BC2DF82FA2AFB1D1E542374B1F9349E\n",
      "[XMP-exif]      ExifImageWidth                  : 1270\n",
      "[XMP-exif]      ExifImageHeight                 : 285\n",
      "[XMP-exif]      ColorSpace                      : Unknown (-1)\n",
      "[XMP-exif]      NativeDigest                    : 36864,40960,40961,37121,37122,40962,40963,37510,40964,36867,36868,33434,33437,34850,34852,34855,34856,37377,37378,37379,37380,37381,37382,37383,37384,37385,37386,37396,41483,41484,41486,41487,41488,41492,41493,41495,41728,41729,41730,41985,41986,41987,41988,41989,41990,41991,41992,41993,41994,41995,41996,42016,0,2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,22,23,24,25,26,27,28,30;7C663A56C90A75AFBE90519C14FAE106\n",
      "[XMP-xmpMM]     DocumentID                      : uuid:11B81C2FCA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     InstanceID                      : uuid:12B81C2FCA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     DerivedFromInstanceID           : uuid:0E1E7741BA03DB11958680BA79BAC3A6\n",
      "[XMP-xmpMM]     DerivedFromDocumentID           : uuid:0D1E7741BA03DB11958680BA79BAC3A6\n"
     ]
    }
   ],
   "source": [
    "!/home/renku/work/exiftool/exiftool -a -G1 -s -XMP:all -XMP-xmpMM:all \"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/04_Entwurf/060625_FinalDesign/02_Texturen/v1_8_r3_cam1_simplified_inv.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "  \"SourceFile\": \"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/04_Entwurf/060625_FinalDesign/02_Texturen/v1_8_r3_cam1_simplified_inv.jpg\",\n",
      "  \"XMP-x:XMPToolkit\": \"3.1.1-112\",\n",
      "  \"XMP-xmpMM:DocumentID\": \"uuid:11B81C2FCA03DB11958680BA79BAC3A6\",\n",
      "  \"XMP-xmpMM:InstanceID\": \"uuid:12B81C2FCA03DB11958680BA79BAC3A6\",\n",
      "  \"XMP-xmpMM:DerivedFrom\": {\n",
      "    \"DocumentID\": \"uuid:0D1E7741BA03DB11958680BA79BAC3A6\",\n",
      "    \"InstanceID\": \"uuid:0E1E7741BA03DB11958680BA79BAC3A6\"\n",
      "  },\n",
      "  \"XMP-xmp:CreateDate\": \"2006:06:24 23:41:53+02:00\",\n",
      "  \"XMP-xmp:ModifyDate\": \"2006:06:24 23:41:53+02:00\",\n",
      "  \"XMP-xmp:MetadataDate\": \"2006:06:24 23:41:53+02:00\",\n",
      "  \"XMP-xmp:CreatorTool\": \"Adobe Photoshop CS2 Windows\",\n",
      "  \"XMP-dc:Format\": \"image/jpeg\",\n",
      "  \"XMP-photoshop:ColorMode\": \"RGB\",\n",
      "  \"XMP-photoshop:History\": \"\",\n",
      "  \"XMP-tiff:Orientation\": \"Horizontal (normal)\",\n",
      "  \"XMP-tiff:XResolution\": 72,\n",
      "  \"XMP-tiff:YResolution\": 72,\n",
      "  \"XMP-tiff:ResolutionUnit\": \"inches\",\n",
      "  \"XMP-tiff:NativeDigest\": \"256,257,258,259,262,274,277,284,530,531,282,283,296,301,318,319,529,532,306,270,271,272,305,315,33432;5BC2DF82FA2AFB1D1E542374B1F9349E\",\n",
      "  \"XMP-exif:ExifImageWidth\": 1270,\n",
      "  \"XMP-exif:ExifImageHeight\": 285,\n",
      "  \"XMP-exif:ColorSpace\": \"Unknown (-1)\",\n",
      "  \"XMP-exif:NativeDigest\": \"36864,40960,40961,37121,37122,40962,40963,37510,40964,36867,36868,33434,33437,34850,34852,34855,34856,37377,37378,37379,37380,37381,37382,37383,37384,37385,37386,37396,41483,41484,41486,41487,41488,41492,41493,41495,41728,41729,41730,41985,41986,41987,41988,41989,41990,41991,41992,41993,41994,41995,41996,42016,0,2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,22,23,24,25,26,27,28,30;7C663A56C90A75AFBE90519C14FAE106\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "!/home/renku/work/exiftool/exiftool -json -a -G1 -s -struct -XMP:all -XMP-xmpMM:all \"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/04_Entwurf/060625_FinalDesign/02_Texturen/v1_8_r3_cam1_simplified_inv.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/renku/work/.venv/lib/python3.10/site-packages (2.3.3)\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tzdata>=2022.7 in /home/renku/work/.venv/lib/python3.10/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/renku/work/.venv/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/renku/work/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: networkx\n",
      "Successfully installed networkx-3.4.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### üìÇ Scanne folgendes Wurzelverzeichnis:\n",
       "`/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üîç Durchsuche Dateien..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚úîÔ∏è Insgesamt gescannt: **12338 Dateien**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ‚úîÔ∏è Dateien mit XMP-MM-Genealogie: **0**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>documentID</th>\n",
       "      <th>instanceID</th>\n",
       "      <th>parentDocumentID</th>\n",
       "      <th>parentInstanceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file documentID instanceID  \\\n",
       "0   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "1   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "2   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "3   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "4   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "5   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "6   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "7   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "8   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "9   /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "10  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "11  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "12  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "13  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "14  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "15  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "16  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "17  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "18  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "19  /home/renku/work/dcaonnextcloud-500gb/DigitalM...       None       None   \n",
       "\n",
       "   parentDocumentID parentInstanceID  \n",
       "0              None             None  \n",
       "1              None             None  \n",
       "2              None             None  \n",
       "3              None             None  \n",
       "4              None             None  \n",
       "5              None             None  \n",
       "6              None             None  \n",
       "7              None             None  \n",
       "8              None             None  \n",
       "9              None             None  \n",
       "10             None             None  \n",
       "11             None             None  \n",
       "12             None             None  \n",
       "13             None             None  \n",
       "14             None             None  \n",
       "15             None             None  \n",
       "16             None             None  \n",
       "17             None             None  \n",
       "18             None             None  \n",
       "19             None             None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üìå Graph-Statistik"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'nodes': 0, 'edges': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renku/work/.venv/lib/python3.10/site-packages/networkx/readwrite/json_graph/node_link.py:142: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üìÅ Genealogie-Graph gespeichert als `genealogy_graph_xmp_full.json`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## üß¨ Gefundene Herkunftsketten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) KONFIGURATION ‚Äì GANZER NEXTCLOUD-ORDNER\n",
    "# ------------------------------------------------------------\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/\")\n",
    "EXTENSIONS = {\".jpg\", \".jpeg\", \".tif\", \".tiff\", \".png\", \".psd\", \".psb\"}\n",
    "\n",
    "display(Markdown(f\"### üìÇ Scanne folgendes Wurzelverzeichnis:\\n`{ROOT}`\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) EXIFTOOL: ALLE XMP-SEGMENTE AUSLESEN (XMP + APP13/8BIM)\n",
    "# ------------------------------------------------------------\n",
    "def extract_xmpmm(path):\n",
    "    \"\"\"\n",
    "    Extrahiert ALLE XMP-MM Felder aus Standard-XMP + Photoshop APP13/8BIM.\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"/home/renku/work/exiftool/exiftool\",   # Pfad zu deinem ExifTool\n",
    "        \"-a\",                          # alle doppelten Tags anzeigen\n",
    "        \"-G1\",                         # zeigt Segment (XMP, APP1, APP13, etc.)\n",
    "        \"-s\",                          # kurze Tag-Namen\n",
    "        \"-struct\",                     # strukturierte Ausgabe\n",
    "        \"-XMP:all\",                    # ALLE XMP-Namespace-Daten\n",
    "        \"-XMP-xmpMM:all\",              # alle Media-Management-Felder\n",
    "        \"-json\",\n",
    "        str(path)\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        out = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        data = json.loads(out.stdout)[0]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    # M√∂gliche Feld-Namen (wegen unterschiedlicher XMP-Segmente)\n",
    "    keys = data.keys()\n",
    "\n",
    "    def get(*names):\n",
    "        for n in names:\n",
    "            if n in data:\n",
    "                return data[n]\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"file\": str(path),\n",
    "        \"documentID\": get(\"XMP-xmpMM-DocumentID\", \"DocumentID\"),\n",
    "        \"instanceID\": get(\"XMP-xmpMM-InstanceID\", \"InstanceID\"),\n",
    "        \"parentDocumentID\": get(\"XMP-xmpMM-DerivedFromDocumentID\"),\n",
    "        \"parentInstanceID\": get(\"XMP-xmpMM-DerivedFromInstanceID\"),\n",
    "    }\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) SCAN DES GESAMTEN VERZEICHNISSES √úBER WEBDAV\n",
    "# ------------------------------------------------------------\n",
    "display(Markdown(\"### üîç Durchsuche Dateien...\"))\n",
    "\n",
    "records = []\n",
    "count = 0\n",
    "\n",
    "for root, dirs, files in os.walk(ROOT):\n",
    "    for f in files:\n",
    "        p = Path(root) / f\n",
    "        if p.suffix.lower() in EXTENSIONS:\n",
    "            rec = extract_xmpmm(p)\n",
    "            if rec:\n",
    "                records.append(rec)\n",
    "            count += 1\n",
    "\n",
    "display(Markdown(f\"### ‚úîÔ∏è Insgesamt gescannt: **{count} Dateien**\"))\n",
    "display(Markdown(f\"### ‚úîÔ∏è Dateien mit XMP-MM-Genealogie: **{sum(1 for r in records if r['documentID'])}**\"))\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "display(df.head(20))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) GENEALOGIE GRAPH\n",
    "# ------------------------------------------------------------\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    doc = row[\"documentID\"]\n",
    "    parent = row[\"parentDocumentID\"]\n",
    "\n",
    "    if doc:\n",
    "        G.add_node(doc)\n",
    "    if parent:\n",
    "        G.add_node(parent)\n",
    "        G.add_edge(parent, doc)\n",
    "\n",
    "display(Markdown(\"### üìå Graph-Statistik\"))\n",
    "display({\"nodes\": G.number_of_nodes(), \"edges\": G.number_of_edges()})\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) EXPORT GRAPH\n",
    "# ------------------------------------------------------------\n",
    "graph_json = nx.readwrite.json_graph.node_link_data(G)\n",
    "\n",
    "with open(\"genealogy_graph_xmp_full.json\", \"w\") as f:\n",
    "    json.dump(graph_json, f, indent=2)\n",
    "\n",
    "display(Markdown(\"### üìÅ Genealogie-Graph gespeichert als `genealogy_graph_xmp_full.json`\"))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) ALLE HERKUNFTS-KETTEN AUSGEBEN\n",
    "# ------------------------------------------------------------\n",
    "def print_chains(G):\n",
    "    display(Markdown(\"## üß¨ Gefundene Herkunftsketten\"))\n",
    "    roots = [n for n in G.nodes if G.in_degree(n) == 0]\n",
    "    for r in roots:\n",
    "        chain = list(nx.dfs_preorder_nodes(G, source=r))\n",
    "        print(\" ‚Üí \".join(chain))\n",
    "\n",
    "print_chains(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√ò pro Datei: 340.0 ms\n",
      "Gesamtdateien: 12338 | ETA ‚âà 69.9 Minuten\n"
     ]
    }
   ],
   "source": [
    "import time, itertools, os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/\")\n",
    "EXT = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".psd\",\".psb\"}\n",
    "\n",
    "def iter_files(root, limit=None):\n",
    "    c = 0\n",
    "    for r, d, files in os.walk(root):\n",
    "        for f in files:\n",
    "            if Path(f).suffix.lower() in EXT:\n",
    "                yield Path(r)/f\n",
    "                c += 1\n",
    "                if limit and c >= limit:\n",
    "                    return\n",
    "\n",
    "def exif_call(p):\n",
    "    return subprocess.run(\n",
    "        [\"/home/renku/work/exiftool/exiftool\",\"-a\",\"-G1\",\"-s\",\"-struct\",\"-XMP:all\",\"-XMP-xmpMM:all\",\"-json\",str(p)],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "\n",
    "# 1) Mini-Benchmark √ºber 200 Dateien\n",
    "N = 200\n",
    "files = list(iter_files(ROOT, limit=N))\n",
    "t0 = time.time()\n",
    "for fp in files:\n",
    "    exif_call(fp)\n",
    "t1 = time.time()\n",
    "\n",
    "per_file = (t1 - t0) / max(1, len(files))\n",
    "print(f\"√ò pro Datei: {per_file*1000:.1f} ms\")\n",
    "\n",
    "# 2) Gesamtdateien z√§hlen\n",
    "total = sum(1 for _ in iter_files(ROOT))\n",
    "eta_sec = per_file * total\n",
    "print(f\"Gesamtdateien: {total} | ETA ‚âà {eta_sec/60:.1f} Minuten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 121\u001b[0m\n\u001b[1;32m    119\u001b[0m batch\u001b[38;5;241m.\u001b[39mappend(fp)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m BATCH_SIZE:\n\u001b[0;32m--> 121\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43met_request_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;66;03m# Quelle (immer enthalten)\u001b[39;00m\n\u001b[1;32m    124\u001b[0m         src \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSourceFile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 67\u001b[0m, in \u001b[0;36met_request_json\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m     65\u001b[0m out_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[43m_et_proc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, json, subprocess, threading, queue, sys, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Konfiguration\n",
    "# -----------------------------\n",
    "EXIFTOOL = \"/home/renku/work/exiftool/exiftool\"  # dein ExifTool\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/\")\n",
    "EXTENSIONS = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".psd\",\".psb\"}\n",
    "\n",
    "# Globale Prozess-Referenz\n",
    "_et_proc = None\n",
    "_et_lock = threading.Lock()\n",
    "\n",
    "def start_exiftool():\n",
    "    global _et_proc\n",
    "    if _et_proc is not None:\n",
    "        return\n",
    "    _et_proc = subprocess.Popen(\n",
    "        [EXIFTOOL, \"-stay_open\", \"True\", \"-@\",\"-\"], \n",
    "        stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "        text=True, bufsize=1\n",
    "    )\n",
    "\n",
    "def stop_exiftool():\n",
    "    global _et_proc\n",
    "    if _et_proc is None:\n",
    "        return\n",
    "    try:\n",
    "        _et_proc.stdin.write(\"-stay_open\\nFalse\\n-execute\\n\")\n",
    "        _et_proc.stdin.flush()\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        _et_proc.communicate(timeout=5)\n",
    "    except Exception:\n",
    "        _et_proc.kill()\n",
    "    _et_proc = None\n",
    "\n",
    "def et_request_json(files):\n",
    "    \"\"\"\n",
    "    Schickt eine Anfrage (f√ºr eine oder mehrere Dateien) an den offenen ExifTool-Prozess\n",
    "    und gibt die JSON-Liste zur√ºck.\n",
    "    \"\"\"\n",
    "    global _et_proc\n",
    "    if _et_proc is None:\n",
    "        start_exiftool()\n",
    "    args = [\n",
    "        \"-a\",\"-G1\",\"-s\",\"-struct\",\n",
    "        \"-XMP:all\",\"-XMP-xmpMM:all\",\n",
    "        \"-json\",\n",
    "    ]\n",
    "    # Schreibe Befehle + Dateien\n",
    "    with _et_lock:\n",
    "        for a in args:\n",
    "            _et_proc.stdin.write(a+\"\\n\")\n",
    "        for f in files:\n",
    "            _et_proc.stdin.write(str(f)+\"\\n\")\n",
    "        _et_proc.stdin.write(\"-execute\\n\")\n",
    "        _et_proc.stdin.flush()\n",
    "\n",
    "        # Antworte lesen: Wir wissen, dass -json nur EINEN JSON-Block je -execute schreibt.\n",
    "        # Wir lesen so lange Zeilen, bis JSON ‚Äûvermutlich‚Äú vollst√§ndig ist (endet mit ']').\n",
    "        out_lines = []\n",
    "        while True:\n",
    "            line = _et_proc.stdout.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            out_lines.append(line)\n",
    "            # sehr einfache Heuristik: JSON-Array endet mit ']\\n'\n",
    "            if line.strip().endswith(']'):\n",
    "                break\n",
    "\n",
    "    out = \"\".join(out_lines).strip()\n",
    "    if not out:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        data = json.loads(out)\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        return [data]\n",
    "    except json.JSONDecodeError:\n",
    "        # Zur Diagnose ggf. stderr lesen (nicht zwingend in der Schleife auswerten)\n",
    "        return []\n",
    "\n",
    "def iter_files(root: Path, exts):\n",
    "    for r, d, files in os.walk(root):\n",
    "        for f in files:\n",
    "            p = Path(r)/f\n",
    "            if p.suffix.lower() in exts:\n",
    "                yield p\n",
    "\n",
    "def extract_from_json_item(item: dict):\n",
    "    # JSON-Struktur wie in deinem Beispiel:\n",
    "    # \"XMP-xmpMM:DocumentID\": \"uuid:‚Ä¶\",\n",
    "    # \"XMP-xmpMM:InstanceID\": \"uuid:‚Ä¶\",\n",
    "    # \"XMP-xmpMM:DerivedFrom\": {\"DocumentID\": \"...\", \"InstanceID\": \"...\"}\n",
    "    doc = item.get(\"XMP-xmpMM:DocumentID\") or item.get(\"DocumentID\")\n",
    "    ins = item.get(\"XMP-xmpMM:InstanceID\") or item.get(\"InstanceID\")\n",
    "    parent_doc, parent_ins = None, None\n",
    "    drv = item.get(\"XMP-xmpMM:DerivedFrom\") or item.get(\"DerivedFrom\")\n",
    "    if isinstance(drv, dict):\n",
    "        parent_doc = drv.get(\"DocumentID\") or drv.get(\"documentID\")\n",
    "        parent_ins = drv.get(\"InstanceID\") or drv.get(\"instanceID\")\n",
    "    return doc, ins, parent_doc, parent_ins\n",
    "\n",
    "# -----------------------------\n",
    "# Lauf: Dateien in Batches (Stay-Open bringt hier den Gewinn)\n",
    "# -----------------------------\n",
    "records = []\n",
    "batch = []\n",
    "BATCH_SIZE = 50  # 50‚Äì200: guter Kompromiss WebDAV <-> Antwortgr√∂√üe\n",
    "\n",
    "start_exiftool()\n",
    "try:\n",
    "    for fp in iter_files(ROOT, EXTENSIONS):\n",
    "        batch.append(fp)\n",
    "        if len(batch) >= BATCH_SIZE:\n",
    "            data = et_request_json(batch)\n",
    "            for item in data:\n",
    "                # Quelle (immer enthalten)\n",
    "                src = item.get(\"SourceFile\")\n",
    "                doc, ins, pdoc, pins = extract_from_json_item(item)\n",
    "                records.append({\n",
    "                    \"file\": src, \n",
    "                    \"documentID\": doc, \n",
    "                    \"instanceID\": ins, \n",
    "                    \"parentDocumentID\": pdoc, \n",
    "                    \"parentInstanceID\": pins\n",
    "                })\n",
    "            batch.clear()\n",
    "\n",
    "    # Rest\n",
    "    if batch:\n",
    "        data = et_request_json(batch)\n",
    "        for item in data:\n",
    "            src = item.get(\"SourceFile\")\n",
    "            doc, ins, pdoc, pins = extract_from_json_item(item)\n",
    "            records.append({\n",
    "                \"file\": src, \n",
    "                \"documentID\": doc, \n",
    "                \"instanceID\": ins, \n",
    "                \"parentDocumentID\": pdoc, \n",
    "                \"parentInstanceID\": pins\n",
    "            })\n",
    "finally:\n",
    "    stop_exiftool()\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "display(df.head(20))\n",
    "print(\"Mit XMP‚ÄëMM:\", df[\"documentID\"].notna().sum(), \"von\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Testlauf (Stay-Open + Sentinel) f√ºr bis zu 200 Dateien:\n",
      " /home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein\n",
      "üîç Teste jetzt 200 Dateien...\n",
      "‚è±Ô∏è Testlauf Dauer: 48.58 s\n",
      "\n",
      "üß¨ Ergebnis (erste 20 Zeilen):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>documentID</th>\n",
       "      <th>instanceID</th>\n",
       "      <th>parentDocumentID</th>\n",
       "      <th>parentInstanceID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>uuid:C74E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:C84E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:C54E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:C54E838EEACFDA118C30CF8EA9BFE8B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>uuid:D9170E74C1CFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:A53BA05DE9CFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:18FD04FBB2CFDA118C30CF8EA9BFE8B1</td>\n",
       "      <td>uuid:B0B29CD2B8CFDA118C30CF8EA9BFE8B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:da668ae1-f595-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:da668ae7-f595-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:4e2d1ba0-f596-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:4e2d1ba6-f596-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:4e2d1baa-f596-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:93726e95-f596-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:eefb7ae0-f596-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>adobe:docid:photoshop:e7dc0224-3095-11d7-a2ec-...</td>\n",
       "      <td>uuid:e7dc0226-3095-11d7-a2ec-d1fcfb080b2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:eefb7ae6-f596-11da-b021-...</td>\n",
       "      <td>uuid:DEBD576D635FDA118C5D9BB46FE99D01</td>\n",
       "      <td>uuid:9EC36DC4625FDA118C5D9BB46FE99D01</td>\n",
       "      <td>uuid:9DC36DC4625FDA118C5D9BB46FE99D01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:17b71261-f597-11da-b021-...</td>\n",
       "      <td>uuid:1B5FD559645FDA118C5D9BB46FE99D01</td>\n",
       "      <td>uuid:1A5FD559645FDA118C5D9BB46FE99D01</td>\n",
       "      <td>uuid:195FD559645FDA118C5D9BB46FE99D01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:17b71267-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:635644d2-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:635644d8-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:9fbfed83-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:9fbfed89-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:dc420934-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:dc42093a-f597-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:335723a5-f598-11da-b021-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/home/renku/work/dcaonnextcloud-500gb/DigitalM...</td>\n",
       "      <td>adobe:docid:photoshop:aac4ade4-f5fb-11da-b848-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file  \\\n",
       "0   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "1   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "2   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "3   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "4   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "5   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "6   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "7   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "8   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "9   /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "10  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "11  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "12  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "13  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "14  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "15  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "16  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "17  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "18  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "19  /home/renku/work/dcaonnextcloud-500gb/DigitalM...   \n",
       "\n",
       "                                           documentID  \\\n",
       "0               uuid:C74E838EEACFDA118C30CF8EA9BFE8B1   \n",
       "1               uuid:D9170E74C1CFDA118C30CF8EA9BFE8B1   \n",
       "2   adobe:docid:photoshop:da668ae1-f595-11da-b021-...   \n",
       "3   adobe:docid:photoshop:da668ae7-f595-11da-b021-...   \n",
       "4   adobe:docid:photoshop:4e2d1ba0-f596-11da-b021-...   \n",
       "5   adobe:docid:photoshop:4e2d1ba6-f596-11da-b021-...   \n",
       "6   adobe:docid:photoshop:4e2d1baa-f596-11da-b021-...   \n",
       "7   adobe:docid:photoshop:93726e95-f596-11da-b021-...   \n",
       "8   adobe:docid:photoshop:eefb7ae0-f596-11da-b021-...   \n",
       "9   adobe:docid:photoshop:eefb7ae6-f596-11da-b021-...   \n",
       "10  adobe:docid:photoshop:17b71261-f597-11da-b021-...   \n",
       "11  adobe:docid:photoshop:17b71267-f597-11da-b021-...   \n",
       "12  adobe:docid:photoshop:635644d2-f597-11da-b021-...   \n",
       "13  adobe:docid:photoshop:635644d8-f597-11da-b021-...   \n",
       "14  adobe:docid:photoshop:9fbfed83-f597-11da-b021-...   \n",
       "15  adobe:docid:photoshop:9fbfed89-f597-11da-b021-...   \n",
       "16  adobe:docid:photoshop:dc420934-f597-11da-b021-...   \n",
       "17  adobe:docid:photoshop:dc42093a-f597-11da-b021-...   \n",
       "18  adobe:docid:photoshop:335723a5-f598-11da-b021-...   \n",
       "19  adobe:docid:photoshop:aac4ade4-f5fb-11da-b848-...   \n",
       "\n",
       "                               instanceID  \\\n",
       "0   uuid:C84E838EEACFDA118C30CF8EA9BFE8B1   \n",
       "1   uuid:A53BA05DE9CFDA118C30CF8EA9BFE8B1   \n",
       "2                                    None   \n",
       "3                                    None   \n",
       "4                                    None   \n",
       "5                                    None   \n",
       "6                                    None   \n",
       "7                                    None   \n",
       "8                                    None   \n",
       "9   uuid:DEBD576D635FDA118C5D9BB46FE99D01   \n",
       "10  uuid:1B5FD559645FDA118C5D9BB46FE99D01   \n",
       "11                                   None   \n",
       "12                                   None   \n",
       "13                                   None   \n",
       "14                                   None   \n",
       "15                                   None   \n",
       "16                                   None   \n",
       "17                                   None   \n",
       "18                                   None   \n",
       "19                                   None   \n",
       "\n",
       "                                     parentDocumentID  \\\n",
       "0               uuid:C54E838EEACFDA118C30CF8EA9BFE8B1   \n",
       "1               uuid:18FD04FBB2CFDA118C30CF8EA9BFE8B1   \n",
       "2                                                None   \n",
       "3                                                None   \n",
       "4                                                None   \n",
       "5                                                None   \n",
       "6                                                None   \n",
       "7                                                None   \n",
       "8   adobe:docid:photoshop:e7dc0224-3095-11d7-a2ec-...   \n",
       "9               uuid:9EC36DC4625FDA118C5D9BB46FE99D01   \n",
       "10              uuid:1A5FD559645FDA118C5D9BB46FE99D01   \n",
       "11                                               None   \n",
       "12                                               None   \n",
       "13                                               None   \n",
       "14                                               None   \n",
       "15                                               None   \n",
       "16                                               None   \n",
       "17                                               None   \n",
       "18                                               None   \n",
       "19                                               None   \n",
       "\n",
       "                             parentInstanceID  \n",
       "0       uuid:C54E838EEACFDA118C30CF8EA9BFE8B1  \n",
       "1       uuid:B0B29CD2B8CFDA118C30CF8EA9BFE8B1  \n",
       "2                                        None  \n",
       "3                                        None  \n",
       "4                                        None  \n",
       "5                                        None  \n",
       "6                                        None  \n",
       "7                                        None  \n",
       "8   uuid:e7dc0226-3095-11d7-a2ec-d1fcfb080b2c  \n",
       "9       uuid:9DC36DC4625FDA118C5D9BB46FE99D01  \n",
       "10      uuid:195FD559645FDA118C5D9BB46FE99D01  \n",
       "11                                       None  \n",
       "12                                       None  \n",
       "13                                       None  \n",
       "14                                       None  \n",
       "15                                       None  \n",
       "16                                       None  \n",
       "17                                       None  \n",
       "18                                       None  \n",
       "19                                       None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úîÔ∏è Dateien MIT XMP‚ÄëMM: 146 von 200\n"
     ]
    }
   ],
   "source": [
    "import os, json, subprocess, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein/\")\n",
    "EXT = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".psd\",\".psb\"}\n",
    "EXIFTOOL = \"/home/renku/work/exiftool/exiftool\"\n",
    "BATCH_SIZE = 50\n",
    "MAX_TEST = 200  # nur Testlauf; f√ºr Vollscan entfernen/erh√∂hen\n",
    "SENTINEL = \"__END__\"\n",
    "\n",
    "print(\"üìÇ Testlauf (Stay-Open + Sentinel) f√ºr bis zu 200 Dateien:\\n\", ROOT)\n",
    "\n",
    "# Dateien einsammeln (bis MAX_TEST)\n",
    "files = []\n",
    "for root, dirs, filelist in os.walk(ROOT):\n",
    "    for f in filelist:\n",
    "        p = Path(root)/f\n",
    "        if p.suffix.lower() in EXT:\n",
    "            files.append(str(p))\n",
    "            if len(files) >= MAX_TEST:\n",
    "                break\n",
    "    if len(files) >= MAX_TEST:\n",
    "        break\n",
    "\n",
    "print(f\"üîç Teste jetzt {len(files)} Dateien...\")\n",
    "\n",
    "# -----------------------------\n",
    "# ExifTool stay-open starten\n",
    "# -----------------------------\n",
    "et = subprocess.Popen(\n",
    "    [EXIFTOOL, \"-stay_open\", \"True\", \"-@\", \"-\"],\n",
    "    stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "    text=True, bufsize=1\n",
    ")\n",
    "\n",
    "def et_send_batch(batch_files):\n",
    "    \"\"\"\n",
    "    Sendet EINEN Auftrag (Batch) an ExifTool:\n",
    "      - schlanke Argumente (nur xmpMM)\n",
    "      - JSON\n",
    "      - Sentinel als EOT-Marker\n",
    "    Liest stdout bis zum Sentinel, extrahiert den JSON-Block und liefert ihn als Liste zur√ºck.\n",
    "    \"\"\"\n",
    "    # SCHLANKE Argumente: nur xmpMM (schneller & weniger Output)\n",
    "    args = [\"-a\", \"-s\", \"-struct\", \"-XMP-xmpMM:all\", \"-json\"]\n",
    "    for a in args:\n",
    "        et.stdin.write(a + \"\\n\")\n",
    "    for f in batch_files:\n",
    "        et.stdin.write(f + \"\\n\")\n",
    "    # Sentinel vor -execute setzen\n",
    "    et.stdin.write(f\"-echo3\\n{SENTINEL}\\n\")\n",
    "    et.stdin.write(\"-execute\\n\")\n",
    "    et.stdin.flush()\n",
    "\n",
    "    # stdout lesen bis Sentinel gefunden\n",
    "    lines = []\n",
    "    t_start = time.time()\n",
    "    while True:\n",
    "        line = et.stdout.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        # Sentinel erreicht -> Ende der Antwort\n",
    "        if line.strip() == SENTINEL:\n",
    "            break\n",
    "        lines.append(line)\n",
    "\n",
    "    out = \"\".join(lines).strip()\n",
    "    if not out:\n",
    "        return []\n",
    "\n",
    "    # JSON extrahieren (es kann vor/nach JSON noch andere Zeilen geben; wir finden den JSON-Array-Block)\n",
    "    # Wir suchen den ersten '[' und das letzte ']'\n",
    "    start = out.find('[')\n",
    "    end   = out.rfind(']')\n",
    "    if start == -1 or end == -1 or end < start:\n",
    "        # Diagnose: zeige kurze Vorschau\n",
    "        print(\"‚ö†Ô∏è Konnte JSON-Block nicht isolieren. Vorschau:\", out[:400])\n",
    "        return []\n",
    "\n",
    "    json_str = out[start:end+1]\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        return data if isinstance(data, list) else [data]\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"‚ö†Ô∏è JSONDecodeError:\", e)\n",
    "        print(\"Vorschau:\", json_str[:400])\n",
    "        return []\n",
    "\n",
    "def et_close():\n",
    "    try:\n",
    "        et.stdin.write(\"-stay_open\\nFalse\\n-execute\\n\")\n",
    "        et.stdin.flush()\n",
    "        et.communicate(timeout=3)\n",
    "    except Exception:\n",
    "        et.kill()\n",
    "\n",
    "# -----------------------------\n",
    "# Batchweise abarbeiten\n",
    "# -----------------------------\n",
    "records = []\n",
    "t0 = time.time()\n",
    "\n",
    "try:\n",
    "    for i in range(0, len(files), BATCH_SIZE):\n",
    "        batch = files[i:i+BATCH_SIZE]\n",
    "        data  = et_send_batch(batch)\n",
    "        # pro Batch extrahieren\n",
    "        for item in data:\n",
    "            src = item.get(\"SourceFile\")\n",
    "            doc = item.get(\"XMP-xmpMM:DocumentID\") or item.get(\"DocumentID\")\n",
    "            ins = item.get(\"XMP-xmpMM:InstanceID\") or item.get(\"InstanceID\")\n",
    "            pdoc = pins = None\n",
    "            drv = item.get(\"XMP-xmpMM:DerivedFrom\") or item.get(\"DerivedFrom\")\n",
    "            if isinstance(drv, dict):\n",
    "                pdoc = drv.get(\"DocumentID\") or drv.get(\"documentID\")\n",
    "                pins = drv.get(\"InstanceID\") or drv.get(\"instanceID\")\n",
    "            records.append({\n",
    "                \"file\": src,\n",
    "                \"documentID\": doc,\n",
    "                \"instanceID\": ins,\n",
    "                \"parentDocumentID\": pdoc,\n",
    "                \"parentInstanceID\": pins\n",
    "            })\n",
    "finally:\n",
    "    et_close()\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"‚è±Ô∏è Testlauf Dauer: {t1-t0:.2f} s\")\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(\"\\nüß¨ Ergebnis (erste 20 Zeilen):\")\n",
    "display(df.head(20))\n",
    "print(\"\\n‚úîÔ∏è Dateien MIT XMP‚ÄëMM:\", df[\"documentID\"].notna().sum() if \"documentID\" in df.columns else 0, \"von\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def norm_id(raw: str|None) -> str|None:\n",
    "    \"\"\"\n",
    "    Normalisiert Document/Instance-IDs:\n",
    "    - trimmt Leerzeichen\n",
    "    - bel√§sst 'uuid:' und 'adobe:docid:photoshop:' Pr√§fixe (wichtig f√ºr Eindeutigkeit)\n",
    "    - wandelt in lowercase f√ºr stabile Vergleiche\n",
    "    \"\"\"\n",
    "    if not raw: \n",
    "        return None\n",
    "    s = raw.strip()\n",
    "    return s.lower()\n",
    "\n",
    "def extract_from_item(item: dict):\n",
    "    \"\"\"\n",
    "    Holt IDs aus der JSON-Struktur (wie in deiner Beispielausgabe):\n",
    "      - XMP-xmpMM:DocumentID\n",
    "      - XMP-xmpMM:InstanceID\n",
    "      - XMP-xmpMM:DerivedFrom{DocumentID,InstanceID}\n",
    "    und normalisiert sie.\n",
    "    \"\"\"\n",
    "    src = item.get(\"SourceFile\")\n",
    "    doc = item.get(\"XMP-xmpMM:DocumentID\") or item.get(\"DocumentID\")\n",
    "    ins = item.get(\"XMP-xmpMM:InstanceID\") or item.get(\"InstanceID\")\n",
    "\n",
    "    pdoc = pins = None\n",
    "    drv = item.get(\"XMP-xmpMM:DerivedFrom\") or item.get(\"DerivedFrom\")\n",
    "    if isinstance(drv, dict):\n",
    "        pdoc = drv.get(\"DocumentID\") or drv.get(\"documentID\")\n",
    "        pins = drv.get(\"InstanceID\") or drv.get(\"instanceID\")\n",
    "\n",
    "    return {\n",
    "        \"file\": src,\n",
    "        \"documentID\": norm_id(doc),\n",
    "        \"instanceID\": norm_id(ins),\n",
    "        \"parentDocumentID\": norm_id(pdoc),\n",
    "        \"parentInstanceID\": norm_id(pins),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Zu scannen:** 12338 Dateien"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12338/12338  |  5.12 Dateien/s  |  ETA 0.0 min\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Mit XMP‚ÄëMM:** 6079 / 12338"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Graph:** 5992 Knoten, 59 Kanten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV ‚Üí genealogy_full.csv\n",
      "Graph JSON ‚Üí genealogy_full_graph.json\n",
      "Gefundene Wurzeln: 5933 (zeige bis zu 5)\n",
      "uuid:c54e838eeacfda118c30cf8ea9bfe8b1 ‚Üí uuid:c74e838eeacfda118c30cf8ea9bfe8b1\n",
      "uuid:18fd04fbb2cfda118c30cf8ea9bfe8b1 ‚Üí uuid:d9170e74c1cfda118c30cf8ea9bfe8b1\n",
      "adobe:docid:photoshop:da668ae1-f595-11da-b021-8ba1b752bf42\n",
      "adobe:docid:photoshop:da668ae7-f595-11da-b021-8ba1b752bf42\n",
      "adobe:docid:photoshop:4e2d1ba0-f596-11da-b021-8ba1b752bf42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renku/work/.venv/lib/python3.10/site-packages/networkx/readwrite/json_graph/node_link.py:142: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, json, subprocess, time, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from IPython.display import display, Markdown\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "# ---------- Konfiguration ----------\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein\")\n",
    "EXT = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".psd\",\".psb\"}\n",
    "EXIFTOOL = \"/home/renku/work/exiftool/exiftool\"\n",
    "SENTINEL = \"__END__\"\n",
    "BATCH_SIZE = 100          # 50‚Äì200 sind oft gut. Bei Timeout: kleiner w√§hlen.\n",
    "FAST = False              # True ‚Üí add -fast f√ºr Minimal‚ÄëI/O\n",
    "OUT_PREFIX = \"genealogy_full\"\n",
    "\n",
    "# ---------- Dateien einsammeln ----------\n",
    "files = []\n",
    "for r, d, flist in os.walk(ROOT):\n",
    "    for f in flist:\n",
    "        p = Path(r)/f\n",
    "        if p.suffix.lower() in EXT:\n",
    "            files.append(str(p))\n",
    "total = len(files)\n",
    "display(Markdown(f\"**Zu scannen:** {total} Dateien\"))\n",
    "\n",
    "# ---------- ExifTool Stay‚ÄëOpen starten ----------\n",
    "args = [EXIFTOOL, \"-stay_open\", \"True\", \"-@\", \"-\"]\n",
    "et = subprocess.Popen(args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "                      text=True, bufsize=1)\n",
    "\n",
    "def send_batch(batch_files):\n",
    "    # Schlanke Argumente ‚Äì nur xmpMM, optional -fast\n",
    "    cmd = [\"-a\",\"-s\",\"-struct\",\"-XMP-xmpMM:all\",\"-json\"]\n",
    "    if FAST:\n",
    "        cmd.insert(0, \"-fast\")\n",
    "    for a in cmd:\n",
    "        et.stdin.write(a + \"\\n\")\n",
    "    for f in batch_files:\n",
    "        et.stdin.write(f + \"\\n\")\n",
    "    # Sentinel f√ºr eindeutigen Abschluss\n",
    "    et.stdin.write(f\"-echo3\\n{SENTINEL}\\n\")\n",
    "    et.stdin.write(\"-execute\\n\")\n",
    "    et.stdin.flush()\n",
    "\n",
    "    # stdout bis Sentinel\n",
    "    lines = []\n",
    "    while True:\n",
    "        line = et.stdout.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        if line.strip() == SENTINEL:\n",
    "            break\n",
    "        lines.append(line)\n",
    "\n",
    "    out = \"\".join(lines).strip()\n",
    "    if not out:\n",
    "        return []\n",
    "\n",
    "    # JSON Array isolieren\n",
    "    i, j = out.find('['), out.rfind(']')\n",
    "    if i == -1 or j == -1 or j < i:\n",
    "        # Diagnose: kleine Vorschau\n",
    "        print(\"‚ö†Ô∏è Kein JSON‚ÄëArray erkennbar. Vorschau:\", out[:400])\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        data = json.loads(out[i:j+1])\n",
    "        return data if isinstance(data, list) else [data]\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"‚ö†Ô∏è JSONDecodeError:\", e)\n",
    "        print(\"Vorschau:\", out[max(0, i-100):min(len(out), j+100)])\n",
    "        return []\n",
    "\n",
    "def close_et():\n",
    "    try:\n",
    "        et.stdin.write(\"-stay_open\\nFalse\\n-execute\\n\")\n",
    "        et.stdin.flush()\n",
    "        et.communicate(timeout=3)\n",
    "    except Exception:\n",
    "        et.kill()\n",
    "\n",
    "# ---------- Hauptlauf mit Fortschritt ----------\n",
    "records = []\n",
    "start = time.time()\n",
    "processed = 0\n",
    "\n",
    "try:\n",
    "    for i in range(0, total, BATCH_SIZE):\n",
    "        batch = files[i:i+BATCH_SIZE]\n",
    "        t0 = time.time()\n",
    "        data = send_batch(batch)\n",
    "        for item in data:\n",
    "            rec = extract_from_item(item)\n",
    "            records.append(rec)\n",
    "        processed += len(batch)\n",
    "        # Fortschritt & ETA\n",
    "        elapsed = time.time() - start\n",
    "        rate = processed / elapsed if elapsed > 0 else 0\n",
    "        remain = (total - processed) / rate if rate > 0 else 0\n",
    "        print(f\"\\r{processed}/{total}  |  {rate:.2f} Dateien/s  |  ETA {remain/60:.1f} min\", end=\"\")\n",
    "finally:\n",
    "    close_et()\n",
    "\n",
    "print()  # Zeilenumbruch\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "display(Markdown(f\"**Mit XMP‚ÄëMM:** {(df['documentID'].notna()).sum() if 'documentID' in df.columns else 0} / {len(df)}\"))\n",
    "\n",
    "# ---------- Graph aufbauen ----------\n",
    "G = nx.DiGraph()\n",
    "for _, row in df.iterrows():\n",
    "    doc, parent = row.get(\"documentID\"), row.get(\"parentDocumentID\")\n",
    "    if doc: G.add_node(doc)\n",
    "    if parent: G.add_edge(parent, doc)\n",
    "\n",
    "display(Markdown(f\"**Graph:** {G.number_of_nodes()} Knoten, {G.number_of_edges()} Kanten\"))\n",
    "\n",
    "# ---------- Exporte ----------\n",
    "csv_path = f\"{OUT_PREFIX}.csv\"\n",
    "json_graph_path = f\"{OUT_PREFIX}_graph.json\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "with open(json_graph_path, \"w\") as f:\n",
    "    json.dump(json_graph.node_link_data(G), f, indent=2)\n",
    "print(f\"CSV ‚Üí {csv_path}\")\n",
    "print(f\"Graph JSON ‚Üí {json_graph_path}\")\n",
    "\n",
    "# ---------- Einfache Ketten-Ausgabe ----------\n",
    "def print_chains(G, max_chains=5):\n",
    "    roots = [n for n in G.nodes if G.in_degree(n) == 0]\n",
    "    print(f\"Gefundene Wurzeln: {len(roots)} (zeige bis zu {max_chains})\")\n",
    "    shown = 0\n",
    "    for r in roots:\n",
    "        if shown >= max_chains: break\n",
    "        chain = list(nx.dfs_preorder_nodes(G, source=r))\n",
    "        print(\" ‚Üí \".join(chain[:10]) + (\" ‚Ä¶\" if len(chain) > 10 else \"\"))\n",
    "        shown += 1\n",
    "\n",
    "print_chains(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pfad zu graph hinzuf√ºgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angereichertes JSON: genealogy_full_graph_with_paths.json\n"
     ]
    }
   ],
   "source": [
    "import json, pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "CSV = \"genealogy_full.csv\"\n",
    "JSON_IN  = \"genealogy_full_graph.json\"\n",
    "JSON_OUT = \"genealogy_full_graph_with_paths.json\"\n",
    "\n",
    "# 1) CSV laden, Pfade je documentID sammeln\n",
    "df = pd.read_csv(CSV)\n",
    "paths_by_doc = defaultdict(list)\n",
    "for _, row in df.iterrows():\n",
    "    doc = str(row.get(\"documentID\")).strip().lower() if pd.notna(row.get(\"documentID\")) else None\n",
    "    fp  = row.get(\"file\")\n",
    "    if doc:\n",
    "        paths_by_doc[doc].append(fp)\n",
    "\n",
    "# 2) JSON laden\n",
    "graph = json.load(open(JSON_IN, \"r\"))\n",
    "\n",
    "# 3) Nodes anreichern\n",
    "for n in graph.get(\"nodes\", []):\n",
    "    doc = str(n.get(\"id\")).strip().lower()\n",
    "    files = sorted(set(paths_by_doc.get(doc, [])))\n",
    "    n[\"files\"] = files\n",
    "    n[\"fileCount\"] = len(files)\n",
    "    n[\"fileSample\"] = files[0] if files else None\n",
    "\n",
    "# 4) Schreiben\n",
    "with open(JSON_OUT, \"w\") as f:\n",
    "    json.dump(graph, f, indent=2)\n",
    "\n",
    "print(\"Angereichertes JSON:\", JSON_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Zu scannen:** 12338 Dateien"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12338/12338  |  5.09 Dateien/s  |  ETA 0.0 min\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Mit XMP‚ÄëMM DocumentID:** 6079 / 12338"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Graph:** 5971 Knoten, 65 Kanten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV ‚Üí genealogy_full.csv\n",
      "Graph JSON ‚Üí genealogy_full_graph.json\n",
      "Gefundene Wurzeln: 5906 (zeige bis zu 5)\n",
      "uuid:C74E838EEACFDA118C30CF8EA9BFE8B1\n",
      "uuid:D9170E74C1CFDA118C30CF8EA9BFE8B1\n",
      "adobe:docid:photoshop:93726e95-f596-11da-b021-8ba1b752bf42\n",
      "adobe:docid:photoshop:eefb7ae0-f596-11da-b021-8ba1b752bf42\n",
      "adobe:docid:photoshop:17b71267-f597-11da-b021-8ba1b752bf42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renku/work/.venv/lib/python3.10/site-packages/networkx/readwrite/json_graph/node_link.py:142: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, json, subprocess, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from IPython.display import display, Markdown\n",
    "from networkx.readwrite import json_graph\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------- Konfiguration ----------\n",
    "ROOT = Path(\"/home/renku/work/dcaonnextcloud-500gb/DigitalMaterialCopies/WeingutGantenbein/gramazio-kohler-archiv-server/036_WeingutGantenbein\")\n",
    "EXT = {\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".png\",\".psd\",\".psb\"}\n",
    "EXIFTOOL = \"/home/renku/work/exiftool/exiftool\"\n",
    "SENTINEL = \"__END__\"\n",
    "BATCH_SIZE = 100          # 50‚Äì200 sind oft gut. Bei Timeout: kleiner w√§hlen.\n",
    "FAST = False              # True ‚Üí add -fast f√ºr Minimal‚ÄëI/O\n",
    "OUT_PREFIX = \"genealogy_full\"\n",
    "\n",
    "# (NEU) Priorit√§ten f√ºr Klassen-Zusammenf√ºhrung je Knoten\n",
    "CLASS_PRIORITY = [\n",
    "    \"photoshop_derivative\",\n",
    "    \"photoshop_no_parent\",\n",
    "    \"camera_original\",\n",
    "    \"bridge_or_raw\",\n",
    "    \"unknown\",\n",
    "    \"camera\"  # nur f√ºr Kamera-Knoten selbst\n",
    "]\n",
    "\n",
    "# ---------- Dateien einsammeln ----------\n",
    "files = []\n",
    "for r, d, flist in os.walk(ROOT):\n",
    "    for f in flist:\n",
    "        p = Path(r) / f\n",
    "        if p.suffix.lower() in EXT:\n",
    "            files.append(str(p))\n",
    "total = len(files)\n",
    "display(Markdown(f\"**Zu scannen:** {total} Dateien\"))\n",
    "\n",
    "# ---------- ExifTool Stay‚ÄëOpen starten ----------\n",
    "args = [EXIFTOOL, \"-stay_open\", \"True\", \"-@\", \"-\"]\n",
    "et = subprocess.Popen(\n",
    "    args,\n",
    "    stdin=subprocess.PIPE,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    text=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "def send_batch(batch_files):\n",
    "    \"\"\"\n",
    "    Ruft ExifTool im Stay-Open-Mode auf und liefert die JSON-Objekte f√ºr die Dateien.\n",
    "    (NEU) Abfrage erweitert um EXIF/TIFF/CreatorTool, -G1 f√ºr stabile Feldnamen.\n",
    "    \"\"\"\n",
    "    # Tags minimal & gezielt halten: XMP-xmpMM + EXIF/TIFF + CreatorTool\n",
    "    cmd = [\n",
    "        \"-a\", \"-s\", \"-struct\", \"-G1\", \"-json\",\n",
    "        # MM-Genealogie\n",
    "        \"XMP-xmpMM:all\",\n",
    "        # Kamera-/EXIF-/TIFF\n",
    "        \"EXIF:Make\", \"EXIF:Model\", \"EXIF:DateTimeOriginal\",\n",
    "        \"XMP-tiff:Make\", \"XMP-tiff:Model\",\n",
    "        # CreatorTool (Photoshop/Camera Raw/Bridge)\n",
    "        \"XMP-xmp:CreatorTool\", \"XMP-x:CreatorTool\"\n",
    "    ]\n",
    "    if FAST:\n",
    "        cmd.insert(0, \"-fast\")\n",
    "\n",
    "    # Kommandos schreiben\n",
    "    for a in cmd:\n",
    "        et.stdin.write(a + \"\\n\")\n",
    "    for f in batch_files:\n",
    "        et.stdin.write(f + \"\\n\")\n",
    "    # Sentinel f√ºr eindeutigen Abschluss\n",
    "    et.stdin.write(f\"-echo3\\n{SENTINEL}\\n\")\n",
    "    et.stdin.write(\"-execute\\n\")\n",
    "    et.stdin.flush()\n",
    "\n",
    "    # stdout bis Sentinel\n",
    "    lines = []\n",
    "    while True:\n",
    "        line = et.stdout.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        if line.strip() == SENTINEL:\n",
    "            break\n",
    "        lines.append(line)\n",
    "\n",
    "    out = \"\".join(lines).strip()\n",
    "    if not out:\n",
    "        return []\n",
    "\n",
    "    # JSON Array isolieren\n",
    "    i, j = out.find('['), out.rfind(']')\n",
    "    if i == -1 or j == -1 or j < i:\n",
    "        # Diagnose: kleine Vorschau\n",
    "        print(\"‚ö†Ô∏è Kein JSON‚ÄëArray erkennbar. Vorschau:\", out[:400])\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        data = json.loads(out[i:j+1])\n",
    "        return data if isinstance(data, list) else [data]\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"‚ö†Ô∏è JSONDecodeError:\", e)\n",
    "        print(\"Vorschau:\", out[max(0, i-100):min(len(out), j+100)])\n",
    "        return []\n",
    "\n",
    "def close_et():\n",
    "    try:\n",
    "        et.stdin.write(\"-stay_open\\nFalse\\n-execute\\n\")\n",
    "        et.stdin.flush()\n",
    "        et.communicate(timeout=3)\n",
    "    except Exception:\n",
    "        et.kill()\n",
    "\n",
    "# ---------- (NEU) Extraktion & Klassifikation ----------\n",
    "def extract_from_item(item):\n",
    "    \"\"\"\n",
    "    Extrahiert XMP‚ÄëMM Genealogie + neue Klassifikation + Kamera-Infos.\n",
    "    Erwartete Schl√ºssel (wegen -G1):\n",
    "    - XMP-xmpMM:DocumentID / InstanceID / DerivedFrom:DocumentID / DerivedFrom:InstanceID\n",
    "    - EXIF:Make/Model/DateTimeOriginal, XMP-tiff:Make/Model\n",
    "    - XMP-xmp:CreatorTool oder XMP-x:CreatorTool\n",
    "    \"\"\"\n",
    "    rec = {}\n",
    "\n",
    "    # Basis\n",
    "    rec[\"file\"] = item.get(\"SourceFile\")\n",
    "\n",
    "    # MM-IDs\n",
    "    rec[\"documentID\"]       = item.get(\"XMP-xmpMM:DocumentID\")\n",
    "    rec[\"instanceID\"]       = item.get(\"XMP-xmpMM:InstanceID\")\n",
    "    rec[\"parentDocumentID\"] = item.get(\"XMP-xmpMM:DerivedFrom:DocumentID\")\n",
    "    rec[\"parentInstanceID\"] = item.get(\"XMP-xmpMM:DerivedFrom:InstanceID\")\n",
    "\n",
    "    # Kamera\n",
    "    make  = item.get(\"EXIF:Make\") or item.get(\"XMP-tiff:Make\")\n",
    "    model = item.get(\"EXIF:Model\") or item.get(\"XMP-tiff:Model\")\n",
    "    rec[\"cameraMake\"] = make\n",
    "    rec[\"cameraModel\"] = model\n",
    "\n",
    "    # CreatorTool\n",
    "    creator = item.get(\"XMP-xmp:CreatorTool\") or item.get(\"XMP-x:CreatorTool\") or \"\"\n",
    "    rec[\"creatorTool\"] = creator\n",
    "\n",
    "    # Flags\n",
    "    has_parent = bool(rec[\"parentDocumentID\"] or rec[\"parentInstanceID\"])\n",
    "    has_exif   = bool(make or model or item.get(\"EXIF:DateTimeOriginal\"))\n",
    "\n",
    "    is_photoshop = \"photoshop\" in creator.lower() if creator else False\n",
    "    is_bridgeraw = (not is_photoshop) and has_exif  # Heuristik: XMP/EXIF ja, aber kein PS\n",
    "\n",
    "    # Klasse\n",
    "    if has_parent:\n",
    "        rec[\"class\"] = \"photoshop_derivative\"\n",
    "    elif has_exif and (make or model):\n",
    "        rec[\"class\"] = \"camera_original\"\n",
    "    elif is_photoshop and not has_parent:\n",
    "        rec[\"class\"] = \"photoshop_no_parent\"\n",
    "    elif is_bridgeraw:\n",
    "        rec[\"class\"] = \"bridge_or_raw\"\n",
    "    else:\n",
    "        rec[\"class\"] = \"unknown\"\n",
    "\n",
    "    return rec\n",
    "\n",
    "def pick_class(old_cls, new_cls):\n",
    "    \"\"\"Nimmt die Klasse mit h√∂herer Priorit√§t.\"\"\"\n",
    "    if not old_cls:\n",
    "        return new_cls\n",
    "    try:\n",
    "        return old_cls if CLASS_PRIORITY.index(old_cls) <= CLASS_PRIORITY.index(new_cls) else new_cls\n",
    "    except ValueError:\n",
    "        return old_cls or new_cls\n",
    "\n",
    "# ---------- Hauptlauf mit Fortschritt ----------\n",
    "records = []\n",
    "start = time.time()\n",
    "processed = 0\n",
    "\n",
    "try:\n",
    "    for i in range(0, total, BATCH_SIZE):\n",
    "        batch = files[i:i+BATCH_SIZE]\n",
    "        t0 = time.time()\n",
    "        data = send_batch(batch)\n",
    "        for item in data:\n",
    "            rec = extract_from_item(item)\n",
    "            records.append(rec)\n",
    "        processed += len(batch)\n",
    "        # Fortschritt & ETA\n",
    "        elapsed = time.time() - start\n",
    "        rate = processed / elapsed if elapsed > 0 else 0\n",
    "        remain = (total - processed) / rate if rate > 0 else 0\n",
    "        print(f\"\\r{processed}/{total}  |  {rate:.2f} Dateien/s  |  ETA {remain/60:.1f} min\", end=\"\")\n",
    "finally:\n",
    "    close_et()\n",
    "\n",
    "print()  # Zeilenumbruch\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "with_xmpmm = (df[\"documentID\"].notna()).sum() if \"documentID\" in df.columns else 0\n",
    "display(Markdown(f\"**Mit XMP‚ÄëMM DocumentID:** {with_xmpmm} / {len(df)}\"))\n",
    "\n",
    "# ---------- Graph aufbauen (NEU: Klassen/Files/Kamera-Knoten) ----------\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Node-Aggregate\n",
    "node_files  = defaultdict(set)\n",
    "node_class  = defaultdict(str)\n",
    "\n",
    "# (1) Zuerst alle Bild-Knoten erfassen (documentID oder fallback instanceID)\n",
    "def get_node_id(row):\n",
    "    return row[\"documentID\"] if pd.notna(row.get(\"documentID\")) else row.get(\"instanceID\")\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    node_id = get_node_id(row)\n",
    "    if not node_id:\n",
    "        continue\n",
    "    # Files sammeln\n",
    "    fpath = row.get(\"file\")\n",
    "    if fpath:\n",
    "        node_files[node_id].add(fpath)\n",
    "    # Klasse zusammenf√ºhren\n",
    "    node_class[node_id] = pick_class(node_class[node_id], row.get(\"class\"))\n",
    "\n",
    "# (2) Kamera-Knoten vorbereiten (nur wenn Kamera-Infos vorhanden)\n",
    "def camera_id_from_row(row):\n",
    "    mk, md = row.get(\"cameraMake\"), row.get(\"cameraModel\")\n",
    "    if mk or md:\n",
    "        # Lesbarer, aber stabiler Identifier:\n",
    "        return f\"camera:{(mk or '').strip()}|{(md or '').strip()}\"\n",
    "    return None\n",
    "\n",
    "camera_nodes = set()\n",
    "for _, row in df.iterrows():\n",
    "    cam_id = camera_id_from_row(row)\n",
    "    if cam_id:\n",
    "        camera_nodes.add(cam_id)\n",
    "\n",
    "# (3) Knoten in den Graph schreiben (mit Attributen class, files)\n",
    "for nid in node_files.keys():\n",
    "    G.add_node(nid, **{\n",
    "        \"class\": node_class[nid] or \"unknown\",\n",
    "        \"files\": sorted(node_files[nid])\n",
    "    })\n",
    "\n",
    "# (4) Kamera-Knoten hinzuf√ºgen (class=camera, files=[])\n",
    "for cam in camera_nodes:\n",
    "    if not G.has_node(cam):\n",
    "        G.add_node(cam, **{\"class\": \"camera\", \"files\": []})\n",
    "\n",
    "# (5) Genealogische Kanten (Parent ‚Üí Child)\n",
    "for _, row in df.iterrows():\n",
    "    child = get_node_id(row)\n",
    "    if not child:\n",
    "        continue\n",
    "    # parent via DocumentID / InstanceID\n",
    "    pdoc = row.get(\"parentDocumentID\")\n",
    "    pinst = row.get(\"parentInstanceID\")\n",
    "    # Wir akzeptieren beide, erzeugen die Knoten bei Bedarf mit default-Attributen\n",
    "    for parent in (pdoc, pinst):\n",
    "        if parent and parent != child:\n",
    "            if not G.has_node(parent):\n",
    "                G.add_node(parent, **{\"class\": \"unknown\", \"files\": []})\n",
    "            G.add_edge(parent, child)\n",
    "\n",
    "# (6) Kamera ‚Üí Bild-Kanten f√ºr camera_original\n",
    "for _, row in df.iterrows():\n",
    "    node_id = get_node_id(row)\n",
    "    if not node_id:\n",
    "        continue\n",
    "    if row.get(\"class\") == \"camera_original\":\n",
    "        cam_id = camera_id_from_row(row)\n",
    "        if cam_id:\n",
    "            if not G.has_node(cam_id):\n",
    "                G.add_node(cam_id, **{\"class\": \"camera\", \"files\": []})\n",
    "            G.add_edge(cam_id, node_id)\n",
    "\n",
    "display(Markdown(f\"**Graph:** {G.number_of_nodes()} Knoten, {G.number_of_edges()} Kanten\"))\n",
    "\n",
    "# ---------- Exporte ----------\n",
    "csv_path = f\"{OUT_PREFIX}.csv\"\n",
    "json_graph_path = f\"{OUT_PREFIX}_graph.json\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "with open(json_graph_path, \"w\") as f:\n",
    "    json.dump(json_graph.node_link_data(G), f, indent=2, ensure_ascii=False)\n",
    "print(f\"CSV ‚Üí {csv_path}\")\n",
    "print(f\"Graph JSON ‚Üí {json_graph_path}\")\n",
    "\n",
    "# ---------- Einfache Ketten-Ausgabe ----------\n",
    "def print_chains(G, max_chains=5):\n",
    "    roots = [n for n in G.nodes if G.in_degree(n) == 0]\n",
    "    print(f\"Gefundene Wurzeln: {len(roots)} (zeige bis zu {max_chains})\")\n",
    "    shown = 0\n",
    "    for r in roots:\n",
    "        if shown >= max_chains:\n",
    "            break\n",
    "        chain = list(nx.dfs_preorder_nodes(G, source=r))\n",
    "        # Eine kurze, lesbare Darstellung:\n",
    "        preview = \" ‚Üí \".join(chain[:10]) + (\" ‚Ä¶\" if len(chain) > 10 else \"\")\n",
    "        print(preview)\n",
    "        shown += 1\n",
    "\n",
    "print_chains(G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
